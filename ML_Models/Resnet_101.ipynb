{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:13.250528Z",
     "start_time": "2024-07-29T19:18:10.510002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:18:10.672117: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 15:18:10.697247: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 15:18:10.697275: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 15:18:10.697298: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 15:18:10.703321: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 15:18:11.552790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:18:13.205279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.228308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.243337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.246067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:13.254597Z",
     "start_time": "2024-07-29T19:18:13.251283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:13.260776Z",
     "start_time": "2024-07-29T19:18:13.255118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:13.264341Z",
     "start_time": "2024-07-29T19:18:13.261719Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:13.267173Z",
     "start_time": "2024-07-29T19:18:13.264993Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:14.145271Z",
     "start_time": "2024-07-29T19:18:13.267645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:18:13.323339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.326109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.329470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.460829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.462697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.464391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:18:13.466461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5971 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-29 15:18:13.604405: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:14.147967Z",
     "start_time": "2024-07-29T19:18:14.145918Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:14.154150Z",
     "start_time": "2024-07-29T19:18:14.148502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.resnet.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:14.184306Z",
     "start_time": "2024-07-29T19:18:14.154665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:14.948620Z",
     "start_time": "2024-07-29T19:18:14.945927Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:17.078663Z",
     "start_time": "2024-07-29T19:18:15.297338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.ResNet101(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:17.082886Z",
     "start_time": "2024-07-29T19:18:17.079602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: conv1_pad, False\n",
      "Layer: conv1_conv, False\n",
      "Layer: conv1_bn, False\n",
      "Layer: conv1_relu, False\n",
      "Layer: pool1_pad, False\n",
      "Layer: pool1_pool, False\n",
      "Layer: conv2_block1_1_conv, False\n",
      "Layer: conv2_block1_1_bn, False\n",
      "Layer: conv2_block1_1_relu, False\n",
      "Layer: conv2_block1_2_conv, False\n",
      "Layer: conv2_block1_2_bn, False\n",
      "Layer: conv2_block1_2_relu, False\n",
      "Layer: conv2_block1_0_conv, False\n",
      "Layer: conv2_block1_3_conv, False\n",
      "Layer: conv2_block1_0_bn, False\n",
      "Layer: conv2_block1_3_bn, False\n",
      "Layer: conv2_block1_add, False\n",
      "Layer: conv2_block1_out, False\n",
      "Layer: conv2_block2_1_conv, False\n",
      "Layer: conv2_block2_1_bn, False\n",
      "Layer: conv2_block2_1_relu, False\n",
      "Layer: conv2_block2_2_conv, False\n",
      "Layer: conv2_block2_2_bn, False\n",
      "Layer: conv2_block2_2_relu, False\n",
      "Layer: conv2_block2_3_conv, False\n",
      "Layer: conv2_block2_3_bn, False\n",
      "Layer: conv2_block2_add, False\n",
      "Layer: conv2_block2_out, False\n",
      "Layer: conv2_block3_1_conv, False\n",
      "Layer: conv2_block3_1_bn, False\n",
      "Layer: conv2_block3_1_relu, False\n",
      "Layer: conv2_block3_2_conv, False\n",
      "Layer: conv2_block3_2_bn, False\n",
      "Layer: conv2_block3_2_relu, False\n",
      "Layer: conv2_block3_3_conv, False\n",
      "Layer: conv2_block3_3_bn, False\n",
      "Layer: conv2_block3_add, False\n",
      "Layer: conv2_block3_out, False\n",
      "Layer: conv3_block1_1_conv, False\n",
      "Layer: conv3_block1_1_bn, False\n",
      "Layer: conv3_block1_1_relu, False\n",
      "Layer: conv3_block1_2_conv, False\n",
      "Layer: conv3_block1_2_bn, False\n",
      "Layer: conv3_block1_2_relu, False\n",
      "Layer: conv3_block1_0_conv, False\n",
      "Layer: conv3_block1_3_conv, False\n",
      "Layer: conv3_block1_0_bn, False\n",
      "Layer: conv3_block1_3_bn, False\n",
      "Layer: conv3_block1_add, False\n",
      "Layer: conv3_block1_out, False\n",
      "Layer: conv3_block2_1_conv, False\n",
      "Layer: conv3_block2_1_bn, False\n",
      "Layer: conv3_block2_1_relu, False\n",
      "Layer: conv3_block2_2_conv, False\n",
      "Layer: conv3_block2_2_bn, False\n",
      "Layer: conv3_block2_2_relu, False\n",
      "Layer: conv3_block2_3_conv, False\n",
      "Layer: conv3_block2_3_bn, False\n",
      "Layer: conv3_block2_add, False\n",
      "Layer: conv3_block2_out, False\n",
      "Layer: conv3_block3_1_conv, False\n",
      "Layer: conv3_block3_1_bn, False\n",
      "Layer: conv3_block3_1_relu, False\n",
      "Layer: conv3_block3_2_conv, False\n",
      "Layer: conv3_block3_2_bn, False\n",
      "Layer: conv3_block3_2_relu, False\n",
      "Layer: conv3_block3_3_conv, False\n",
      "Layer: conv3_block3_3_bn, False\n",
      "Layer: conv3_block3_add, False\n",
      "Layer: conv3_block3_out, False\n",
      "Layer: conv3_block4_1_conv, False\n",
      "Layer: conv3_block4_1_bn, False\n",
      "Layer: conv3_block4_1_relu, False\n",
      "Layer: conv3_block4_2_conv, False\n",
      "Layer: conv3_block4_2_bn, False\n",
      "Layer: conv3_block4_2_relu, False\n",
      "Layer: conv3_block4_3_conv, False\n",
      "Layer: conv3_block4_3_bn, False\n",
      "Layer: conv3_block4_add, False\n",
      "Layer: conv3_block4_out, False\n",
      "Layer: conv4_block1_1_conv, False\n",
      "Layer: conv4_block1_1_bn, False\n",
      "Layer: conv4_block1_1_relu, False\n",
      "Layer: conv4_block1_2_conv, False\n",
      "Layer: conv4_block1_2_bn, False\n",
      "Layer: conv4_block1_2_relu, False\n",
      "Layer: conv4_block1_0_conv, False\n",
      "Layer: conv4_block1_3_conv, False\n",
      "Layer: conv4_block1_0_bn, False\n",
      "Layer: conv4_block1_3_bn, False\n",
      "Layer: conv4_block1_add, False\n",
      "Layer: conv4_block1_out, False\n",
      "Layer: conv4_block2_1_conv, False\n",
      "Layer: conv4_block2_1_bn, False\n",
      "Layer: conv4_block2_1_relu, False\n",
      "Layer: conv4_block2_2_conv, False\n",
      "Layer: conv4_block2_2_bn, False\n",
      "Layer: conv4_block2_2_relu, False\n",
      "Layer: conv4_block2_3_conv, False\n",
      "Layer: conv4_block2_3_bn, False\n",
      "Layer: conv4_block2_add, False\n",
      "Layer: conv4_block2_out, False\n",
      "Layer: conv4_block3_1_conv, False\n",
      "Layer: conv4_block3_1_bn, False\n",
      "Layer: conv4_block3_1_relu, False\n",
      "Layer: conv4_block3_2_conv, False\n",
      "Layer: conv4_block3_2_bn, False\n",
      "Layer: conv4_block3_2_relu, False\n",
      "Layer: conv4_block3_3_conv, False\n",
      "Layer: conv4_block3_3_bn, False\n",
      "Layer: conv4_block3_add, False\n",
      "Layer: conv4_block3_out, False\n",
      "Layer: conv4_block4_1_conv, False\n",
      "Layer: conv4_block4_1_bn, False\n",
      "Layer: conv4_block4_1_relu, False\n",
      "Layer: conv4_block4_2_conv, False\n",
      "Layer: conv4_block4_2_bn, False\n",
      "Layer: conv4_block4_2_relu, False\n",
      "Layer: conv4_block4_3_conv, False\n",
      "Layer: conv4_block4_3_bn, False\n",
      "Layer: conv4_block4_add, False\n",
      "Layer: conv4_block4_out, False\n",
      "Layer: conv4_block5_1_conv, False\n",
      "Layer: conv4_block5_1_bn, False\n",
      "Layer: conv4_block5_1_relu, False\n",
      "Layer: conv4_block5_2_conv, False\n",
      "Layer: conv4_block5_2_bn, False\n",
      "Layer: conv4_block5_2_relu, False\n",
      "Layer: conv4_block5_3_conv, False\n",
      "Layer: conv4_block5_3_bn, False\n",
      "Layer: conv4_block5_add, False\n",
      "Layer: conv4_block5_out, False\n",
      "Layer: conv4_block6_1_conv, False\n",
      "Layer: conv4_block6_1_bn, False\n",
      "Layer: conv4_block6_1_relu, False\n",
      "Layer: conv4_block6_2_conv, False\n",
      "Layer: conv4_block6_2_bn, False\n",
      "Layer: conv4_block6_2_relu, False\n",
      "Layer: conv4_block6_3_conv, False\n",
      "Layer: conv4_block6_3_bn, False\n",
      "Layer: conv4_block6_add, False\n",
      "Layer: conv4_block6_out, False\n",
      "Layer: conv4_block7_1_conv, False\n",
      "Layer: conv4_block7_1_bn, False\n",
      "Layer: conv4_block7_1_relu, False\n",
      "Layer: conv4_block7_2_conv, False\n",
      "Layer: conv4_block7_2_bn, False\n",
      "Layer: conv4_block7_2_relu, False\n",
      "Layer: conv4_block7_3_conv, False\n",
      "Layer: conv4_block7_3_bn, False\n",
      "Layer: conv4_block7_add, False\n",
      "Layer: conv4_block7_out, False\n",
      "Layer: conv4_block8_1_conv, False\n",
      "Layer: conv4_block8_1_bn, False\n",
      "Layer: conv4_block8_1_relu, False\n",
      "Layer: conv4_block8_2_conv, False\n",
      "Layer: conv4_block8_2_bn, False\n",
      "Layer: conv4_block8_2_relu, False\n",
      "Layer: conv4_block8_3_conv, False\n",
      "Layer: conv4_block8_3_bn, False\n",
      "Layer: conv4_block8_add, False\n",
      "Layer: conv4_block8_out, False\n",
      "Layer: conv4_block9_1_conv, False\n",
      "Layer: conv4_block9_1_bn, False\n",
      "Layer: conv4_block9_1_relu, False\n",
      "Layer: conv4_block9_2_conv, False\n",
      "Layer: conv4_block9_2_bn, False\n",
      "Layer: conv4_block9_2_relu, False\n",
      "Layer: conv4_block9_3_conv, False\n",
      "Layer: conv4_block9_3_bn, False\n",
      "Layer: conv4_block9_add, False\n",
      "Layer: conv4_block9_out, False\n",
      "Layer: conv4_block10_1_conv, False\n",
      "Layer: conv4_block10_1_bn, False\n",
      "Layer: conv4_block10_1_relu, False\n",
      "Layer: conv4_block10_2_conv, False\n",
      "Layer: conv4_block10_2_bn, False\n",
      "Layer: conv4_block10_2_relu, False\n",
      "Layer: conv4_block10_3_conv, False\n",
      "Layer: conv4_block10_3_bn, False\n",
      "Layer: conv4_block10_add, False\n",
      "Layer: conv4_block10_out, False\n",
      "Layer: conv4_block11_1_conv, False\n",
      "Layer: conv4_block11_1_bn, False\n",
      "Layer: conv4_block11_1_relu, False\n",
      "Layer: conv4_block11_2_conv, False\n",
      "Layer: conv4_block11_2_bn, False\n",
      "Layer: conv4_block11_2_relu, False\n",
      "Layer: conv4_block11_3_conv, False\n",
      "Layer: conv4_block11_3_bn, False\n",
      "Layer: conv4_block11_add, False\n",
      "Layer: conv4_block11_out, False\n",
      "Layer: conv4_block12_1_conv, False\n",
      "Layer: conv4_block12_1_bn, False\n",
      "Layer: conv4_block12_1_relu, False\n",
      "Layer: conv4_block12_2_conv, False\n",
      "Layer: conv4_block12_2_bn, False\n",
      "Layer: conv4_block12_2_relu, False\n",
      "Layer: conv4_block12_3_conv, False\n",
      "Layer: conv4_block12_3_bn, False\n",
      "Layer: conv4_block12_add, False\n",
      "Layer: conv4_block12_out, False\n",
      "Layer: conv4_block13_1_conv, False\n",
      "Layer: conv4_block13_1_bn, False\n",
      "Layer: conv4_block13_1_relu, False\n",
      "Layer: conv4_block13_2_conv, False\n",
      "Layer: conv4_block13_2_bn, False\n",
      "Layer: conv4_block13_2_relu, False\n",
      "Layer: conv4_block13_3_conv, False\n",
      "Layer: conv4_block13_3_bn, False\n",
      "Layer: conv4_block13_add, False\n",
      "Layer: conv4_block13_out, False\n",
      "Layer: conv4_block14_1_conv, False\n",
      "Layer: conv4_block14_1_bn, False\n",
      "Layer: conv4_block14_1_relu, False\n",
      "Layer: conv4_block14_2_conv, False\n",
      "Layer: conv4_block14_2_bn, False\n",
      "Layer: conv4_block14_2_relu, False\n",
      "Layer: conv4_block14_3_conv, False\n",
      "Layer: conv4_block14_3_bn, False\n",
      "Layer: conv4_block14_add, False\n",
      "Layer: conv4_block14_out, False\n",
      "Layer: conv4_block15_1_conv, False\n",
      "Layer: conv4_block15_1_bn, False\n",
      "Layer: conv4_block15_1_relu, False\n",
      "Layer: conv4_block15_2_conv, False\n",
      "Layer: conv4_block15_2_bn, False\n",
      "Layer: conv4_block15_2_relu, False\n",
      "Layer: conv4_block15_3_conv, False\n",
      "Layer: conv4_block15_3_bn, False\n",
      "Layer: conv4_block15_add, False\n",
      "Layer: conv4_block15_out, False\n",
      "Layer: conv4_block16_1_conv, False\n",
      "Layer: conv4_block16_1_bn, False\n",
      "Layer: conv4_block16_1_relu, False\n",
      "Layer: conv4_block16_2_conv, False\n",
      "Layer: conv4_block16_2_bn, False\n",
      "Layer: conv4_block16_2_relu, False\n",
      "Layer: conv4_block16_3_conv, False\n",
      "Layer: conv4_block16_3_bn, False\n",
      "Layer: conv4_block16_add, False\n",
      "Layer: conv4_block16_out, False\n",
      "Layer: conv4_block17_1_conv, False\n",
      "Layer: conv4_block17_1_bn, False\n",
      "Layer: conv4_block17_1_relu, False\n",
      "Layer: conv4_block17_2_conv, False\n",
      "Layer: conv4_block17_2_bn, False\n",
      "Layer: conv4_block17_2_relu, False\n",
      "Layer: conv4_block17_3_conv, False\n",
      "Layer: conv4_block17_3_bn, False\n",
      "Layer: conv4_block17_add, False\n",
      "Layer: conv4_block17_out, False\n",
      "Layer: conv4_block18_1_conv, False\n",
      "Layer: conv4_block18_1_bn, False\n",
      "Layer: conv4_block18_1_relu, False\n",
      "Layer: conv4_block18_2_conv, False\n",
      "Layer: conv4_block18_2_bn, False\n",
      "Layer: conv4_block18_2_relu, False\n",
      "Layer: conv4_block18_3_conv, False\n",
      "Layer: conv4_block18_3_bn, False\n",
      "Layer: conv4_block18_add, False\n",
      "Layer: conv4_block18_out, False\n",
      "Layer: conv4_block19_1_conv, False\n",
      "Layer: conv4_block19_1_bn, False\n",
      "Layer: conv4_block19_1_relu, False\n",
      "Layer: conv4_block19_2_conv, False\n",
      "Layer: conv4_block19_2_bn, False\n",
      "Layer: conv4_block19_2_relu, False\n",
      "Layer: conv4_block19_3_conv, False\n",
      "Layer: conv4_block19_3_bn, False\n",
      "Layer: conv4_block19_add, False\n",
      "Layer: conv4_block19_out, False\n",
      "Layer: conv4_block20_1_conv, False\n",
      "Layer: conv4_block20_1_bn, False\n",
      "Layer: conv4_block20_1_relu, False\n",
      "Layer: conv4_block20_2_conv, False\n",
      "Layer: conv4_block20_2_bn, False\n",
      "Layer: conv4_block20_2_relu, False\n",
      "Layer: conv4_block20_3_conv, False\n",
      "Layer: conv4_block20_3_bn, False\n",
      "Layer: conv4_block20_add, False\n",
      "Layer: conv4_block20_out, False\n",
      "Layer: conv4_block21_1_conv, False\n",
      "Layer: conv4_block21_1_bn, False\n",
      "Layer: conv4_block21_1_relu, False\n",
      "Layer: conv4_block21_2_conv, False\n",
      "Layer: conv4_block21_2_bn, False\n",
      "Layer: conv4_block21_2_relu, False\n",
      "Layer: conv4_block21_3_conv, False\n",
      "Layer: conv4_block21_3_bn, False\n",
      "Layer: conv4_block21_add, False\n",
      "Layer: conv4_block21_out, False\n",
      "Layer: conv4_block22_1_conv, False\n",
      "Layer: conv4_block22_1_bn, False\n",
      "Layer: conv4_block22_1_relu, False\n",
      "Layer: conv4_block22_2_conv, False\n",
      "Layer: conv4_block22_2_bn, False\n",
      "Layer: conv4_block22_2_relu, False\n",
      "Layer: conv4_block22_3_conv, False\n",
      "Layer: conv4_block22_3_bn, False\n",
      "Layer: conv4_block22_add, False\n",
      "Layer: conv4_block22_out, False\n",
      "Layer: conv4_block23_1_conv, False\n",
      "Layer: conv4_block23_1_bn, False\n",
      "Layer: conv4_block23_1_relu, False\n",
      "Layer: conv4_block23_2_conv, False\n",
      "Layer: conv4_block23_2_bn, False\n",
      "Layer: conv4_block23_2_relu, False\n",
      "Layer: conv4_block23_3_conv, False\n",
      "Layer: conv4_block23_3_bn, False\n",
      "Layer: conv4_block23_add, False\n",
      "Layer: conv4_block23_out, False\n",
      "Layer: conv5_block1_1_conv, False\n",
      "Layer: conv5_block1_1_bn, False\n",
      "Layer: conv5_block1_1_relu, False\n",
      "Layer: conv5_block1_2_conv, False\n",
      "Layer: conv5_block1_2_bn, False\n",
      "Layer: conv5_block1_2_relu, False\n",
      "Layer: conv5_block1_0_conv, False\n",
      "Layer: conv5_block1_3_conv, False\n",
      "Layer: conv5_block1_0_bn, False\n",
      "Layer: conv5_block1_3_bn, False\n",
      "Layer: conv5_block1_add, False\n",
      "Layer: conv5_block1_out, False\n",
      "Layer: conv5_block2_1_conv, False\n",
      "Layer: conv5_block2_1_bn, False\n",
      "Layer: conv5_block2_1_relu, False\n",
      "Layer: conv5_block2_2_conv, False\n",
      "Layer: conv5_block2_2_bn, False\n",
      "Layer: conv5_block2_2_relu, False\n",
      "Layer: conv5_block2_3_conv, False\n",
      "Layer: conv5_block2_3_bn, False\n",
      "Layer: conv5_block2_add, False\n",
      "Layer: conv5_block2_out, False\n",
      "Layer: conv5_block3_1_conv, False\n",
      "Layer: conv5_block3_1_bn, False\n",
      "Layer: conv5_block3_1_relu, False\n",
      "Layer: conv5_block3_2_conv, False\n",
      "Layer: conv5_block3_2_bn, False\n",
      "Layer: conv5_block3_2_relu, False\n",
      "Layer: conv5_block3_3_conv, False\n",
      "Layer: conv5_block3_3_bn, False\n",
      "Layer: conv5_block3_add, False\n",
      "Layer: conv5_block3_out, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:17.089734Z",
     "start_time": "2024-07-29T19:18:17.083428Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:17.975048Z",
     "start_time": "2024-07-29T19:18:17.972469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:19.815181Z",
     "start_time": "2024-07-29T19:18:19.809918Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:30.625394Z",
     "start_time": "2024-07-29T19:18:30.059842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "x = aug_layer(inputs)\n",
    "#x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'Resnet_101')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet101 (Functional)      (None, 7, 7, 2048)        42658176  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 2048)              8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43892036 (167.43 MB)\n",
      "Trainable params: 1227844 (4.68 MB)\n",
      "Non-trainable params: 42664192 (162.75 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:32.399235Z",
     "start_time": "2024-07-29T19:18:32.396757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models',model_1.name), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:32.668727Z",
     "start_time": "2024-07-29T19:18:32.666651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=3) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:18:33.007470Z",
     "start_time": "2024-07-29T19:18:32.988904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:27:31.287105Z",
     "start_time": "2024-07-29T19:18:36.489743Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 20, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:18:40.540701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-29 15:18:40.625690: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-29 15:18:41.858140: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x732e74003470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-29 15:18:41.858179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-29 15:18:41.864962: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-29 15:18:41.937167: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 13.2548 - accuracy: 0.5909\n",
      "Epoch 1: val_loss improved from inf to 11.26959, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 53s 651ms/step - loss: 13.2548 - accuracy: 0.5909 - val_loss: 11.2696 - val_accuracy: 0.2502 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.1726 - accuracy: 0.7501\n",
      "Epoch 2: val_loss improved from 11.26959 to 6.44356, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 38s 517ms/step - loss: 8.1726 - accuracy: 0.7501 - val_loss: 6.4436 - val_accuracy: 0.6518 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.9559 - accuracy: 0.7726\n",
      "Epoch 3: val_loss improved from 6.44356 to 4.37699, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 37s 494ms/step - loss: 4.9559 - accuracy: 0.7726 - val_loss: 4.3770 - val_accuracy: 0.3848 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 3.2377 - accuracy: 0.7768\n",
      "Epoch 4: val_loss improved from 4.37699 to 2.69517, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 36s 479ms/step - loss: 3.2377 - accuracy: 0.7768 - val_loss: 2.6952 - val_accuracy: 0.7715 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.3135 - accuracy: 0.7768\n",
      "Epoch 5: val_loss improved from 2.69517 to 2.30318, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 34s 461ms/step - loss: 2.3135 - accuracy: 0.7768 - val_loss: 2.3032 - val_accuracy: 0.6202 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.7437 - accuracy: 0.7946\n",
      "Epoch 6: val_loss improved from 2.30318 to 2.02195, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 35s 474ms/step - loss: 1.7437 - accuracy: 0.7946 - val_loss: 2.0219 - val_accuracy: 0.4372 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.4787 - accuracy: 0.7878\n",
      "Epoch 7: val_loss improved from 2.02195 to 1.56987, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 34s 459ms/step - loss: 1.4787 - accuracy: 0.7878 - val_loss: 1.5699 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2828 - accuracy: 0.7984\n",
      "Epoch 8: val_loss improved from 1.56987 to 1.28226, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 31s 422ms/step - loss: 1.2828 - accuracy: 0.7984 - val_loss: 1.2823 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2014 - accuracy: 0.7734\n",
      "Epoch 9: val_loss improved from 1.28226 to 0.87851, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 31s 423ms/step - loss: 1.2014 - accuracy: 0.7734 - val_loss: 0.8785 - val_accuracy: 0.9337 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1152 - accuracy: 0.7844\n",
      "Epoch 10: val_loss did not improve from 0.87851\n",
      "74/74 [==============================] - 16s 207ms/step - loss: 1.1152 - accuracy: 0.7844 - val_loss: 1.0226 - val_accuracy: 0.8605 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.7793\n",
      "Epoch 11: val_loss improved from 0.87851 to 0.87804, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 30s 408ms/step - loss: 1.0870 - accuracy: 0.7793 - val_loss: 0.8780 - val_accuracy: 0.8605 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0148 - accuracy: 0.7967\n",
      "Epoch 12: val_loss did not improve from 0.87804\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 1.0148 - accuracy: 0.7967 - val_loss: 1.1134 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0425 - accuracy: 0.7848\n",
      "Epoch 13: val_loss did not improve from 0.87804\n",
      "74/74 [==============================] - 15s 199ms/step - loss: 1.0425 - accuracy: 0.7848 - val_loss: 1.4785 - val_accuracy: 0.5183 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0381 - accuracy: 0.7781\n",
      "Epoch 14: val_loss did not improve from 0.87804\n",
      "74/74 [==============================] - 15s 197ms/step - loss: 1.0381 - accuracy: 0.7781 - val_loss: 1.0805 - val_accuracy: 0.7498 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.8136\n",
      "Epoch 15: val_loss did not improve from 0.87804\n",
      "74/74 [==============================] - 14s 182ms/step - loss: 0.8628 - accuracy: 0.8136 - val_loss: 1.2253 - val_accuracy: 0.5262 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7738 - accuracy: 0.8323\n",
      "Epoch 16: val_loss improved from 0.87804 to 0.74767, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 29s 389ms/step - loss: 0.7738 - accuracy: 0.8323 - val_loss: 0.7477 - val_accuracy: 0.8388 - lr: 3.0000e-04\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7175 - accuracy: 0.8374\n",
      "Epoch 17: val_loss did not improve from 0.74767\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 0.7175 - accuracy: 0.8374 - val_loss: 0.9873 - val_accuracy: 0.6528 - lr: 3.0000e-04\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.8378\n",
      "Epoch 18: val_loss improved from 0.74767 to 0.70119, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 29s 391ms/step - loss: 0.6849 - accuracy: 0.8378 - val_loss: 0.7012 - val_accuracy: 0.8457 - lr: 3.0000e-04\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.8395\n",
      "Epoch 19: val_loss did not improve from 0.70119\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 0.6896 - accuracy: 0.8395 - val_loss: 1.1097 - val_accuracy: 0.6231 - lr: 3.0000e-04\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.8247\n",
      "Epoch 20: val_loss did not improve from 0.70119\n",
      "74/74 [==============================] - 14s 178ms/step - loss: 0.7059 - accuracy: 0.8247 - val_loss: 1.1510 - val_accuracy: 0.5796 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:27:59.614629Z",
     "start_time": "2024-07-29T19:27:57.802074Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "eb9cc0053cd28662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 63ms/step - loss: 0.9564 - accuracy: 0.7065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9563683867454529, 0.7065088748931885]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:28:04.837798Z",
     "start_time": "2024-07-29T19:28:04.831875Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:28:05.197434Z",
     "start_time": "2024-07-29T19:28:05.191896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-25]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:28:05.594811Z",
     "start_time": "2024-07-29T19:28:05.591486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:28:13.706200Z",
     "start_time": "2024-07-29T19:28:13.676156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 20\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet101 (Functional)      (None, 7, 7, 2048)        42658176  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 2048)              8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43892036 (167.43 MB)\n",
      "Trainable params: 11217988 (42.79 MB)\n",
      "Non-trainable params: 32674048 (124.64 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:29:59.505994Z",
     "start_time": "2024-07-29T19:28:14.516513Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1102 - accuracy: 0.7039\n",
      "Epoch 21: val_loss did not improve from 0.70119\n",
      "74/74 [==============================] - 24s 258ms/step - loss: 1.1102 - accuracy: 0.7039 - val_loss: 0.8146 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8287 - accuracy: 0.7552\n",
      "Epoch 22: val_loss improved from 0.70119 to 0.42129, saving model to Trained_Models/Resnet_101\n",
      "74/74 [==============================] - 30s 400ms/step - loss: 0.8287 - accuracy: 0.7552 - val_loss: 0.4213 - val_accuracy: 0.9139 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.7916\n",
      "Epoch 23: val_loss did not improve from 0.42129\n",
      "74/74 [==============================] - 15s 192ms/step - loss: 0.7217 - accuracy: 0.7916 - val_loss: 0.7701 - val_accuracy: 0.6578 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7062 - accuracy: 0.7942\n",
      "Epoch 24: val_loss did not improve from 0.42129\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 0.7062 - accuracy: 0.7942 - val_loss: 0.8193 - val_accuracy: 0.7507 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - ETA: 0s - loss: nan - accuracy: 0.7891\n",
      "Epoch 25: val_loss did not improve from 0.42129\n",
      "74/74 [==============================] - 14s 188ms/step - loss: nan - accuracy: 0.7891 - val_loss: nan - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "37/74 [==============>...............] - ETA: 5s - loss: nan - accuracy: 0.8024"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history_50 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_1chkpt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:05.280153Z",
     "start_time": "2024-07-29T19:30:03.720628Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "629d0435a43b82c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 54ms/step - loss: nan - accuracy: 0.2462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.2461538463830948]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:22:41.342727Z",
     "start_time": "2024-07-29T17:22:41.339631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 20\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:22:41.887061Z",
     "start_time": "2024-07-29T17:22:41.846397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24821572 (94.69 MB)\n",
      "Trainable params: 20680772 (78.89 MB)\n",
      "Non-trainable params: 4140800 (15.80 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T17:22:50.773611Z",
     "start_time": "2024-07-29T17:22:43.071007Z"
    }
   },
   "cell_type": "code",
   "source": "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "47/74 [==================>...........] - ETA: 1s - loss: nan - accuracy: 0.2513"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history_100 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_1chkpt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:49:11.117505Z",
     "start_time": "2024-07-25T23:49:11.111064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 30\n",
    "for layer in base_model.layers[-300:]:\n",
    "    layer.trainable = True"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:49:11.194870Z",
     "start_time": "2024-07-25T23:49:11.118218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00009), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 45484484 (173.51 MB)\n",
      "Non-trainable params: 13452416 (51.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:54:03.897112Z",
     "start_time": "2024-07-25T23:49:11.195700Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.8619\n",
      "Epoch 31: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 54s 291ms/step - loss: 0.4440 - accuracy: 0.8619 - val_loss: 0.1423 - val_accuracy: 0.9594 - lr: 9.0000e-05\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.8937\n",
      "Epoch 32: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 19s 256ms/step - loss: 0.3214 - accuracy: 0.8937 - val_loss: 0.1051 - val_accuracy: 0.9674 - lr: 9.0000e-05\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.8967\n",
      "Epoch 33: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 20s 266ms/step - loss: 0.3136 - accuracy: 0.8967 - val_loss: 0.2196 - val_accuracy: 0.9357 - lr: 9.0000e-05\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.8920\n",
      "Epoch 34: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 19s 258ms/step - loss: 0.3187 - accuracy: 0.8920 - val_loss: 0.1450 - val_accuracy: 0.9664 - lr: 9.0000e-05\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9153\n",
      "Epoch 35: val_loss improved from 0.08031 to 0.07935, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 56s 753ms/step - loss: 0.2571 - accuracy: 0.9153 - val_loss: 0.0793 - val_accuracy: 0.9713 - lr: 9.0000e-05\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.9030\n",
      "Epoch 36: val_loss did not improve from 0.07935\n",
      "74/74 [==============================] - 20s 268ms/step - loss: 0.3020 - accuracy: 0.9030 - val_loss: 0.1073 - val_accuracy: 0.9723 - lr: 9.0000e-05\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9225\n",
      "Epoch 37: val_loss improved from 0.07935 to 0.05755, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 48s 644ms/step - loss: 0.2405 - accuracy: 0.9225 - val_loss: 0.0576 - val_accuracy: 0.9832 - lr: 9.0000e-05\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9178\n",
      "Epoch 38: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 18s 243ms/step - loss: 0.2280 - accuracy: 0.9178 - val_loss: 0.1797 - val_accuracy: 0.9525 - lr: 9.0000e-05\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2480 - accuracy: 0.9166\n",
      "Epoch 39: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 18s 241ms/step - loss: 0.2480 - accuracy: 0.9166 - val_loss: 0.0798 - val_accuracy: 0.9753 - lr: 9.0000e-05\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.9322\n",
      "Epoch 40: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 20s 265ms/step - loss: 0.2166 - accuracy: 0.9322 - val_loss: 0.1572 - val_accuracy: 0.9594 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:54:03.906374Z",
     "start_time": "2024-07-25T23:54:03.898184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 40\n",
    "for layer in base_model.layers[-450:]:\n",
    "    layer.trainable = True"
   ],
   "id": "5a4cd9a6567e4701",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:54:03.970717Z",
     "start_time": "2024-07-25T23:54:03.907078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00005), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "23a1c345daf87a3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 57683652 (220.05 MB)\n",
      "Non-trainable params: 1253248 (4.78 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:59:37.318129Z",
     "start_time": "2024-07-25T23:54:08.797812Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "6d8eb63102e1de90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.9000\n",
      "Epoch 41: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 84s 489ms/step - loss: 0.3006 - accuracy: 0.9000 - val_loss: 0.1595 - val_accuracy: 0.9555 - lr: 5.0000e-05\n",
      "Epoch 42/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9238\n",
      "Epoch 42: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 29s 388ms/step - loss: 0.2307 - accuracy: 0.9238 - val_loss: 0.0795 - val_accuracy: 0.9743 - lr: 5.0000e-05\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9327\n",
      "Epoch 43: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 27s 355ms/step - loss: 0.2274 - accuracy: 0.9327 - val_loss: 0.0609 - val_accuracy: 0.9842 - lr: 5.0000e-05\n",
      "Epoch 44/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.8916\n",
      "Epoch 44: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 25s 337ms/step - loss: 0.3318 - accuracy: 0.8916 - val_loss: 0.1507 - val_accuracy: 0.9525 - lr: 5.0000e-05\n",
      "Epoch 45/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.9187\n",
      "Epoch 45: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 24s 324ms/step - loss: 0.2501 - accuracy: 0.9187 - val_loss: 0.0856 - val_accuracy: 0.9723 - lr: 5.0000e-05\n",
      "Epoch 46/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9411\n",
      "Epoch 46: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 23s 305ms/step - loss: 0.1764 - accuracy: 0.9411 - val_loss: 0.1330 - val_accuracy: 0.9674 - lr: 5.0000e-05\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9593\n",
      "Epoch 47: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 24s 313ms/step - loss: 0.1448 - accuracy: 0.9593 - val_loss: 0.0819 - val_accuracy: 0.9693 - lr: 1.5000e-05\n",
      "Epoch 48/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9636\n",
      "Epoch 48: val_loss improved from 0.05755 to 0.04952, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 50s 681ms/step - loss: 0.1125 - accuracy: 0.9636 - val_loss: 0.0495 - val_accuracy: 0.9842 - lr: 1.5000e-05\n",
      "Epoch 49/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9678\n",
      "Epoch 49: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 21s 279ms/step - loss: 0.0960 - accuracy: 0.9678 - val_loss: 0.0886 - val_accuracy: 0.9723 - lr: 1.5000e-05\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9695\n",
      "Epoch 50: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 21s 280ms/step - loss: 0.0953 - accuracy: 0.9695 - val_loss: 0.0846 - val_accuracy: 0.9713 - lr: 1.5000e-05\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:01:09.040648Z",
     "start_time": "2024-07-26T00:01:09.032554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 50\n",
    "for layer in base_model.layers[-510:]:\n",
    "    layer.trainable = True"
   ],
   "id": "93ad3cc030c9c69",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:01:14.096107Z",
     "start_time": "2024-07-26T00:01:14.039694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000005), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "9ed4bf4a63f90d77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 58775876 (224.21 MB)\n",
      "Non-trainable params: 161024 (629.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:04:45.822727Z",
     "start_time": "2024-07-26T00:01:22.262325Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "b0794490c20e0209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9788\n",
      "Epoch 51: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 86s 581ms/step - loss: 0.0817 - accuracy: 0.9788 - val_loss: 0.0766 - val_accuracy: 0.9773 - lr: 5.0000e-06\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9818\n",
      "Epoch 52: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 39s 521ms/step - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.1039 - val_accuracy: 0.9753 - lr: 5.0000e-06\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9818\n",
      "Epoch 53: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 38s 506ms/step - loss: 0.0651 - accuracy: 0.9818 - val_loss: 0.0727 - val_accuracy: 0.9763 - lr: 5.0000e-06\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9792\n",
      "Epoch 54: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 34s 447ms/step - loss: 0.0696 - accuracy: 0.9792 - val_loss: 0.0556 - val_accuracy: 0.9792 - lr: 5.0000e-06\n",
      "Epoch 55/60\n",
      "10/74 [===>..........................] - ETA: 34s - loss: 0.0599 - accuracy: 0.9812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history_500 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_1chkpt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:05:26.202107Z",
     "start_time": "2024-07-26T00:05:11.958054Z"
    }
   },
   "cell_type": "code",
   "source": "resnet = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:05:46.917207Z",
     "start_time": "2024-07-26T00:05:44.665455Z"
    }
   },
   "cell_type": "code",
   "source": "resnet.evaluate(val_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 67ms/step - loss: 0.0495 - accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04952496290206909, 0.9841740727424622]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
