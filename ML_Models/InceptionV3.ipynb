{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:53:28.866580Z",
     "start_time": "2024-07-25T21:53:27.136332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 17:53:27.282976: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 17:53:27.308454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 17:53:27.308479: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 17:53:27.308497: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 17:53:27.313866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 17:53:27.884693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 17:53:28.831147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:28.856217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:28.858857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:28.861851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:53:28.872108Z",
     "start_time": "2024-07-25T21:53:28.867623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:53:28.879441Z",
     "start_time": "2024-07-25T21:53:28.872789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:53:29.123822Z",
     "start_time": "2024-07-25T21:53:29.120872Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'mild_dr', 'hypertensive_retinopathy', 'normal_fundus', 'cataract', 'moderate_dr', 'proliferate_dr', 'severe_dr', 'dry_amd', 'wet_amd', 'pathological_myopia']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:53:30.035696Z",
     "start_time": "2024-07-25T21:53:30.033050Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:53:33.589675Z",
     "start_time": "2024-07-25T21:53:32.174890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16269 files belonging to 11 classes.\n",
      "Using 11389 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 17:53:32.449723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:32.451303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:32.452603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:32.556411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:32.557747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:32.559367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 17:53:32.560611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1148 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-25 17:53:32.666313: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16269 files belonging to 11 classes.\n",
      "Using 4880 files for validation.\n",
      "Found 5428 files belonging to 11 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:05.765868Z",
     "start_time": "2024-07-25T21:55:05.763155Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 11), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:11.236204Z",
     "start_time": "2024-07-25T21:55:11.233735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.inception_v3.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:13.226240Z",
     "start_time": "2024-07-25T21:55:13.189592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:13.646540Z",
     "start_time": "2024-07-25T21:55:13.643449Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 11), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:19.559524Z",
     "start_time": "2024-07-25T21:55:18.124659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.InceptionV3(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:19.851785Z",
     "start_time": "2024-07-25T21:55:19.847750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: conv2d, False\n",
      "Layer: batch_normalization, False\n",
      "Layer: activation, False\n",
      "Layer: conv2d_1, False\n",
      "Layer: batch_normalization_1, False\n",
      "Layer: activation_1, False\n",
      "Layer: conv2d_2, False\n",
      "Layer: batch_normalization_2, False\n",
      "Layer: activation_2, False\n",
      "Layer: max_pooling2d, False\n",
      "Layer: conv2d_3, False\n",
      "Layer: batch_normalization_3, False\n",
      "Layer: activation_3, False\n",
      "Layer: conv2d_4, False\n",
      "Layer: batch_normalization_4, False\n",
      "Layer: activation_4, False\n",
      "Layer: max_pooling2d_1, False\n",
      "Layer: conv2d_8, False\n",
      "Layer: batch_normalization_8, False\n",
      "Layer: activation_8, False\n",
      "Layer: conv2d_6, False\n",
      "Layer: conv2d_9, False\n",
      "Layer: batch_normalization_6, False\n",
      "Layer: batch_normalization_9, False\n",
      "Layer: activation_6, False\n",
      "Layer: activation_9, False\n",
      "Layer: average_pooling2d, False\n",
      "Layer: conv2d_5, False\n",
      "Layer: conv2d_7, False\n",
      "Layer: conv2d_10, False\n",
      "Layer: conv2d_11, False\n",
      "Layer: batch_normalization_5, False\n",
      "Layer: batch_normalization_7, False\n",
      "Layer: batch_normalization_10, False\n",
      "Layer: batch_normalization_11, False\n",
      "Layer: activation_5, False\n",
      "Layer: activation_7, False\n",
      "Layer: activation_10, False\n",
      "Layer: activation_11, False\n",
      "Layer: mixed0, False\n",
      "Layer: conv2d_15, False\n",
      "Layer: batch_normalization_15, False\n",
      "Layer: activation_15, False\n",
      "Layer: conv2d_13, False\n",
      "Layer: conv2d_16, False\n",
      "Layer: batch_normalization_13, False\n",
      "Layer: batch_normalization_16, False\n",
      "Layer: activation_13, False\n",
      "Layer: activation_16, False\n",
      "Layer: average_pooling2d_1, False\n",
      "Layer: conv2d_12, False\n",
      "Layer: conv2d_14, False\n",
      "Layer: conv2d_17, False\n",
      "Layer: conv2d_18, False\n",
      "Layer: batch_normalization_12, False\n",
      "Layer: batch_normalization_14, False\n",
      "Layer: batch_normalization_17, False\n",
      "Layer: batch_normalization_18, False\n",
      "Layer: activation_12, False\n",
      "Layer: activation_14, False\n",
      "Layer: activation_17, False\n",
      "Layer: activation_18, False\n",
      "Layer: mixed1, False\n",
      "Layer: conv2d_22, False\n",
      "Layer: batch_normalization_22, False\n",
      "Layer: activation_22, False\n",
      "Layer: conv2d_20, False\n",
      "Layer: conv2d_23, False\n",
      "Layer: batch_normalization_20, False\n",
      "Layer: batch_normalization_23, False\n",
      "Layer: activation_20, False\n",
      "Layer: activation_23, False\n",
      "Layer: average_pooling2d_2, False\n",
      "Layer: conv2d_19, False\n",
      "Layer: conv2d_21, False\n",
      "Layer: conv2d_24, False\n",
      "Layer: conv2d_25, False\n",
      "Layer: batch_normalization_19, False\n",
      "Layer: batch_normalization_21, False\n",
      "Layer: batch_normalization_24, False\n",
      "Layer: batch_normalization_25, False\n",
      "Layer: activation_19, False\n",
      "Layer: activation_21, False\n",
      "Layer: activation_24, False\n",
      "Layer: activation_25, False\n",
      "Layer: mixed2, False\n",
      "Layer: conv2d_27, False\n",
      "Layer: batch_normalization_27, False\n",
      "Layer: activation_27, False\n",
      "Layer: conv2d_28, False\n",
      "Layer: batch_normalization_28, False\n",
      "Layer: activation_28, False\n",
      "Layer: conv2d_26, False\n",
      "Layer: conv2d_29, False\n",
      "Layer: batch_normalization_26, False\n",
      "Layer: batch_normalization_29, False\n",
      "Layer: activation_26, False\n",
      "Layer: activation_29, False\n",
      "Layer: max_pooling2d_2, False\n",
      "Layer: mixed3, False\n",
      "Layer: conv2d_34, False\n",
      "Layer: batch_normalization_34, False\n",
      "Layer: activation_34, False\n",
      "Layer: conv2d_35, False\n",
      "Layer: batch_normalization_35, False\n",
      "Layer: activation_35, False\n",
      "Layer: conv2d_31, False\n",
      "Layer: conv2d_36, False\n",
      "Layer: batch_normalization_31, False\n",
      "Layer: batch_normalization_36, False\n",
      "Layer: activation_31, False\n",
      "Layer: activation_36, False\n",
      "Layer: conv2d_32, False\n",
      "Layer: conv2d_37, False\n",
      "Layer: batch_normalization_32, False\n",
      "Layer: batch_normalization_37, False\n",
      "Layer: activation_32, False\n",
      "Layer: activation_37, False\n",
      "Layer: average_pooling2d_3, False\n",
      "Layer: conv2d_30, False\n",
      "Layer: conv2d_33, False\n",
      "Layer: conv2d_38, False\n",
      "Layer: conv2d_39, False\n",
      "Layer: batch_normalization_30, False\n",
      "Layer: batch_normalization_33, False\n",
      "Layer: batch_normalization_38, False\n",
      "Layer: batch_normalization_39, False\n",
      "Layer: activation_30, False\n",
      "Layer: activation_33, False\n",
      "Layer: activation_38, False\n",
      "Layer: activation_39, False\n",
      "Layer: mixed4, False\n",
      "Layer: conv2d_44, False\n",
      "Layer: batch_normalization_44, False\n",
      "Layer: activation_44, False\n",
      "Layer: conv2d_45, False\n",
      "Layer: batch_normalization_45, False\n",
      "Layer: activation_45, False\n",
      "Layer: conv2d_41, False\n",
      "Layer: conv2d_46, False\n",
      "Layer: batch_normalization_41, False\n",
      "Layer: batch_normalization_46, False\n",
      "Layer: activation_41, False\n",
      "Layer: activation_46, False\n",
      "Layer: conv2d_42, False\n",
      "Layer: conv2d_47, False\n",
      "Layer: batch_normalization_42, False\n",
      "Layer: batch_normalization_47, False\n",
      "Layer: activation_42, False\n",
      "Layer: activation_47, False\n",
      "Layer: average_pooling2d_4, False\n",
      "Layer: conv2d_40, False\n",
      "Layer: conv2d_43, False\n",
      "Layer: conv2d_48, False\n",
      "Layer: conv2d_49, False\n",
      "Layer: batch_normalization_40, False\n",
      "Layer: batch_normalization_43, False\n",
      "Layer: batch_normalization_48, False\n",
      "Layer: batch_normalization_49, False\n",
      "Layer: activation_40, False\n",
      "Layer: activation_43, False\n",
      "Layer: activation_48, False\n",
      "Layer: activation_49, False\n",
      "Layer: mixed5, False\n",
      "Layer: conv2d_54, False\n",
      "Layer: batch_normalization_54, False\n",
      "Layer: activation_54, False\n",
      "Layer: conv2d_55, False\n",
      "Layer: batch_normalization_55, False\n",
      "Layer: activation_55, False\n",
      "Layer: conv2d_51, False\n",
      "Layer: conv2d_56, False\n",
      "Layer: batch_normalization_51, False\n",
      "Layer: batch_normalization_56, False\n",
      "Layer: activation_51, False\n",
      "Layer: activation_56, False\n",
      "Layer: conv2d_52, False\n",
      "Layer: conv2d_57, False\n",
      "Layer: batch_normalization_52, False\n",
      "Layer: batch_normalization_57, False\n",
      "Layer: activation_52, False\n",
      "Layer: activation_57, False\n",
      "Layer: average_pooling2d_5, False\n",
      "Layer: conv2d_50, False\n",
      "Layer: conv2d_53, False\n",
      "Layer: conv2d_58, False\n",
      "Layer: conv2d_59, False\n",
      "Layer: batch_normalization_50, False\n",
      "Layer: batch_normalization_53, False\n",
      "Layer: batch_normalization_58, False\n",
      "Layer: batch_normalization_59, False\n",
      "Layer: activation_50, False\n",
      "Layer: activation_53, False\n",
      "Layer: activation_58, False\n",
      "Layer: activation_59, False\n",
      "Layer: mixed6, False\n",
      "Layer: conv2d_64, False\n",
      "Layer: batch_normalization_64, False\n",
      "Layer: activation_64, False\n",
      "Layer: conv2d_65, False\n",
      "Layer: batch_normalization_65, False\n",
      "Layer: activation_65, False\n",
      "Layer: conv2d_61, False\n",
      "Layer: conv2d_66, False\n",
      "Layer: batch_normalization_61, False\n",
      "Layer: batch_normalization_66, False\n",
      "Layer: activation_61, False\n",
      "Layer: activation_66, False\n",
      "Layer: conv2d_62, False\n",
      "Layer: conv2d_67, False\n",
      "Layer: batch_normalization_62, False\n",
      "Layer: batch_normalization_67, False\n",
      "Layer: activation_62, False\n",
      "Layer: activation_67, False\n",
      "Layer: average_pooling2d_6, False\n",
      "Layer: conv2d_60, False\n",
      "Layer: conv2d_63, False\n",
      "Layer: conv2d_68, False\n",
      "Layer: conv2d_69, False\n",
      "Layer: batch_normalization_60, False\n",
      "Layer: batch_normalization_63, False\n",
      "Layer: batch_normalization_68, False\n",
      "Layer: batch_normalization_69, False\n",
      "Layer: activation_60, False\n",
      "Layer: activation_63, False\n",
      "Layer: activation_68, False\n",
      "Layer: activation_69, False\n",
      "Layer: mixed7, False\n",
      "Layer: conv2d_72, False\n",
      "Layer: batch_normalization_72, False\n",
      "Layer: activation_72, False\n",
      "Layer: conv2d_73, False\n",
      "Layer: batch_normalization_73, False\n",
      "Layer: activation_73, False\n",
      "Layer: conv2d_70, False\n",
      "Layer: conv2d_74, False\n",
      "Layer: batch_normalization_70, False\n",
      "Layer: batch_normalization_74, False\n",
      "Layer: activation_70, False\n",
      "Layer: activation_74, False\n",
      "Layer: conv2d_71, False\n",
      "Layer: conv2d_75, False\n",
      "Layer: batch_normalization_71, False\n",
      "Layer: batch_normalization_75, False\n",
      "Layer: activation_71, False\n",
      "Layer: activation_75, False\n",
      "Layer: max_pooling2d_3, False\n",
      "Layer: mixed8, False\n",
      "Layer: conv2d_80, False\n",
      "Layer: batch_normalization_80, False\n",
      "Layer: activation_80, False\n",
      "Layer: conv2d_77, False\n",
      "Layer: conv2d_81, False\n",
      "Layer: batch_normalization_77, False\n",
      "Layer: batch_normalization_81, False\n",
      "Layer: activation_77, False\n",
      "Layer: activation_81, False\n",
      "Layer: conv2d_78, False\n",
      "Layer: conv2d_79, False\n",
      "Layer: conv2d_82, False\n",
      "Layer: conv2d_83, False\n",
      "Layer: average_pooling2d_7, False\n",
      "Layer: conv2d_76, False\n",
      "Layer: batch_normalization_78, False\n",
      "Layer: batch_normalization_79, False\n",
      "Layer: batch_normalization_82, False\n",
      "Layer: batch_normalization_83, False\n",
      "Layer: conv2d_84, False\n",
      "Layer: batch_normalization_76, False\n",
      "Layer: activation_78, False\n",
      "Layer: activation_79, False\n",
      "Layer: activation_82, False\n",
      "Layer: activation_83, False\n",
      "Layer: batch_normalization_84, False\n",
      "Layer: activation_76, False\n",
      "Layer: mixed9_0, False\n",
      "Layer: concatenate, False\n",
      "Layer: activation_84, False\n",
      "Layer: mixed9, False\n",
      "Layer: conv2d_89, False\n",
      "Layer: batch_normalization_89, False\n",
      "Layer: activation_89, False\n",
      "Layer: conv2d_86, False\n",
      "Layer: conv2d_90, False\n",
      "Layer: batch_normalization_86, False\n",
      "Layer: batch_normalization_90, False\n",
      "Layer: activation_86, False\n",
      "Layer: activation_90, False\n",
      "Layer: conv2d_87, False\n",
      "Layer: conv2d_88, False\n",
      "Layer: conv2d_91, False\n",
      "Layer: conv2d_92, False\n",
      "Layer: average_pooling2d_8, False\n",
      "Layer: conv2d_85, False\n",
      "Layer: batch_normalization_87, False\n",
      "Layer: batch_normalization_88, False\n",
      "Layer: batch_normalization_91, False\n",
      "Layer: batch_normalization_92, False\n",
      "Layer: conv2d_93, False\n",
      "Layer: batch_normalization_85, False\n",
      "Layer: activation_87, False\n",
      "Layer: activation_88, False\n",
      "Layer: activation_91, False\n",
      "Layer: activation_92, False\n",
      "Layer: batch_normalization_93, False\n",
      "Layer: activation_85, False\n",
      "Layer: mixed9_1, False\n",
      "Layer: concatenate_1, False\n",
      "Layer: activation_93, False\n",
      "Layer: mixed10, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:24.814260Z",
     "start_time": "2024-07-25T21:55:24.810808Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:30.293054Z",
     "start_time": "2024-07-25T21:55:30.290067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:55:43.683113Z",
     "start_time": "2024-07-25T21:55:43.270082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "x = base_model(inputs, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'EfficientB7')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23280171 (88.81 MB)\n",
      "Trainable params: 1477387 (5.64 MB)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:56:30.878656Z",
     "start_time": "2024-07-25T21:56:30.875875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models','InceptionV3'), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:56:31.150996Z",
     "start_time": "2024-07-25T21:56:31.148581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=2) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:56:31.476075Z",
     "start_time": "2024-07-25T21:56:31.468001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-25T21:56:32.212943Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 10, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "356/356 [==============================] - ETA: 0s - loss: 1.4852 - accuracy: 0.4501\n",
      "Epoch 1: val_loss improved from inf to 1.44878, saving model to Trained_Models/InceptionV3\n",
      "356/356 [==============================] - 27s 69ms/step - loss: 1.4852 - accuracy: 0.4501 - val_loss: 1.4488 - val_accuracy: 0.4059 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/356 [============================>.] - ETA: 0s - loss: 1.3989 - accuracy: 0.4740\n",
      "Epoch 2: val_loss improved from 1.44878 to 1.29696, saving model to Trained_Models/InceptionV3\n",
      "356/356 [==============================] - 24s 67ms/step - loss: 1.3988 - accuracy: 0.4740 - val_loss: 1.2970 - val_accuracy: 0.4877 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/356 [============================>.] - ETA: 0s - loss: 1.3461 - accuracy: 0.4823\n",
      "Epoch 3: val_loss did not improve from 1.29696\n",
      "356/356 [==============================] - 14s 38ms/step - loss: 1.3456 - accuracy: 0.4824 - val_loss: 1.3721 - val_accuracy: 0.4299 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "354/356 [============================>.] - ETA: 0s - loss: 1.3181 - accuracy: 0.4946\n",
      "Epoch 4: val_loss did not improve from 1.29696\n",
      "356/356 [==============================] - 13s 38ms/step - loss: 1.3181 - accuracy: 0.4951 - val_loss: 1.3062 - val_accuracy: 0.4752 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "355/356 [============================>.] - ETA: 0s - loss: 1.2353 - accuracy: 0.5112\n",
      "Epoch 5: val_loss improved from 1.29696 to 1.27226, saving model to Trained_Models/InceptionV3\n",
      "356/356 [==============================] - 25s 69ms/step - loss: 1.2355 - accuracy: 0.5110 - val_loss: 1.2723 - val_accuracy: 0.4645 - lr: 3.0000e-04\n",
      "Epoch 6/10\n",
      "355/356 [============================>.] - ETA: 0s - loss: 1.1937 - accuracy: 0.5225\n",
      "Epoch 6: val_loss improved from 1.27226 to 1.21082, saving model to Trained_Models/InceptionV3\n",
      "356/356 [==============================] - 28s 80ms/step - loss: 1.1938 - accuracy: 0.5223 - val_loss: 1.2108 - val_accuracy: 0.5076 - lr: 3.0000e-04\n",
      "Epoch 7/10\n",
      "355/356 [============================>.] - ETA: 0s - loss: 1.1800 - accuracy: 0.5303\n",
      "Epoch 7: val_loss improved from 1.21082 to 1.19156, saving model to Trained_Models/InceptionV3\n",
      "356/356 [==============================] - 24s 67ms/step - loss: 1.1807 - accuracy: 0.5301 - val_loss: 1.1916 - val_accuracy: 0.5242 - lr: 3.0000e-04\n",
      "Epoch 8/10\n",
      " 81/356 [=====>........................] - ETA: 9s - loss: 1.1446 - accuracy: 0.5417"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:35:13.449149Z",
     "start_time": "2024-07-25T21:35:13.443953Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:35:13.457390Z",
     "start_time": "2024-07-25T21:35:13.450320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:35:13.461922Z",
     "start_time": "2024-07-25T21:35:13.457972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:35:13.485554Z",
     "start_time": "2024-07-25T21:35:13.462576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 5\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3350027 (12.78 MB)\n",
      "Trainable params: 1948395 (7.43 MB)\n",
      "Non-trainable params: 1401632 (5.35 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:37:51.158625Z",
     "start_time": "2024-07-25T21:35:13.486081Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.9169 - accuracy: 0.6364\n",
      "Epoch 6: val_loss improved from 0.70975 to 0.69144, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 20s 48ms/step - loss: 0.9165 - accuracy: 0.6362 - val_loss: 0.6914 - val_accuracy: 0.6672 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.7614 - accuracy: 0.6794\n",
      "Epoch 7: val_loss improved from 0.69144 to 0.51389, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 17s 47ms/step - loss: 0.7610 - accuracy: 0.6797 - val_loss: 0.5139 - val_accuracy: 0.6303 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.6618 - accuracy: 0.7116\n",
      "Epoch 8: val_loss improved from 0.51389 to 0.48093, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 18s 50ms/step - loss: 0.6617 - accuracy: 0.7117 - val_loss: 0.4809 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7282\n",
      "Epoch 9: val_loss improved from 0.48093 to 0.42083, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 18s 50ms/step - loss: 0.6176 - accuracy: 0.7287 - val_loss: 0.4208 - val_accuracy: 0.8385 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.7497\n",
      "Epoch 10: val_loss improved from 0.42083 to 0.35274, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 19s 53ms/step - loss: 0.5902 - accuracy: 0.7497 - val_loss: 0.3527 - val_accuracy: 0.8457 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.5340 - accuracy: 0.7742\n",
      "Epoch 11: val_loss did not improve from 0.35274\n",
      "356/356 [==============================] - 10s 28ms/step - loss: 0.5340 - accuracy: 0.7742 - val_loss: 0.3635 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.7636\n",
      "Epoch 12: val_loss did not improve from 0.35274\n",
      "356/356 [==============================] - 10s 28ms/step - loss: 0.6189 - accuracy: 0.7633 - val_loss: 0.4518 - val_accuracy: 0.7014 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "354/356 [============================>.] - ETA: 0s - loss: 0.4531 - accuracy: 0.8075\n",
      "Epoch 13: val_loss improved from 0.35274 to 0.30713, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 18s 51ms/step - loss: 0.4529 - accuracy: 0.8074 - val_loss: 0.3071 - val_accuracy: 0.8678 - lr: 3.0000e-04\n",
      "Epoch 14/15\n",
      "354/356 [============================>.] - ETA: 0s - loss: 0.4048 - accuracy: 0.8178\n",
      "Epoch 14: val_loss improved from 0.30713 to 0.27371, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 18s 49ms/step - loss: 0.4043 - accuracy: 0.8180 - val_loss: 0.2737 - val_accuracy: 0.8836 - lr: 3.0000e-04\n",
      "Epoch 15/15\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.8254\n",
      "Epoch 15: val_loss did not improve from 0.27371\n",
      "356/356 [==============================] - 10s 28ms/step - loss: 0.3954 - accuracy: 0.8254 - val_loss: 0.2815 - val_accuracy: 0.8850 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:37:51.162093Z",
     "start_time": "2024-07-25T21:37:51.159209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 15\n",
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:37:51.196331Z",
     "start_time": "2024-07-25T21:37:51.162639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3350027 (12.78 MB)\n",
      "Trainable params: 2973243 (11.34 MB)\n",
      "Non-trainable params: 376784 (1.44 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:42:06.012604Z",
     "start_time": "2024-07-25T21:37:51.197061Z"
    }
   },
   "cell_type": "code",
   "source": "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+15, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.7916\n",
      "Epoch 16: val_loss did not improve from 0.27371\n",
      "356/356 [==============================] - 16s 32ms/step - loss: 0.5453 - accuracy: 0.7916 - val_loss: 0.3833 - val_accuracy: 0.8607 - lr: 3.0000e-04\n",
      "Epoch 17/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.4776 - accuracy: 0.8000\n",
      "Epoch 17: val_loss did not improve from 0.27371\n",
      "356/356 [==============================] - 13s 37ms/step - loss: 0.4771 - accuracy: 0.8003 - val_loss: 0.3473 - val_accuracy: 0.8738 - lr: 3.0000e-04\n",
      "Epoch 18/30\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.7815\n",
      "Epoch 18: val_loss did not improve from 0.27371\n",
      "356/356 [==============================] - 13s 37ms/step - loss: 0.6035 - accuracy: 0.7815 - val_loss: 0.3543 - val_accuracy: 0.8594 - lr: 3.0000e-04\n",
      "Epoch 19/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.4299 - accuracy: 0.8150\n",
      "Epoch 19: val_loss did not improve from 0.27371\n",
      "356/356 [==============================] - 13s 36ms/step - loss: 0.4294 - accuracy: 0.8153 - val_loss: 0.3483 - val_accuracy: 0.8738 - lr: 3.0000e-04\n",
      "Epoch 20/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8381\n",
      "Epoch 20: val_loss improved from 0.27371 to 0.23143, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 21s 59ms/step - loss: 0.3531 - accuracy: 0.8384 - val_loss: 0.2314 - val_accuracy: 0.9057 - lr: 9.0000e-05\n",
      "Epoch 21/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8429\n",
      "Epoch 21: val_loss improved from 0.23143 to 0.22144, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 23s 63ms/step - loss: 0.3474 - accuracy: 0.8431 - val_loss: 0.2214 - val_accuracy: 0.9045 - lr: 9.0000e-05\n",
      "Epoch 22/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.8471\n",
      "Epoch 22: val_loss did not improve from 0.22144\n",
      "356/356 [==============================] - 14s 38ms/step - loss: 0.3270 - accuracy: 0.8473 - val_loss: 0.2252 - val_accuracy: 0.9115 - lr: 9.0000e-05\n",
      "Epoch 23/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3253 - accuracy: 0.8501\n",
      "Epoch 23: val_loss improved from 0.22144 to 0.21049, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 21s 59ms/step - loss: 0.3249 - accuracy: 0.8504 - val_loss: 0.2105 - val_accuracy: 0.9160 - lr: 9.0000e-05\n",
      "Epoch 24/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3288 - accuracy: 0.8518\n",
      "Epoch 24: val_loss did not improve from 0.21049\n",
      "356/356 [==============================] - 13s 36ms/step - loss: 0.3288 - accuracy: 0.8520 - val_loss: 0.2449 - val_accuracy: 0.9047 - lr: 9.0000e-05\n",
      "Epoch 25/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8514\n",
      "Epoch 25: val_loss did not improve from 0.21049\n",
      "356/356 [==============================] - 15s 41ms/step - loss: 0.3179 - accuracy: 0.8515 - val_loss: 0.2106 - val_accuracy: 0.9205 - lr: 9.0000e-05\n",
      "Epoch 26/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2858 - accuracy: 0.8646\n",
      "Epoch 26: val_loss improved from 0.21049 to 0.16710, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 24s 66ms/step - loss: 0.2854 - accuracy: 0.8648 - val_loss: 0.1671 - val_accuracy: 0.9346 - lr: 2.7000e-05\n",
      "Epoch 27/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2838 - accuracy: 0.8662\n",
      "Epoch 27: val_loss improved from 0.16710 to 0.16419, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 21s 60ms/step - loss: 0.2836 - accuracy: 0.8664 - val_loss: 0.1642 - val_accuracy: 0.9357 - lr: 2.7000e-05\n",
      "Epoch 28/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.8702\n",
      "Epoch 28: val_loss improved from 0.16419 to 0.15543, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 22s 61ms/step - loss: 0.2765 - accuracy: 0.8706 - val_loss: 0.1554 - val_accuracy: 0.9422 - lr: 2.7000e-05\n",
      "Epoch 29/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2748 - accuracy: 0.8700\n",
      "Epoch 29: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 14s 38ms/step - loss: 0.2747 - accuracy: 0.8701 - val_loss: 0.1574 - val_accuracy: 0.9412 - lr: 2.7000e-05\n",
      "Epoch 30/30\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.8731\n",
      "Epoch 30: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 14s 38ms/step - loss: 0.2663 - accuracy: 0.8731 - val_loss: 0.1620 - val_accuracy: 0.9412 - lr: 2.7000e-05\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:42:06.020066Z",
     "start_time": "2024-07-25T21:42:06.015265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 30\n",
    "for layer in base_model.layers[-200:]:\n",
    "    layer.trainable = True"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:42:06.058875Z",
     "start_time": "2024-07-25T21:42:06.021033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00009), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3350027 (12.78 MB)\n",
      "Trainable params: 3290379 (12.55 MB)\n",
      "Non-trainable params: 59648 (233.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:46:34.896780Z",
     "start_time": "2024-07-25T21:42:06.059786Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+15, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/45\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8564\n",
      "Epoch 31: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 27s 48ms/step - loss: 0.3254 - accuracy: 0.8564 - val_loss: 0.1932 - val_accuracy: 0.9262 - lr: 9.0000e-05\n",
      "Epoch 32/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8568\n",
      "Epoch 32: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 14s 39ms/step - loss: 0.3094 - accuracy: 0.8570 - val_loss: 0.2302 - val_accuracy: 0.9232 - lr: 9.0000e-05\n",
      "Epoch 33/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8511\n",
      "Epoch 33: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 14s 40ms/step - loss: 0.3423 - accuracy: 0.8513 - val_loss: 0.2257 - val_accuracy: 0.9205 - lr: 9.0000e-05\n",
      "Epoch 34/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.8718\n",
      "Epoch 34: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 14s 40ms/step - loss: 0.2938 - accuracy: 0.8719 - val_loss: 0.1708 - val_accuracy: 0.9414 - lr: 2.7000e-05\n",
      "Epoch 35/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.8716\n",
      "Epoch 35: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 15s 41ms/step - loss: 0.3261 - accuracy: 0.8718 - val_loss: 0.2043 - val_accuracy: 0.9283 - lr: 2.7000e-05\n",
      "Epoch 36/45\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.8648\n",
      "Epoch 36: val_loss did not improve from 0.15543\n",
      "356/356 [==============================] - 15s 41ms/step - loss: 0.2876 - accuracy: 0.8648 - val_loss: 0.1678 - val_accuracy: 0.9418 - lr: 2.7000e-05\n",
      "Epoch 37/45\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.8714\n",
      "Epoch 37: val_loss improved from 0.15543 to 0.15391, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 23s 63ms/step - loss: 0.2669 - accuracy: 0.8714 - val_loss: 0.1539 - val_accuracy: 0.9457 - lr: 2.7000e-05\n",
      "Epoch 38/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.8723\n",
      "Epoch 38: val_loss improved from 0.15391 to 0.14985, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 23s 64ms/step - loss: 0.2619 - accuracy: 0.8721 - val_loss: 0.1498 - val_accuracy: 0.9494 - lr: 2.7000e-05\n",
      "Epoch 39/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2531 - accuracy: 0.8790\n",
      "Epoch 39: val_loss did not improve from 0.14985\n",
      "356/356 [==============================] - 14s 39ms/step - loss: 0.2529 - accuracy: 0.8791 - val_loss: 0.1551 - val_accuracy: 0.9523 - lr: 2.7000e-05\n",
      "Epoch 40/45\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.8827\n",
      "Epoch 40: val_loss did not improve from 0.14985\n",
      "356/356 [==============================] - 15s 42ms/step - loss: 0.2488 - accuracy: 0.8827 - val_loss: 0.1647 - val_accuracy: 0.9475 - lr: 2.7000e-05\n",
      "Epoch 41/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.8874\n",
      "Epoch 41: val_loss improved from 0.14985 to 0.14636, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 24s 66ms/step - loss: 0.2440 - accuracy: 0.8875 - val_loss: 0.1464 - val_accuracy: 0.9553 - lr: 8.1000e-06\n",
      "Epoch 42/45\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.8863\n",
      "Epoch 42: val_loss improved from 0.14636 to 0.14520, saving model to Trained_Models/MobilenetV3L\n",
      "356/356 [==============================] - 24s 67ms/step - loss: 0.2376 - accuracy: 0.8863 - val_loss: 0.1452 - val_accuracy: 0.9549 - lr: 8.1000e-06\n",
      "Epoch 43/45\n",
      "356/356 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.8881\n",
      "Epoch 43: val_loss did not improve from 0.14520\n",
      "356/356 [==============================] - 16s 44ms/step - loss: 0.2323 - accuracy: 0.8881 - val_loss: 0.1490 - val_accuracy: 0.9564 - lr: 8.1000e-06\n",
      "Epoch 44/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.8926\n",
      "Epoch 44: val_loss did not improve from 0.14520\n",
      "356/356 [==============================] - 16s 46ms/step - loss: 0.2295 - accuracy: 0.8924 - val_loss: 0.1512 - val_accuracy: 0.9578 - lr: 8.1000e-06\n",
      "Epoch 45/45\n",
      "355/356 [============================>.] - ETA: 0s - loss: 0.2248 - accuracy: 0.8931\n",
      "Epoch 45: val_loss did not improve from 0.14520\n",
      "356/356 [==============================] - 16s 44ms/step - loss: 0.2248 - accuracy: 0.8932 - val_loss: 0.1526 - val_accuracy: 0.9582 - lr: 2.4300e-06\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:46:34.902353Z",
     "start_time": "2024-07-25T21:46:34.897564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 45\n",
    "for layer in base_model.layers[-250:]:\n",
    "    layer.trainable = True"
   ],
   "id": "f24912d6c3aa128",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:46:34.932935Z",
     "start_time": "2024-07-25T21:46:34.903035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0000015), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "81ac6230c263bbc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3350027 (12.78 MB)\n",
      "Trainable params: 3324699 (12.68 MB)\n",
      "Non-trainable params: 25328 (98.94 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-25T21:46:34.933650Z"
    }
   },
   "cell_type": "code",
   "source": "history_250 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+15, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler])",
   "id": "fd98979b64e68f4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:52:01.163167Z",
     "start_time": "2024-07-25T21:51:57.311946Z"
    }
   },
   "cell_type": "code",
   "source": "MobileNet_Best = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/MobilenetV3L\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:52:24.867512Z",
     "start_time": "2024-07-25T21:52:20.220475Z"
    }
   },
   "cell_type": "code",
   "source": "MobileNet_Best.evaluate(test_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 17:52:20.965819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-25 17:52:21.202099: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 5s 18ms/step - loss: 0.4258 - accuracy: 0.8493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42583829164505005, 0.8492999076843262]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
