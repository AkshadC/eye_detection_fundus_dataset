{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:31.957653Z",
     "start_time": "2024-07-29T19:30:30.344935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:30:30.469176: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 15:30:30.492460: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 15:30:30.492483: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 15:30:30.492508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 15:30:30.497850: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 15:30:30.980454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:30:31.926471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:31.948723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:31.951100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:31.953523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:31.961461Z",
     "start_time": "2024-07-29T19:30:31.958369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:31.969086Z",
     "start_time": "2024-07-29T19:30:31.961923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:31.973479Z",
     "start_time": "2024-07-29T19:30:31.969627Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:31.976339Z",
     "start_time": "2024-07-29T19:30:31.974302Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:33.083590Z",
     "start_time": "2024-07-29T19:30:32.214333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:30:32.277228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:32.279820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:32.282647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:32.420988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:32.422932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:32.424646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:30:32.426329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5960 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-29 15:30:32.565331: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:33.688823Z",
     "start_time": "2024-07-29T19:30:33.686362Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:37.779459Z",
     "start_time": "2024-07-29T19:30:37.777431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.nasnet.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:30:38.132060Z",
     "start_time": "2024-07-29T19:30:38.103055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:31:17.789239Z",
     "start_time": "2024-07-29T19:31:17.786575Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:31:39.399686Z",
     "start_time": "2024-07-29T19:31:36.818619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.NASNetMobile(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:31:58.747299Z",
     "start_time": "2024-07-29T19:31:58.742552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: stem_conv1, False\n",
      "Layer: stem_bn1, False\n",
      "Layer: activation, False\n",
      "Layer: reduction_conv_1_stem_1, False\n",
      "Layer: reduction_bn_1_stem_1, False\n",
      "Layer: activation_1, False\n",
      "Layer: activation_3, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_stem_1, False\n",
      "Layer: separable_conv_1_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_1_reduction_right1_stem_1, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_stem_1, False\n",
      "Layer: activation_2, False\n",
      "Layer: activation_4, False\n",
      "Layer: separable_conv_2_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_2_reduction_right1_stem_1, False\n",
      "Layer: activation_5, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_stem_1, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_stem_1, False\n",
      "Layer: activation_7, False\n",
      "Layer: reduction_add_1_stem_1, False\n",
      "Layer: separable_conv_1_reduction_right2_stem_1, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_stem_1, False\n",
      "Layer: activation_9, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_stem_1, False\n",
      "Layer: separable_conv_1_reduction_right3_stem_1, False\n",
      "Layer: separable_conv_1_reduction_left4_stem_1, False\n",
      "Layer: activation_6, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_stem_1, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_stem_1, False\n",
      "Layer: reduction_pad_1_stem_1, False\n",
      "Layer: separable_conv_2_reduction_right2_stem_1, False\n",
      "Layer: activation_8, False\n",
      "Layer: activation_10, False\n",
      "Layer: reduction_left2_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_stem_1, False\n",
      "Layer: separable_conv_2_reduction_right3_stem_1, False\n",
      "Layer: separable_conv_2_reduction_left4_stem_1, False\n",
      "Layer: adjust_relu_1_stem_2, False\n",
      "Layer: reduction_add_2_stem_1, False\n",
      "Layer: reduction_left3_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_stem_1, False\n",
      "Layer: reduction_left4_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_stem_1, False\n",
      "Layer: reduction_right5_stem_1, False\n",
      "Layer: zero_padding2d, False\n",
      "Layer: reduction_add3_stem_1, False\n",
      "Layer: add, False\n",
      "Layer: reduction_add4_stem_1, False\n",
      "Layer: cropping2d, False\n",
      "Layer: reduction_concat_stem_1, False\n",
      "Layer: adjust_avg_pool_1_stem_2, False\n",
      "Layer: adjust_avg_pool_2_stem_2, False\n",
      "Layer: activation_11, False\n",
      "Layer: adjust_conv_1_stem_2, False\n",
      "Layer: adjust_conv_2_stem_2, False\n",
      "Layer: reduction_conv_1_stem_2, False\n",
      "Layer: concatenate, False\n",
      "Layer: reduction_bn_1_stem_2, False\n",
      "Layer: adjust_bn_stem_2, False\n",
      "Layer: activation_12, False\n",
      "Layer: activation_14, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_stem_2, False\n",
      "Layer: separable_conv_1_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_1_reduction_right1_stem_2, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_stem_2, False\n",
      "Layer: activation_13, False\n",
      "Layer: activation_15, False\n",
      "Layer: separable_conv_2_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_2_reduction_right1_stem_2, False\n",
      "Layer: activation_16, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_stem_2, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_stem_2, False\n",
      "Layer: activation_18, False\n",
      "Layer: reduction_add_1_stem_2, False\n",
      "Layer: separable_conv_1_reduction_right2_stem_2, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_stem_2, False\n",
      "Layer: activation_20, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_stem_2, False\n",
      "Layer: separable_conv_1_reduction_right3_stem_2, False\n",
      "Layer: separable_conv_1_reduction_left4_stem_2, False\n",
      "Layer: activation_17, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_stem_2, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_stem_2, False\n",
      "Layer: reduction_pad_1_stem_2, False\n",
      "Layer: separable_conv_2_reduction_right2_stem_2, False\n",
      "Layer: activation_19, False\n",
      "Layer: activation_21, False\n",
      "Layer: reduction_left2_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_stem_2, False\n",
      "Layer: separable_conv_2_reduction_right3_stem_2, False\n",
      "Layer: separable_conv_2_reduction_left4_stem_2, False\n",
      "Layer: adjust_relu_1_0, False\n",
      "Layer: reduction_add_2_stem_2, False\n",
      "Layer: reduction_left3_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_stem_2, False\n",
      "Layer: reduction_left4_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_stem_2, False\n",
      "Layer: reduction_right5_stem_2, False\n",
      "Layer: zero_padding2d_1, False\n",
      "Layer: reduction_add3_stem_2, False\n",
      "Layer: add_1, False\n",
      "Layer: reduction_add4_stem_2, False\n",
      "Layer: cropping2d_1, False\n",
      "Layer: reduction_concat_stem_2, False\n",
      "Layer: adjust_avg_pool_1_0, False\n",
      "Layer: adjust_avg_pool_2_0, False\n",
      "Layer: adjust_conv_1_0, False\n",
      "Layer: adjust_conv_2_0, False\n",
      "Layer: activation_22, False\n",
      "Layer: concatenate_1, False\n",
      "Layer: normal_conv_1_0, False\n",
      "Layer: adjust_bn_0, False\n",
      "Layer: normal_bn_1_0, False\n",
      "Layer: activation_23, False\n",
      "Layer: activation_25, False\n",
      "Layer: activation_27, False\n",
      "Layer: activation_29, False\n",
      "Layer: activation_31, False\n",
      "Layer: separable_conv_1_normal_left1_0, False\n",
      "Layer: separable_conv_1_normal_right1_0, False\n",
      "Layer: separable_conv_1_normal_left2_0, False\n",
      "Layer: separable_conv_1_normal_right2_0, False\n",
      "Layer: separable_conv_1_normal_left5_0, False\n",
      "Layer: separable_conv_1_bn_normal_left1_0, False\n",
      "Layer: separable_conv_1_bn_normal_right1_0, False\n",
      "Layer: separable_conv_1_bn_normal_left2_0, False\n",
      "Layer: separable_conv_1_bn_normal_right2_0, False\n",
      "Layer: separable_conv_1_bn_normal_left5_0, False\n",
      "Layer: activation_24, False\n",
      "Layer: activation_26, False\n",
      "Layer: activation_28, False\n",
      "Layer: activation_30, False\n",
      "Layer: activation_32, False\n",
      "Layer: separable_conv_2_normal_left1_0, False\n",
      "Layer: separable_conv_2_normal_right1_0, False\n",
      "Layer: separable_conv_2_normal_left2_0, False\n",
      "Layer: separable_conv_2_normal_right2_0, False\n",
      "Layer: separable_conv_2_normal_left5_0, False\n",
      "Layer: separable_conv_2_bn_normal_left1_0, False\n",
      "Layer: separable_conv_2_bn_normal_right1_0, False\n",
      "Layer: separable_conv_2_bn_normal_left2_0, False\n",
      "Layer: separable_conv_2_bn_normal_right2_0, False\n",
      "Layer: normal_left3_0, False\n",
      "Layer: normal_left4_0, False\n",
      "Layer: normal_right4_0, False\n",
      "Layer: separable_conv_2_bn_normal_left5_0, False\n",
      "Layer: normal_add_1_0, False\n",
      "Layer: normal_add_2_0, False\n",
      "Layer: normal_add_3_0, False\n",
      "Layer: normal_add_4_0, False\n",
      "Layer: normal_add_5_0, False\n",
      "Layer: normal_concat_0, False\n",
      "Layer: activation_33, False\n",
      "Layer: activation_34, False\n",
      "Layer: adjust_conv_projection_1, False\n",
      "Layer: normal_conv_1_1, False\n",
      "Layer: adjust_bn_1, False\n",
      "Layer: normal_bn_1_1, False\n",
      "Layer: activation_35, False\n",
      "Layer: activation_37, False\n",
      "Layer: activation_39, False\n",
      "Layer: activation_41, False\n",
      "Layer: activation_43, False\n",
      "Layer: separable_conv_1_normal_left1_1, False\n",
      "Layer: separable_conv_1_normal_right1_1, False\n",
      "Layer: separable_conv_1_normal_left2_1, False\n",
      "Layer: separable_conv_1_normal_right2_1, False\n",
      "Layer: separable_conv_1_normal_left5_1, False\n",
      "Layer: separable_conv_1_bn_normal_left1_1, False\n",
      "Layer: separable_conv_1_bn_normal_right1_1, False\n",
      "Layer: separable_conv_1_bn_normal_left2_1, False\n",
      "Layer: separable_conv_1_bn_normal_right2_1, False\n",
      "Layer: separable_conv_1_bn_normal_left5_1, False\n",
      "Layer: activation_36, False\n",
      "Layer: activation_38, False\n",
      "Layer: activation_40, False\n",
      "Layer: activation_42, False\n",
      "Layer: activation_44, False\n",
      "Layer: separable_conv_2_normal_left1_1, False\n",
      "Layer: separable_conv_2_normal_right1_1, False\n",
      "Layer: separable_conv_2_normal_left2_1, False\n",
      "Layer: separable_conv_2_normal_right2_1, False\n",
      "Layer: separable_conv_2_normal_left5_1, False\n",
      "Layer: separable_conv_2_bn_normal_left1_1, False\n",
      "Layer: separable_conv_2_bn_normal_right1_1, False\n",
      "Layer: separable_conv_2_bn_normal_left2_1, False\n",
      "Layer: separable_conv_2_bn_normal_right2_1, False\n",
      "Layer: normal_left3_1, False\n",
      "Layer: normal_left4_1, False\n",
      "Layer: normal_right4_1, False\n",
      "Layer: separable_conv_2_bn_normal_left5_1, False\n",
      "Layer: normal_add_1_1, False\n",
      "Layer: normal_add_2_1, False\n",
      "Layer: normal_add_3_1, False\n",
      "Layer: normal_add_4_1, False\n",
      "Layer: normal_add_5_1, False\n",
      "Layer: normal_concat_1, False\n",
      "Layer: activation_45, False\n",
      "Layer: activation_46, False\n",
      "Layer: adjust_conv_projection_2, False\n",
      "Layer: normal_conv_1_2, False\n",
      "Layer: adjust_bn_2, False\n",
      "Layer: normal_bn_1_2, False\n",
      "Layer: activation_47, False\n",
      "Layer: activation_49, False\n",
      "Layer: activation_51, False\n",
      "Layer: activation_53, False\n",
      "Layer: activation_55, False\n",
      "Layer: separable_conv_1_normal_left1_2, False\n",
      "Layer: separable_conv_1_normal_right1_2, False\n",
      "Layer: separable_conv_1_normal_left2_2, False\n",
      "Layer: separable_conv_1_normal_right2_2, False\n",
      "Layer: separable_conv_1_normal_left5_2, False\n",
      "Layer: separable_conv_1_bn_normal_left1_2, False\n",
      "Layer: separable_conv_1_bn_normal_right1_2, False\n",
      "Layer: separable_conv_1_bn_normal_left2_2, False\n",
      "Layer: separable_conv_1_bn_normal_right2_2, False\n",
      "Layer: separable_conv_1_bn_normal_left5_2, False\n",
      "Layer: activation_48, False\n",
      "Layer: activation_50, False\n",
      "Layer: activation_52, False\n",
      "Layer: activation_54, False\n",
      "Layer: activation_56, False\n",
      "Layer: separable_conv_2_normal_left1_2, False\n",
      "Layer: separable_conv_2_normal_right1_2, False\n",
      "Layer: separable_conv_2_normal_left2_2, False\n",
      "Layer: separable_conv_2_normal_right2_2, False\n",
      "Layer: separable_conv_2_normal_left5_2, False\n",
      "Layer: separable_conv_2_bn_normal_left1_2, False\n",
      "Layer: separable_conv_2_bn_normal_right1_2, False\n",
      "Layer: separable_conv_2_bn_normal_left2_2, False\n",
      "Layer: separable_conv_2_bn_normal_right2_2, False\n",
      "Layer: normal_left3_2, False\n",
      "Layer: normal_left4_2, False\n",
      "Layer: normal_right4_2, False\n",
      "Layer: separable_conv_2_bn_normal_left5_2, False\n",
      "Layer: normal_add_1_2, False\n",
      "Layer: normal_add_2_2, False\n",
      "Layer: normal_add_3_2, False\n",
      "Layer: normal_add_4_2, False\n",
      "Layer: normal_add_5_2, False\n",
      "Layer: normal_concat_2, False\n",
      "Layer: activation_57, False\n",
      "Layer: activation_58, False\n",
      "Layer: adjust_conv_projection_3, False\n",
      "Layer: normal_conv_1_3, False\n",
      "Layer: adjust_bn_3, False\n",
      "Layer: normal_bn_1_3, False\n",
      "Layer: activation_59, False\n",
      "Layer: activation_61, False\n",
      "Layer: activation_63, False\n",
      "Layer: activation_65, False\n",
      "Layer: activation_67, False\n",
      "Layer: separable_conv_1_normal_left1_3, False\n",
      "Layer: separable_conv_1_normal_right1_3, False\n",
      "Layer: separable_conv_1_normal_left2_3, False\n",
      "Layer: separable_conv_1_normal_right2_3, False\n",
      "Layer: separable_conv_1_normal_left5_3, False\n",
      "Layer: separable_conv_1_bn_normal_left1_3, False\n",
      "Layer: separable_conv_1_bn_normal_right1_3, False\n",
      "Layer: separable_conv_1_bn_normal_left2_3, False\n",
      "Layer: separable_conv_1_bn_normal_right2_3, False\n",
      "Layer: separable_conv_1_bn_normal_left5_3, False\n",
      "Layer: activation_60, False\n",
      "Layer: activation_62, False\n",
      "Layer: activation_64, False\n",
      "Layer: activation_66, False\n",
      "Layer: activation_68, False\n",
      "Layer: separable_conv_2_normal_left1_3, False\n",
      "Layer: separable_conv_2_normal_right1_3, False\n",
      "Layer: separable_conv_2_normal_left2_3, False\n",
      "Layer: separable_conv_2_normal_right2_3, False\n",
      "Layer: separable_conv_2_normal_left5_3, False\n",
      "Layer: separable_conv_2_bn_normal_left1_3, False\n",
      "Layer: separable_conv_2_bn_normal_right1_3, False\n",
      "Layer: separable_conv_2_bn_normal_left2_3, False\n",
      "Layer: separable_conv_2_bn_normal_right2_3, False\n",
      "Layer: normal_left3_3, False\n",
      "Layer: normal_left4_3, False\n",
      "Layer: normal_right4_3, False\n",
      "Layer: separable_conv_2_bn_normal_left5_3, False\n",
      "Layer: normal_add_1_3, False\n",
      "Layer: normal_add_2_3, False\n",
      "Layer: normal_add_3_3, False\n",
      "Layer: normal_add_4_3, False\n",
      "Layer: normal_add_5_3, False\n",
      "Layer: normal_concat_3, False\n",
      "Layer: activation_70, False\n",
      "Layer: activation_69, False\n",
      "Layer: reduction_conv_1_reduce_4, False\n",
      "Layer: adjust_conv_projection_reduce_4, False\n",
      "Layer: reduction_bn_1_reduce_4, False\n",
      "Layer: adjust_bn_reduce_4, False\n",
      "Layer: activation_71, False\n",
      "Layer: activation_73, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_reduce_4, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_reduce_4, False\n",
      "Layer: separable_conv_1_reduction_left1_reduce_4, False\n",
      "Layer: separable_conv_1_reduction_right1_reduce_4, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_reduce_4, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_reduce_4, False\n",
      "Layer: activation_72, False\n",
      "Layer: activation_74, False\n",
      "Layer: separable_conv_2_reduction_left1_reduce_4, False\n",
      "Layer: separable_conv_2_reduction_right1_reduce_4, False\n",
      "Layer: activation_75, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_reduce_4, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_reduce_4, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_reduce_4, False\n",
      "Layer: activation_77, False\n",
      "Layer: reduction_add_1_reduce_4, False\n",
      "Layer: separable_conv_1_reduction_right2_reduce_4, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_reduce_4, False\n",
      "Layer: activation_79, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_reduce_4, False\n",
      "Layer: separable_conv_1_reduction_right3_reduce_4, False\n",
      "Layer: separable_conv_1_reduction_left4_reduce_4, False\n",
      "Layer: activation_76, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_reduce_4, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_reduce_4, False\n",
      "Layer: reduction_pad_1_reduce_4, False\n",
      "Layer: separable_conv_2_reduction_right2_reduce_4, False\n",
      "Layer: activation_78, False\n",
      "Layer: activation_80, False\n",
      "Layer: reduction_left2_reduce_4, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_reduce_4, False\n",
      "Layer: separable_conv_2_reduction_right3_reduce_4, False\n",
      "Layer: separable_conv_2_reduction_left4_reduce_4, False\n",
      "Layer: adjust_relu_1_5, False\n",
      "Layer: reduction_add_2_reduce_4, False\n",
      "Layer: reduction_left3_reduce_4, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_reduce_4, False\n",
      "Layer: reduction_left4_reduce_4, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_reduce_4, False\n",
      "Layer: reduction_right5_reduce_4, False\n",
      "Layer: zero_padding2d_2, False\n",
      "Layer: reduction_add3_reduce_4, False\n",
      "Layer: add_2, False\n",
      "Layer: reduction_add4_reduce_4, False\n",
      "Layer: cropping2d_2, False\n",
      "Layer: reduction_concat_reduce_4, False\n",
      "Layer: adjust_avg_pool_1_5, False\n",
      "Layer: adjust_avg_pool_2_5, False\n",
      "Layer: adjust_conv_1_5, False\n",
      "Layer: adjust_conv_2_5, False\n",
      "Layer: activation_81, False\n",
      "Layer: concatenate_2, False\n",
      "Layer: normal_conv_1_5, False\n",
      "Layer: adjust_bn_5, False\n",
      "Layer: normal_bn_1_5, False\n",
      "Layer: activation_82, False\n",
      "Layer: activation_84, False\n",
      "Layer: activation_86, False\n",
      "Layer: activation_88, False\n",
      "Layer: activation_90, False\n",
      "Layer: separable_conv_1_normal_left1_5, False\n",
      "Layer: separable_conv_1_normal_right1_5, False\n",
      "Layer: separable_conv_1_normal_left2_5, False\n",
      "Layer: separable_conv_1_normal_right2_5, False\n",
      "Layer: separable_conv_1_normal_left5_5, False\n",
      "Layer: separable_conv_1_bn_normal_left1_5, False\n",
      "Layer: separable_conv_1_bn_normal_right1_5, False\n",
      "Layer: separable_conv_1_bn_normal_left2_5, False\n",
      "Layer: separable_conv_1_bn_normal_right2_5, False\n",
      "Layer: separable_conv_1_bn_normal_left5_5, False\n",
      "Layer: activation_83, False\n",
      "Layer: activation_85, False\n",
      "Layer: activation_87, False\n",
      "Layer: activation_89, False\n",
      "Layer: activation_91, False\n",
      "Layer: separable_conv_2_normal_left1_5, False\n",
      "Layer: separable_conv_2_normal_right1_5, False\n",
      "Layer: separable_conv_2_normal_left2_5, False\n",
      "Layer: separable_conv_2_normal_right2_5, False\n",
      "Layer: separable_conv_2_normal_left5_5, False\n",
      "Layer: separable_conv_2_bn_normal_left1_5, False\n",
      "Layer: separable_conv_2_bn_normal_right1_5, False\n",
      "Layer: separable_conv_2_bn_normal_left2_5, False\n",
      "Layer: separable_conv_2_bn_normal_right2_5, False\n",
      "Layer: normal_left3_5, False\n",
      "Layer: normal_left4_5, False\n",
      "Layer: normal_right4_5, False\n",
      "Layer: separable_conv_2_bn_normal_left5_5, False\n",
      "Layer: normal_add_1_5, False\n",
      "Layer: normal_add_2_5, False\n",
      "Layer: normal_add_3_5, False\n",
      "Layer: normal_add_4_5, False\n",
      "Layer: normal_add_5_5, False\n",
      "Layer: normal_concat_5, False\n",
      "Layer: activation_92, False\n",
      "Layer: activation_93, False\n",
      "Layer: adjust_conv_projection_6, False\n",
      "Layer: normal_conv_1_6, False\n",
      "Layer: adjust_bn_6, False\n",
      "Layer: normal_bn_1_6, False\n",
      "Layer: activation_94, False\n",
      "Layer: activation_96, False\n",
      "Layer: activation_98, False\n",
      "Layer: activation_100, False\n",
      "Layer: activation_102, False\n",
      "Layer: separable_conv_1_normal_left1_6, False\n",
      "Layer: separable_conv_1_normal_right1_6, False\n",
      "Layer: separable_conv_1_normal_left2_6, False\n",
      "Layer: separable_conv_1_normal_right2_6, False\n",
      "Layer: separable_conv_1_normal_left5_6, False\n",
      "Layer: separable_conv_1_bn_normal_left1_6, False\n",
      "Layer: separable_conv_1_bn_normal_right1_6, False\n",
      "Layer: separable_conv_1_bn_normal_left2_6, False\n",
      "Layer: separable_conv_1_bn_normal_right2_6, False\n",
      "Layer: separable_conv_1_bn_normal_left5_6, False\n",
      "Layer: activation_95, False\n",
      "Layer: activation_97, False\n",
      "Layer: activation_99, False\n",
      "Layer: activation_101, False\n",
      "Layer: activation_103, False\n",
      "Layer: separable_conv_2_normal_left1_6, False\n",
      "Layer: separable_conv_2_normal_right1_6, False\n",
      "Layer: separable_conv_2_normal_left2_6, False\n",
      "Layer: separable_conv_2_normal_right2_6, False\n",
      "Layer: separable_conv_2_normal_left5_6, False\n",
      "Layer: separable_conv_2_bn_normal_left1_6, False\n",
      "Layer: separable_conv_2_bn_normal_right1_6, False\n",
      "Layer: separable_conv_2_bn_normal_left2_6, False\n",
      "Layer: separable_conv_2_bn_normal_right2_6, False\n",
      "Layer: normal_left3_6, False\n",
      "Layer: normal_left4_6, False\n",
      "Layer: normal_right4_6, False\n",
      "Layer: separable_conv_2_bn_normal_left5_6, False\n",
      "Layer: normal_add_1_6, False\n",
      "Layer: normal_add_2_6, False\n",
      "Layer: normal_add_3_6, False\n",
      "Layer: normal_add_4_6, False\n",
      "Layer: normal_add_5_6, False\n",
      "Layer: normal_concat_6, False\n",
      "Layer: activation_104, False\n",
      "Layer: activation_105, False\n",
      "Layer: adjust_conv_projection_7, False\n",
      "Layer: normal_conv_1_7, False\n",
      "Layer: adjust_bn_7, False\n",
      "Layer: normal_bn_1_7, False\n",
      "Layer: activation_106, False\n",
      "Layer: activation_108, False\n",
      "Layer: activation_110, False\n",
      "Layer: activation_112, False\n",
      "Layer: activation_114, False\n",
      "Layer: separable_conv_1_normal_left1_7, False\n",
      "Layer: separable_conv_1_normal_right1_7, False\n",
      "Layer: separable_conv_1_normal_left2_7, False\n",
      "Layer: separable_conv_1_normal_right2_7, False\n",
      "Layer: separable_conv_1_normal_left5_7, False\n",
      "Layer: separable_conv_1_bn_normal_left1_7, False\n",
      "Layer: separable_conv_1_bn_normal_right1_7, False\n",
      "Layer: separable_conv_1_bn_normal_left2_7, False\n",
      "Layer: separable_conv_1_bn_normal_right2_7, False\n",
      "Layer: separable_conv_1_bn_normal_left5_7, False\n",
      "Layer: activation_107, False\n",
      "Layer: activation_109, False\n",
      "Layer: activation_111, False\n",
      "Layer: activation_113, False\n",
      "Layer: activation_115, False\n",
      "Layer: separable_conv_2_normal_left1_7, False\n",
      "Layer: separable_conv_2_normal_right1_7, False\n",
      "Layer: separable_conv_2_normal_left2_7, False\n",
      "Layer: separable_conv_2_normal_right2_7, False\n",
      "Layer: separable_conv_2_normal_left5_7, False\n",
      "Layer: separable_conv_2_bn_normal_left1_7, False\n",
      "Layer: separable_conv_2_bn_normal_right1_7, False\n",
      "Layer: separable_conv_2_bn_normal_left2_7, False\n",
      "Layer: separable_conv_2_bn_normal_right2_7, False\n",
      "Layer: normal_left3_7, False\n",
      "Layer: normal_left4_7, False\n",
      "Layer: normal_right4_7, False\n",
      "Layer: separable_conv_2_bn_normal_left5_7, False\n",
      "Layer: normal_add_1_7, False\n",
      "Layer: normal_add_2_7, False\n",
      "Layer: normal_add_3_7, False\n",
      "Layer: normal_add_4_7, False\n",
      "Layer: normal_add_5_7, False\n",
      "Layer: normal_concat_7, False\n",
      "Layer: activation_116, False\n",
      "Layer: activation_117, False\n",
      "Layer: adjust_conv_projection_8, False\n",
      "Layer: normal_conv_1_8, False\n",
      "Layer: adjust_bn_8, False\n",
      "Layer: normal_bn_1_8, False\n",
      "Layer: activation_118, False\n",
      "Layer: activation_120, False\n",
      "Layer: activation_122, False\n",
      "Layer: activation_124, False\n",
      "Layer: activation_126, False\n",
      "Layer: separable_conv_1_normal_left1_8, False\n",
      "Layer: separable_conv_1_normal_right1_8, False\n",
      "Layer: separable_conv_1_normal_left2_8, False\n",
      "Layer: separable_conv_1_normal_right2_8, False\n",
      "Layer: separable_conv_1_normal_left5_8, False\n",
      "Layer: separable_conv_1_bn_normal_left1_8, False\n",
      "Layer: separable_conv_1_bn_normal_right1_8, False\n",
      "Layer: separable_conv_1_bn_normal_left2_8, False\n",
      "Layer: separable_conv_1_bn_normal_right2_8, False\n",
      "Layer: separable_conv_1_bn_normal_left5_8, False\n",
      "Layer: activation_119, False\n",
      "Layer: activation_121, False\n",
      "Layer: activation_123, False\n",
      "Layer: activation_125, False\n",
      "Layer: activation_127, False\n",
      "Layer: separable_conv_2_normal_left1_8, False\n",
      "Layer: separable_conv_2_normal_right1_8, False\n",
      "Layer: separable_conv_2_normal_left2_8, False\n",
      "Layer: separable_conv_2_normal_right2_8, False\n",
      "Layer: separable_conv_2_normal_left5_8, False\n",
      "Layer: separable_conv_2_bn_normal_left1_8, False\n",
      "Layer: separable_conv_2_bn_normal_right1_8, False\n",
      "Layer: separable_conv_2_bn_normal_left2_8, False\n",
      "Layer: separable_conv_2_bn_normal_right2_8, False\n",
      "Layer: normal_left3_8, False\n",
      "Layer: normal_left4_8, False\n",
      "Layer: normal_right4_8, False\n",
      "Layer: separable_conv_2_bn_normal_left5_8, False\n",
      "Layer: normal_add_1_8, False\n",
      "Layer: normal_add_2_8, False\n",
      "Layer: normal_add_3_8, False\n",
      "Layer: normal_add_4_8, False\n",
      "Layer: normal_add_5_8, False\n",
      "Layer: normal_concat_8, False\n",
      "Layer: activation_129, False\n",
      "Layer: activation_128, False\n",
      "Layer: reduction_conv_1_reduce_8, False\n",
      "Layer: adjust_conv_projection_reduce_8, False\n",
      "Layer: reduction_bn_1_reduce_8, False\n",
      "Layer: adjust_bn_reduce_8, False\n",
      "Layer: activation_130, False\n",
      "Layer: activation_132, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_reduce_8, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_reduce_8, False\n",
      "Layer: separable_conv_1_reduction_left1_reduce_8, False\n",
      "Layer: separable_conv_1_reduction_right1_reduce_8, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_reduce_8, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_reduce_8, False\n",
      "Layer: activation_131, False\n",
      "Layer: activation_133, False\n",
      "Layer: separable_conv_2_reduction_left1_reduce_8, False\n",
      "Layer: separable_conv_2_reduction_right1_reduce_8, False\n",
      "Layer: activation_134, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_reduce_8, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_reduce_8, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_reduce_8, False\n",
      "Layer: activation_136, False\n",
      "Layer: reduction_add_1_reduce_8, False\n",
      "Layer: separable_conv_1_reduction_right2_reduce_8, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_reduce_8, False\n",
      "Layer: activation_138, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_reduce_8, False\n",
      "Layer: separable_conv_1_reduction_right3_reduce_8, False\n",
      "Layer: separable_conv_1_reduction_left4_reduce_8, False\n",
      "Layer: activation_135, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_reduce_8, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_reduce_8, False\n",
      "Layer: reduction_pad_1_reduce_8, False\n",
      "Layer: separable_conv_2_reduction_right2_reduce_8, False\n",
      "Layer: activation_137, False\n",
      "Layer: activation_139, False\n",
      "Layer: reduction_left2_reduce_8, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_reduce_8, False\n",
      "Layer: separable_conv_2_reduction_right3_reduce_8, False\n",
      "Layer: separable_conv_2_reduction_left4_reduce_8, False\n",
      "Layer: adjust_relu_1_9, False\n",
      "Layer: reduction_add_2_reduce_8, False\n",
      "Layer: reduction_left3_reduce_8, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_reduce_8, False\n",
      "Layer: reduction_left4_reduce_8, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_reduce_8, False\n",
      "Layer: reduction_right5_reduce_8, False\n",
      "Layer: zero_padding2d_3, False\n",
      "Layer: reduction_add3_reduce_8, False\n",
      "Layer: add_3, False\n",
      "Layer: reduction_add4_reduce_8, False\n",
      "Layer: cropping2d_3, False\n",
      "Layer: reduction_concat_reduce_8, False\n",
      "Layer: adjust_avg_pool_1_9, False\n",
      "Layer: adjust_avg_pool_2_9, False\n",
      "Layer: adjust_conv_1_9, False\n",
      "Layer: adjust_conv_2_9, False\n",
      "Layer: activation_140, False\n",
      "Layer: concatenate_3, False\n",
      "Layer: normal_conv_1_9, False\n",
      "Layer: adjust_bn_9, False\n",
      "Layer: normal_bn_1_9, False\n",
      "Layer: activation_141, False\n",
      "Layer: activation_143, False\n",
      "Layer: activation_145, False\n",
      "Layer: activation_147, False\n",
      "Layer: activation_149, False\n",
      "Layer: separable_conv_1_normal_left1_9, False\n",
      "Layer: separable_conv_1_normal_right1_9, False\n",
      "Layer: separable_conv_1_normal_left2_9, False\n",
      "Layer: separable_conv_1_normal_right2_9, False\n",
      "Layer: separable_conv_1_normal_left5_9, False\n",
      "Layer: separable_conv_1_bn_normal_left1_9, False\n",
      "Layer: separable_conv_1_bn_normal_right1_9, False\n",
      "Layer: separable_conv_1_bn_normal_left2_9, False\n",
      "Layer: separable_conv_1_bn_normal_right2_9, False\n",
      "Layer: separable_conv_1_bn_normal_left5_9, False\n",
      "Layer: activation_142, False\n",
      "Layer: activation_144, False\n",
      "Layer: activation_146, False\n",
      "Layer: activation_148, False\n",
      "Layer: activation_150, False\n",
      "Layer: separable_conv_2_normal_left1_9, False\n",
      "Layer: separable_conv_2_normal_right1_9, False\n",
      "Layer: separable_conv_2_normal_left2_9, False\n",
      "Layer: separable_conv_2_normal_right2_9, False\n",
      "Layer: separable_conv_2_normal_left5_9, False\n",
      "Layer: separable_conv_2_bn_normal_left1_9, False\n",
      "Layer: separable_conv_2_bn_normal_right1_9, False\n",
      "Layer: separable_conv_2_bn_normal_left2_9, False\n",
      "Layer: separable_conv_2_bn_normal_right2_9, False\n",
      "Layer: normal_left3_9, False\n",
      "Layer: normal_left4_9, False\n",
      "Layer: normal_right4_9, False\n",
      "Layer: separable_conv_2_bn_normal_left5_9, False\n",
      "Layer: normal_add_1_9, False\n",
      "Layer: normal_add_2_9, False\n",
      "Layer: normal_add_3_9, False\n",
      "Layer: normal_add_4_9, False\n",
      "Layer: normal_add_5_9, False\n",
      "Layer: normal_concat_9, False\n",
      "Layer: activation_151, False\n",
      "Layer: activation_152, False\n",
      "Layer: adjust_conv_projection_10, False\n",
      "Layer: normal_conv_1_10, False\n",
      "Layer: adjust_bn_10, False\n",
      "Layer: normal_bn_1_10, False\n",
      "Layer: activation_153, False\n",
      "Layer: activation_155, False\n",
      "Layer: activation_157, False\n",
      "Layer: activation_159, False\n",
      "Layer: activation_161, False\n",
      "Layer: separable_conv_1_normal_left1_10, False\n",
      "Layer: separable_conv_1_normal_right1_10, False\n",
      "Layer: separable_conv_1_normal_left2_10, False\n",
      "Layer: separable_conv_1_normal_right2_10, False\n",
      "Layer: separable_conv_1_normal_left5_10, False\n",
      "Layer: separable_conv_1_bn_normal_left1_10, False\n",
      "Layer: separable_conv_1_bn_normal_right1_10, False\n",
      "Layer: separable_conv_1_bn_normal_left2_10, False\n",
      "Layer: separable_conv_1_bn_normal_right2_10, False\n",
      "Layer: separable_conv_1_bn_normal_left5_10, False\n",
      "Layer: activation_154, False\n",
      "Layer: activation_156, False\n",
      "Layer: activation_158, False\n",
      "Layer: activation_160, False\n",
      "Layer: activation_162, False\n",
      "Layer: separable_conv_2_normal_left1_10, False\n",
      "Layer: separable_conv_2_normal_right1_10, False\n",
      "Layer: separable_conv_2_normal_left2_10, False\n",
      "Layer: separable_conv_2_normal_right2_10, False\n",
      "Layer: separable_conv_2_normal_left5_10, False\n",
      "Layer: separable_conv_2_bn_normal_left1_10, False\n",
      "Layer: separable_conv_2_bn_normal_right1_10, False\n",
      "Layer: separable_conv_2_bn_normal_left2_10, False\n",
      "Layer: separable_conv_2_bn_normal_right2_10, False\n",
      "Layer: normal_left3_10, False\n",
      "Layer: normal_left4_10, False\n",
      "Layer: normal_right4_10, False\n",
      "Layer: separable_conv_2_bn_normal_left5_10, False\n",
      "Layer: normal_add_1_10, False\n",
      "Layer: normal_add_2_10, False\n",
      "Layer: normal_add_3_10, False\n",
      "Layer: normal_add_4_10, False\n",
      "Layer: normal_add_5_10, False\n",
      "Layer: normal_concat_10, False\n",
      "Layer: activation_163, False\n",
      "Layer: activation_164, False\n",
      "Layer: adjust_conv_projection_11, False\n",
      "Layer: normal_conv_1_11, False\n",
      "Layer: adjust_bn_11, False\n",
      "Layer: normal_bn_1_11, False\n",
      "Layer: activation_165, False\n",
      "Layer: activation_167, False\n",
      "Layer: activation_169, False\n",
      "Layer: activation_171, False\n",
      "Layer: activation_173, False\n",
      "Layer: separable_conv_1_normal_left1_11, False\n",
      "Layer: separable_conv_1_normal_right1_11, False\n",
      "Layer: separable_conv_1_normal_left2_11, False\n",
      "Layer: separable_conv_1_normal_right2_11, False\n",
      "Layer: separable_conv_1_normal_left5_11, False\n",
      "Layer: separable_conv_1_bn_normal_left1_11, False\n",
      "Layer: separable_conv_1_bn_normal_right1_11, False\n",
      "Layer: separable_conv_1_bn_normal_left2_11, False\n",
      "Layer: separable_conv_1_bn_normal_right2_11, False\n",
      "Layer: separable_conv_1_bn_normal_left5_11, False\n",
      "Layer: activation_166, False\n",
      "Layer: activation_168, False\n",
      "Layer: activation_170, False\n",
      "Layer: activation_172, False\n",
      "Layer: activation_174, False\n",
      "Layer: separable_conv_2_normal_left1_11, False\n",
      "Layer: separable_conv_2_normal_right1_11, False\n",
      "Layer: separable_conv_2_normal_left2_11, False\n",
      "Layer: separable_conv_2_normal_right2_11, False\n",
      "Layer: separable_conv_2_normal_left5_11, False\n",
      "Layer: separable_conv_2_bn_normal_left1_11, False\n",
      "Layer: separable_conv_2_bn_normal_right1_11, False\n",
      "Layer: separable_conv_2_bn_normal_left2_11, False\n",
      "Layer: separable_conv_2_bn_normal_right2_11, False\n",
      "Layer: normal_left3_11, False\n",
      "Layer: normal_left4_11, False\n",
      "Layer: normal_right4_11, False\n",
      "Layer: separable_conv_2_bn_normal_left5_11, False\n",
      "Layer: normal_add_1_11, False\n",
      "Layer: normal_add_2_11, False\n",
      "Layer: normal_add_3_11, False\n",
      "Layer: normal_add_4_11, False\n",
      "Layer: normal_add_5_11, False\n",
      "Layer: normal_concat_11, False\n",
      "Layer: activation_175, False\n",
      "Layer: activation_176, False\n",
      "Layer: adjust_conv_projection_12, False\n",
      "Layer: normal_conv_1_12, False\n",
      "Layer: adjust_bn_12, False\n",
      "Layer: normal_bn_1_12, False\n",
      "Layer: activation_177, False\n",
      "Layer: activation_179, False\n",
      "Layer: activation_181, False\n",
      "Layer: activation_183, False\n",
      "Layer: activation_185, False\n",
      "Layer: separable_conv_1_normal_left1_12, False\n",
      "Layer: separable_conv_1_normal_right1_12, False\n",
      "Layer: separable_conv_1_normal_left2_12, False\n",
      "Layer: separable_conv_1_normal_right2_12, False\n",
      "Layer: separable_conv_1_normal_left5_12, False\n",
      "Layer: separable_conv_1_bn_normal_left1_12, False\n",
      "Layer: separable_conv_1_bn_normal_right1_12, False\n",
      "Layer: separable_conv_1_bn_normal_left2_12, False\n",
      "Layer: separable_conv_1_bn_normal_right2_12, False\n",
      "Layer: separable_conv_1_bn_normal_left5_12, False\n",
      "Layer: activation_178, False\n",
      "Layer: activation_180, False\n",
      "Layer: activation_182, False\n",
      "Layer: activation_184, False\n",
      "Layer: activation_186, False\n",
      "Layer: separable_conv_2_normal_left1_12, False\n",
      "Layer: separable_conv_2_normal_right1_12, False\n",
      "Layer: separable_conv_2_normal_left2_12, False\n",
      "Layer: separable_conv_2_normal_right2_12, False\n",
      "Layer: separable_conv_2_normal_left5_12, False\n",
      "Layer: separable_conv_2_bn_normal_left1_12, False\n",
      "Layer: separable_conv_2_bn_normal_right1_12, False\n",
      "Layer: separable_conv_2_bn_normal_left2_12, False\n",
      "Layer: separable_conv_2_bn_normal_right2_12, False\n",
      "Layer: normal_left3_12, False\n",
      "Layer: normal_left4_12, False\n",
      "Layer: normal_right4_12, False\n",
      "Layer: separable_conv_2_bn_normal_left5_12, False\n",
      "Layer: normal_add_1_12, False\n",
      "Layer: normal_add_2_12, False\n",
      "Layer: normal_add_3_12, False\n",
      "Layer: normal_add_4_12, False\n",
      "Layer: normal_add_5_12, False\n",
      "Layer: normal_concat_12, False\n",
      "Layer: activation_187, False\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:31:59.322171Z",
     "start_time": "2024-07-29T19:31:59.319161Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:32:00.133888Z",
     "start_time": "2024-07-29T19:32:00.131268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:32:01.858437Z",
     "start_time": "2024-07-29T19:32:01.852519Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:32:23.509690Z",
     "start_time": "2024-07-29T19:32:22.470952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "#x = aug_layer(inputs)\n",
    "#x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "x = base_model(inputs, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'NasnetMobile_89.23')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 717956 (2.74 MB)\n",
      "Non-trainable params: 4273748 (16.30 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:32:31.720861Z",
     "start_time": "2024-07-29T19:32:31.718301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models',model_1.name), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:32:31.881388Z",
     "start_time": "2024-07-29T19:32:31.879349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=3) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:32:32.684193Z",
     "start_time": "2024-07-29T19:32:32.668410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:38:32.325835Z",
     "start_time": "2024-07-29T19:32:35.730507Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 15, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:32:41.760812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-29 15:32:41.820914: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-29 15:32:43.036416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x762e5c003470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-29 15:32:43.036441: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-29 15:32:43.041727: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-29 15:32:43.100937: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 11.8785 - accuracy: 0.6374\n",
      "Epoch 1: val_loss improved from inf to 9.43202, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 38s 410ms/step - loss: 11.8785 - accuracy: 0.6374 - val_loss: 9.4320 - val_accuracy: 0.8764 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.3012 - accuracy: 0.7798\n",
      "Epoch 2: val_loss improved from 9.43202 to 5.57450, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 30s 401ms/step - loss: 7.3012 - accuracy: 0.7798 - val_loss: 5.5745 - val_accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.3811 - accuracy: 0.8098\n",
      "Epoch 3: val_loss improved from 5.57450 to 3.41565, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 29s 391ms/step - loss: 4.3811 - accuracy: 0.8098 - val_loss: 3.4157 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 2.8060 - accuracy: 0.8146\n",
      "Epoch 4: val_loss improved from 3.41565 to 2.36280, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 30s 412ms/step - loss: 2.8028 - accuracy: 0.8136 - val_loss: 2.3628 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.9647 - accuracy: 0.8215\n",
      "Epoch 5: val_loss improved from 2.36280 to 1.56211, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 30s 407ms/step - loss: 1.9616 - accuracy: 0.8213 - val_loss: 1.5621 - val_accuracy: 0.9703 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.4485 - accuracy: 0.8378\n",
      "Epoch 6: val_loss improved from 1.56211 to 1.24463, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 29s 395ms/step - loss: 1.4485 - accuracy: 0.8378 - val_loss: 1.2446 - val_accuracy: 0.9486 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2159 - accuracy: 0.8208\n",
      "Epoch 7: val_loss improved from 1.24463 to 1.03731, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 419ms/step - loss: 1.2159 - accuracy: 0.8208 - val_loss: 1.0373 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.0912 - accuracy: 0.8266\n",
      "Epoch 8: val_loss improved from 1.03731 to 0.85752, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 423ms/step - loss: 1.0877 - accuracy: 0.8276 - val_loss: 0.8575 - val_accuracy: 0.9238 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.9794 - accuracy: 0.8296\n",
      "Epoch 9: val_loss did not improve from 0.85752\n",
      "74/74 [==============================] - 4s 55ms/step - loss: 0.9802 - accuracy: 0.8297 - val_loss: 0.9251 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8785 - accuracy: 0.8288\n",
      "Epoch 10: val_loss improved from 0.85752 to 0.76510, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 29s 397ms/step - loss: 0.8771 - accuracy: 0.8293 - val_loss: 0.7651 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8429 - accuracy: 0.8313\n",
      "Epoch 11: val_loss did not improve from 0.76510\n",
      "74/74 [==============================] - 5s 59ms/step - loss: 0.8440 - accuracy: 0.8306 - val_loss: 0.8777 - val_accuracy: 0.8694 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8364 - accuracy: 0.8446\n",
      "Epoch 12: val_loss did not improve from 0.76510\n",
      "74/74 [==============================] - 5s 63ms/step - loss: 0.8364 - accuracy: 0.8446 - val_loss: 0.8617 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8459 - accuracy: 0.8302\n",
      "Epoch 13: val_loss did not improve from 0.76510\n",
      "74/74 [==============================] - 5s 63ms/step - loss: 0.8459 - accuracy: 0.8302 - val_loss: 1.0931 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.8741\n",
      "Epoch 14: val_loss improved from 0.76510 to 0.59567, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 30s 408ms/step - loss: 0.6830 - accuracy: 0.8751 - val_loss: 0.5957 - val_accuracy: 0.9575 - lr: 3.0000e-04\n",
      "Epoch 15/15\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5835 - accuracy: 0.8878\n",
      "Epoch 15: val_loss improved from 0.59567 to 0.53758, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 29s 398ms/step - loss: 0.5872 - accuracy: 0.8865 - val_loss: 0.5376 - val_accuracy: 0.9515 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:38:33.571759Z",
     "start_time": "2024-07-29T19:38:32.332100Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "eb9cc0053cd28662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 43ms/step - loss: 0.6405 - accuracy: 0.8663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6404761075973511, 0.8662722110748291]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:38:37.949526Z",
     "start_time": "2024-07-29T19:38:37.939196Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:38:38.600562Z",
     "start_time": "2024-07-29T19:38:38.590070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-25]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:38:39.003221Z",
     "start_time": "2024-07-29T19:38:38.997704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:38:44.127863Z",
     "start_time": "2024-07-29T19:38:44.083831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 15\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 888148 (3.39 MB)\n",
      "Non-trainable params: 4103556 (15.65 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:41:23.408579Z",
     "start_time": "2024-07-29T19:38:48.827668Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7677 - accuracy: 0.8390\n",
      "Epoch 16: val_loss did not improve from 0.53758\n",
      "74/74 [==============================] - 13s 73ms/step - loss: 0.7670 - accuracy: 0.8391 - val_loss: 0.6958 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7121 - accuracy: 0.8695\n",
      "Epoch 17: val_loss did not improve from 0.53758\n",
      "74/74 [==============================] - 4s 52ms/step - loss: 0.7121 - accuracy: 0.8695 - val_loss: 0.5452 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6763 - accuracy: 0.8720\n",
      "Epoch 18: val_loss did not improve from 0.53758\n",
      "74/74 [==============================] - 4s 52ms/step - loss: 0.6770 - accuracy: 0.8712 - val_loss: 0.6540 - val_accuracy: 0.9337 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.8818\n",
      "Epoch 19: val_loss improved from 0.53758 to 0.48257, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 30s 401ms/step - loss: 0.6212 - accuracy: 0.8818 - val_loss: 0.4826 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.8992\n",
      "Epoch 20: val_loss did not improve from 0.48257\n",
      "74/74 [==============================] - 4s 51ms/step - loss: 0.6023 - accuracy: 0.8992 - val_loss: 0.8018 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.9039\n",
      "Epoch 21: val_loss did not improve from 0.48257\n",
      "74/74 [==============================] - 4s 51ms/step - loss: 0.5906 - accuracy: 0.9039 - val_loss: 0.5810 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.9022\n",
      "Epoch 22: val_loss did not improve from 0.48257\n",
      "74/74 [==============================] - 4s 52ms/step - loss: 0.6004 - accuracy: 0.9022 - val_loss: 0.5445 - val_accuracy: 0.9446 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.9324\n",
      "Epoch 23: val_loss improved from 0.48257 to 0.45792, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 417ms/step - loss: 0.4800 - accuracy: 0.9322 - val_loss: 0.4579 - val_accuracy: 0.9416 - lr: 3.0000e-04\n",
      "Epoch 24/25\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.3723 - accuracy: 0.9469\n",
      "Epoch 24: val_loss improved from 0.45792 to 0.37024, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 29s 398ms/step - loss: 0.3717 - accuracy: 0.9471 - val_loss: 0.3702 - val_accuracy: 0.9575 - lr: 3.0000e-04\n",
      "Epoch 25/25\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.3117 - accuracy: 0.9615\n",
      "Epoch 25: val_loss improved from 0.37024 to 0.32211, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 421ms/step - loss: 0.3109 - accuracy: 0.9615 - val_loss: 0.3221 - val_accuracy: 0.9594 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:41:24.423226Z",
     "start_time": "2024-07-29T19:41:23.416999Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "76e9cd11a6024452",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 35ms/step - loss: 0.5579 - accuracy: 0.8615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5578933358192444, 0.8615384697914124]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:41:38.971385Z",
     "start_time": "2024-07-29T19:41:38.968064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 25\n",
    "for layer in base_model.layers[-75:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:41:40.344954Z",
     "start_time": "2024-07-29T19:41:40.296716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 1602708 (6.11 MB)\n",
      "Non-trainable params: 3388996 (12.93 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:44:27.823351Z",
     "start_time": "2024-07-29T19:41:41.308764Z"
    }
   },
   "cell_type": "code",
   "source": "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.4235 - accuracy: 0.9114\n",
      "Epoch 26: val_loss did not improve from 0.32211\n",
      "74/74 [==============================] - 17s 81ms/step - loss: 0.4242 - accuracy: 0.9111 - val_loss: 0.7964 - val_accuracy: 0.7685 - lr: 3.0000e-04\n",
      "Epoch 27/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.9183\n",
      "Epoch 27: val_loss improved from 0.32211 to 0.30892, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 426ms/step - loss: 0.3826 - accuracy: 0.9183 - val_loss: 0.3089 - val_accuracy: 0.9614 - lr: 3.0000e-04\n",
      "Epoch 28/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.9339\n",
      "Epoch 28: val_loss did not improve from 0.30892\n",
      "74/74 [==============================] - 5s 58ms/step - loss: 0.3423 - accuracy: 0.9339 - val_loss: 0.3647 - val_accuracy: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 29/35\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.9478\n",
      "Epoch 29: val_loss did not improve from 0.30892\n",
      "74/74 [==============================] - 5s 58ms/step - loss: 0.2983 - accuracy: 0.9475 - val_loss: 0.3471 - val_accuracy: 0.9228 - lr: 3.0000e-04\n",
      "Epoch 30/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.9356\n",
      "Epoch 30: val_loss improved from 0.30892 to 0.27983, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 424ms/step - loss: 0.3251 - accuracy: 0.9356 - val_loss: 0.2798 - val_accuracy: 0.9525 - lr: 3.0000e-04\n",
      "Epoch 31/35\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.2921 - accuracy: 0.9491\n",
      "Epoch 31: val_loss improved from 0.27983 to 0.27866, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 32s 435ms/step - loss: 0.2926 - accuracy: 0.9488 - val_loss: 0.2787 - val_accuracy: 0.9575 - lr: 3.0000e-04\n",
      "Epoch 32/35\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.2894 - accuracy: 0.9486\n",
      "Epoch 32: val_loss did not improve from 0.27866\n",
      "74/74 [==============================] - 5s 58ms/step - loss: 0.2885 - accuracy: 0.9492 - val_loss: 0.5900 - val_accuracy: 0.8299 - lr: 3.0000e-04\n",
      "Epoch 33/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9521\n",
      "Epoch 33: val_loss did not improve from 0.27866\n",
      "74/74 [==============================] - 5s 59ms/step - loss: 0.2755 - accuracy: 0.9521 - val_loss: 0.4046 - val_accuracy: 0.9070 - lr: 3.0000e-04\n",
      "Epoch 34/35\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.9576\n",
      "Epoch 34: val_loss did not improve from 0.27866\n",
      "74/74 [==============================] - 5s 58ms/step - loss: 0.2527 - accuracy: 0.9581 - val_loss: 0.3266 - val_accuracy: 0.9416 - lr: 3.0000e-04\n",
      "Epoch 35/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9759\n",
      "Epoch 35: val_loss improved from 0.27866 to 0.20760, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 426ms/step - loss: 0.2044 - accuracy: 0.9759 - val_loss: 0.2076 - val_accuracy: 0.9763 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:44:34.946557Z",
     "start_time": "2024-07-29T19:44:33.915079Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "cb9409c4dba63f27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 36ms/step - loss: 0.4785 - accuracy: 0.8899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4785414934158325, 0.8899408578872681]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:44:49.213684Z",
     "start_time": "2024-07-29T19:44:49.196401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 35\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-125]:\n",
    "    layer.trainable = False"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:44:51.128251Z",
     "start_time": "2024-07-29T19:44:51.079745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000075), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 2483940 (9.48 MB)\n",
      "Non-trainable params: 2507764 (9.57 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:46:55.504275Z",
     "start_time": "2024-07-29T19:44:52.758073Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/45\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9816\n",
      "Epoch 36: val_loss did not improve from 0.20760\n",
      "74/74 [==============================] - 24s 129ms/step - loss: 0.1771 - accuracy: 0.9814 - val_loss: 0.3641 - val_accuracy: 0.9110 - lr: 7.5000e-05\n",
      "Epoch 37/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9890\n",
      "Epoch 37: val_loss did not improve from 0.20760\n",
      "74/74 [==============================] - 5s 66ms/step - loss: 0.1477 - accuracy: 0.9890 - val_loss: 0.2148 - val_accuracy: 0.9644 - lr: 7.5000e-05\n",
      "Epoch 38/45\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9863\n",
      "Epoch 38: val_loss improved from 0.20760 to 0.20575, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 31s 424ms/step - loss: 0.1404 - accuracy: 0.9864 - val_loss: 0.2057 - val_accuracy: 0.9664 - lr: 7.5000e-05\n",
      "Epoch 39/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9750\n",
      "Epoch 39: val_loss did not improve from 0.20575\n",
      "74/74 [==============================] - 5s 66ms/step - loss: 0.1672 - accuracy: 0.9750 - val_loss: 0.2169 - val_accuracy: 0.9565 - lr: 7.5000e-05\n",
      "Epoch 40/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9864\n",
      "Epoch 40: val_loss did not improve from 0.20575\n",
      "74/74 [==============================] - 5s 67ms/step - loss: 0.1327 - accuracy: 0.9864 - val_loss: 0.2306 - val_accuracy: 0.9515 - lr: 7.5000e-05\n",
      "Epoch 41/45\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9820\n",
      "Epoch 41: val_loss improved from 0.20575 to 0.16067, saving model to Trained_Models/Nasnet\n",
      "74/74 [==============================] - 32s 427ms/step - loss: 0.1490 - accuracy: 0.9814 - val_loss: 0.1607 - val_accuracy: 0.9753 - lr: 7.5000e-05\n",
      "Epoch 42/45\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.1247 - accuracy: 0.9897\n",
      "Epoch 42: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 5s 64ms/step - loss: 0.1248 - accuracy: 0.9894 - val_loss: 0.2043 - val_accuracy: 0.9644 - lr: 7.5000e-05\n",
      "Epoch 43/45\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9854\n",
      "Epoch 43: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 5s 64ms/step - loss: 0.1312 - accuracy: 0.9852 - val_loss: 0.2400 - val_accuracy: 0.9545 - lr: 7.5000e-05\n",
      "Epoch 44/45\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9859\n",
      "Epoch 44: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 5s 65ms/step - loss: 0.1248 - accuracy: 0.9860 - val_loss: 0.2243 - val_accuracy: 0.9594 - lr: 7.5000e-05\n",
      "Epoch 45/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9962\n",
      "Epoch 45: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 5s 65ms/step - loss: 0.0970 - accuracy: 0.9962 - val_loss: 0.1940 - val_accuracy: 0.9664 - lr: 2.2500e-05\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:47:35.569625Z",
     "start_time": "2024-07-29T19:47:34.535022Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "572beefd899e12a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 35ms/step - loss: 0.4816 - accuracy: 0.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48157748579978943, 0.8828402161598206]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:47:38.807369Z",
     "start_time": "2024-07-29T19:47:38.801646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 45\n",
    "for layer in base_model.layers[-300:]:\n",
    "    layer.trainable = True"
   ],
   "id": "93ad3cc030c9c69",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:47:39.712985Z",
     "start_time": "2024-07-29T19:47:39.665045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000025), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "9ed4bf4a63f90d77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 4121356 (15.72 MB)\n",
      "Non-trainable params: 870348 (3.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:49:16.600177Z",
     "start_time": "2024-07-29T19:47:41.082633Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "b0794490c20e0209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9856\n",
      "Epoch 46: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 36s 107ms/step - loss: 0.1190 - accuracy: 0.9856 - val_loss: 0.2369 - val_accuracy: 0.9585 - lr: 2.5000e-05\n",
      "Epoch 47/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9894\n",
      "Epoch 47: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.1114 - accuracy: 0.9894 - val_loss: 0.4673 - val_accuracy: 0.8724 - lr: 2.5000e-05\n",
      "Epoch 48/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9886\n",
      "Epoch 48: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.1195 - accuracy: 0.9886 - val_loss: 0.2321 - val_accuracy: 0.9525 - lr: 2.5000e-05\n",
      "Epoch 49/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9936\n",
      "Epoch 49: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.0976 - accuracy: 0.9936 - val_loss: 0.1823 - val_accuracy: 0.9703 - lr: 2.5000e-05\n",
      "Epoch 50/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9941\n",
      "Epoch 50: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 84ms/step - loss: 0.0975 - accuracy: 0.9941 - val_loss: 0.1955 - val_accuracy: 0.9644 - lr: 2.5000e-05\n",
      "Epoch 51/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9915\n",
      "Epoch 51: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 84ms/step - loss: 0.1015 - accuracy: 0.9915 - val_loss: 0.2076 - val_accuracy: 0.9624 - lr: 2.5000e-05\n",
      "Epoch 52/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9924\n",
      "Epoch 52: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 91ms/step - loss: 0.0962 - accuracy: 0.9924 - val_loss: 0.1759 - val_accuracy: 0.9733 - lr: 2.5000e-05\n",
      "Epoch 53/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9920\n",
      "Epoch 53: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 88ms/step - loss: 0.1000 - accuracy: 0.9920 - val_loss: 0.2659 - val_accuracy: 0.9505 - lr: 2.5000e-05\n",
      "Epoch 54/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9915\n",
      "Epoch 54: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 89ms/step - loss: 0.0947 - accuracy: 0.9915 - val_loss: 0.2483 - val_accuracy: 0.9525 - lr: 2.5000e-05\n",
      "Epoch 55/55\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9957\n",
      "Epoch 55: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.0838 - accuracy: 0.9958 - val_loss: 0.2698 - val_accuracy: 0.9496 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:49:44.279319Z",
     "start_time": "2024-07-29T19:49:44.269349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 55\n",
    "for layer in base_model.layers[-700:]:\n",
    "    layer.trainable = True"
   ],
   "id": "65b379ec652de956",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:49:45.195948Z",
     "start_time": "2024-07-29T19:49:45.117047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000025), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "c49c24beb9980801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 4937116 (18.83 MB)\n",
      "Non-trainable params: 54588 (213.23 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:51:58.666869Z",
     "start_time": "2024-07-29T19:49:47.229317Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "5fd98f0c46842888",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9814\n",
      "Epoch 56: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 55s 148ms/step - loss: 0.1236 - accuracy: 0.9814 - val_loss: 0.3335 - val_accuracy: 0.9308 - lr: 2.5000e-05\n",
      "Epoch 57/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9809\n",
      "Epoch 57: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 0.1372 - accuracy: 0.9809 - val_loss: 0.1625 - val_accuracy: 0.9763 - lr: 2.5000e-05\n",
      "Epoch 58/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9903\n",
      "Epoch 58: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 108ms/step - loss: 0.1013 - accuracy: 0.9903 - val_loss: 0.2233 - val_accuracy: 0.9594 - lr: 2.5000e-05\n",
      "Epoch 59/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9911\n",
      "Epoch 59: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 108ms/step - loss: 0.0955 - accuracy: 0.9911 - val_loss: 0.2628 - val_accuracy: 0.9476 - lr: 2.5000e-05\n",
      "Epoch 60/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9932\n",
      "Epoch 60: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 0.0850 - accuracy: 0.9932 - val_loss: 0.2176 - val_accuracy: 0.9585 - lr: 2.5000e-05\n",
      "Epoch 61/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9953\n",
      "Epoch 61: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 9s 111ms/step - loss: 0.0802 - accuracy: 0.9953 - val_loss: 0.2081 - val_accuracy: 0.9624 - lr: 7.5000e-06\n",
      "Epoch 62/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9975\n",
      "Epoch 62: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 9s 113ms/step - loss: 0.0740 - accuracy: 0.9975 - val_loss: 0.1655 - val_accuracy: 0.9763 - lr: 7.5000e-06\n",
      "Epoch 63/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9979\n",
      "Epoch 63: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 0.0718 - accuracy: 0.9979 - val_loss: 0.1921 - val_accuracy: 0.9654 - lr: 7.5000e-06\n",
      "Epoch 64/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9987\n",
      "Epoch 64: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 9s 113ms/step - loss: 0.0699 - accuracy: 0.9987 - val_loss: 0.1884 - val_accuracy: 0.9683 - lr: 2.2500e-06\n",
      "Epoch 65/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9975\n",
      "Epoch 65: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 9s 111ms/step - loss: 0.0735 - accuracy: 0.9975 - val_loss: 0.1921 - val_accuracy: 0.9674 - lr: 2.2500e-06\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:51:59.680306Z",
     "start_time": "2024-07-29T19:51:58.667598Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "7accf2968e67a759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 35ms/step - loss: 0.4736 - accuracy: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47362667322158813, 0.892307698726654]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:29:20.860931Z",
     "start_time": "2024-07-29T18:29:20.592463Z"
    }
   },
   "cell_type": "code",
   "source": "resnet = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m resnet \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/saving/saving_api.py:262\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    255\u001B[0m         filepath,\n\u001B[1;32m    256\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[1;32m    258\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[1;32m    259\u001B[0m     )\n\u001B[1;32m    261\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[0;32m--> 234\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[1;32m    235\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    236\u001B[0m         )\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[1;32m    239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[1;32m    240\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[1;32m    241\u001B[0m         )\n",
      "\u001B[0;31mOSError\u001B[0m: No file or directory found at /home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resnet.evaluate(val_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
