{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:38.940016Z",
     "start_time": "2024-07-29T19:52:36.072403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:52:36.254244: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 15:52:36.280970: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 15:52:36.280998: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 15:52:36.281024: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 15:52:36.290746: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 15:52:37.123888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:52:38.886984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:38.931821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:38.934043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:38.936044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:38.944002Z",
     "start_time": "2024-07-29T19:52:38.940685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:38.947021Z",
     "start_time": "2024-07-29T19:52:38.944504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:38.950934Z",
     "start_time": "2024-07-29T19:52:38.947754Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:38.953370Z",
     "start_time": "2024-07-29T19:52:38.951639Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:39.856962Z",
     "start_time": "2024-07-29T19:52:38.953933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:52:39.009035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:39.011127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:39.012915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:39.138964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:39.140849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:39.142584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 15:52:39.144257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5975 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-29 15:52:39.297106: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:39.859738Z",
     "start_time": "2024-07-29T19:52:39.857626Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:40.772462Z",
     "start_time": "2024-07-29T19:52:40.770384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.nasnet.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:42.037601Z",
     "start_time": "2024-07-29T19:52:42.001199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:52:43.017743Z",
     "start_time": "2024-07-29T19:52:43.014605Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:14.746529Z",
     "start_time": "2024-07-29T19:52:49.628609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.NASNetLarge(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
      "343610240/343610240 [==============================] - 21s 0us/step\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:16.160090Z",
     "start_time": "2024-07-29T19:53:16.153374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: stem_conv1, False\n",
      "Layer: stem_bn1, False\n",
      "Layer: activation, False\n",
      "Layer: reduction_conv_1_stem_1, False\n",
      "Layer: reduction_bn_1_stem_1, False\n",
      "Layer: activation_1, False\n",
      "Layer: activation_3, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_stem_1, False\n",
      "Layer: separable_conv_1_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_1_reduction_right1_stem_1, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_stem_1, False\n",
      "Layer: activation_2, False\n",
      "Layer: activation_4, False\n",
      "Layer: separable_conv_2_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_2_reduction_right1_stem_1, False\n",
      "Layer: activation_5, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_stem_1, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_stem_1, False\n",
      "Layer: activation_7, False\n",
      "Layer: reduction_add_1_stem_1, False\n",
      "Layer: separable_conv_1_reduction_right2_stem_1, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_stem_1, False\n",
      "Layer: activation_9, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_stem_1, False\n",
      "Layer: separable_conv_1_reduction_right3_stem_1, False\n",
      "Layer: separable_conv_1_reduction_left4_stem_1, False\n",
      "Layer: activation_6, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_stem_1, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_stem_1, False\n",
      "Layer: reduction_pad_1_stem_1, False\n",
      "Layer: separable_conv_2_reduction_right2_stem_1, False\n",
      "Layer: activation_8, False\n",
      "Layer: activation_10, False\n",
      "Layer: reduction_left2_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_stem_1, False\n",
      "Layer: separable_conv_2_reduction_right3_stem_1, False\n",
      "Layer: separable_conv_2_reduction_left4_stem_1, False\n",
      "Layer: adjust_relu_1_stem_2, False\n",
      "Layer: reduction_add_2_stem_1, False\n",
      "Layer: reduction_left3_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_stem_1, False\n",
      "Layer: reduction_left4_stem_1, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_stem_1, False\n",
      "Layer: reduction_right5_stem_1, False\n",
      "Layer: zero_padding2d, False\n",
      "Layer: reduction_add3_stem_1, False\n",
      "Layer: add, False\n",
      "Layer: reduction_add4_stem_1, False\n",
      "Layer: cropping2d, False\n",
      "Layer: reduction_concat_stem_1, False\n",
      "Layer: adjust_avg_pool_1_stem_2, False\n",
      "Layer: adjust_avg_pool_2_stem_2, False\n",
      "Layer: activation_11, False\n",
      "Layer: adjust_conv_1_stem_2, False\n",
      "Layer: adjust_conv_2_stem_2, False\n",
      "Layer: reduction_conv_1_stem_2, False\n",
      "Layer: concatenate, False\n",
      "Layer: reduction_bn_1_stem_2, False\n",
      "Layer: adjust_bn_stem_2, False\n",
      "Layer: activation_12, False\n",
      "Layer: activation_14, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_stem_2, False\n",
      "Layer: separable_conv_1_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_1_reduction_right1_stem_2, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_stem_2, False\n",
      "Layer: activation_13, False\n",
      "Layer: activation_15, False\n",
      "Layer: separable_conv_2_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_2_reduction_right1_stem_2, False\n",
      "Layer: activation_16, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_stem_2, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_stem_2, False\n",
      "Layer: activation_18, False\n",
      "Layer: reduction_add_1_stem_2, False\n",
      "Layer: separable_conv_1_reduction_right2_stem_2, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_stem_2, False\n",
      "Layer: activation_20, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_stem_2, False\n",
      "Layer: separable_conv_1_reduction_right3_stem_2, False\n",
      "Layer: separable_conv_1_reduction_left4_stem_2, False\n",
      "Layer: activation_17, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_stem_2, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_stem_2, False\n",
      "Layer: reduction_pad_1_stem_2, False\n",
      "Layer: separable_conv_2_reduction_right2_stem_2, False\n",
      "Layer: activation_19, False\n",
      "Layer: activation_21, False\n",
      "Layer: reduction_left2_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_stem_2, False\n",
      "Layer: separable_conv_2_reduction_right3_stem_2, False\n",
      "Layer: separable_conv_2_reduction_left4_stem_2, False\n",
      "Layer: adjust_relu_1_0, False\n",
      "Layer: reduction_add_2_stem_2, False\n",
      "Layer: reduction_left3_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_stem_2, False\n",
      "Layer: reduction_left4_stem_2, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_stem_2, False\n",
      "Layer: reduction_right5_stem_2, False\n",
      "Layer: zero_padding2d_1, False\n",
      "Layer: reduction_add3_stem_2, False\n",
      "Layer: add_1, False\n",
      "Layer: reduction_add4_stem_2, False\n",
      "Layer: cropping2d_1, False\n",
      "Layer: reduction_concat_stem_2, False\n",
      "Layer: adjust_avg_pool_1_0, False\n",
      "Layer: adjust_avg_pool_2_0, False\n",
      "Layer: adjust_conv_1_0, False\n",
      "Layer: adjust_conv_2_0, False\n",
      "Layer: activation_22, False\n",
      "Layer: concatenate_1, False\n",
      "Layer: normal_conv_1_0, False\n",
      "Layer: adjust_bn_0, False\n",
      "Layer: normal_bn_1_0, False\n",
      "Layer: activation_23, False\n",
      "Layer: activation_25, False\n",
      "Layer: activation_27, False\n",
      "Layer: activation_29, False\n",
      "Layer: activation_31, False\n",
      "Layer: separable_conv_1_normal_left1_0, False\n",
      "Layer: separable_conv_1_normal_right1_0, False\n",
      "Layer: separable_conv_1_normal_left2_0, False\n",
      "Layer: separable_conv_1_normal_right2_0, False\n",
      "Layer: separable_conv_1_normal_left5_0, False\n",
      "Layer: separable_conv_1_bn_normal_left1_0, False\n",
      "Layer: separable_conv_1_bn_normal_right1_0, False\n",
      "Layer: separable_conv_1_bn_normal_left2_0, False\n",
      "Layer: separable_conv_1_bn_normal_right2_0, False\n",
      "Layer: separable_conv_1_bn_normal_left5_0, False\n",
      "Layer: activation_24, False\n",
      "Layer: activation_26, False\n",
      "Layer: activation_28, False\n",
      "Layer: activation_30, False\n",
      "Layer: activation_32, False\n",
      "Layer: separable_conv_2_normal_left1_0, False\n",
      "Layer: separable_conv_2_normal_right1_0, False\n",
      "Layer: separable_conv_2_normal_left2_0, False\n",
      "Layer: separable_conv_2_normal_right2_0, False\n",
      "Layer: separable_conv_2_normal_left5_0, False\n",
      "Layer: separable_conv_2_bn_normal_left1_0, False\n",
      "Layer: separable_conv_2_bn_normal_right1_0, False\n",
      "Layer: separable_conv_2_bn_normal_left2_0, False\n",
      "Layer: separable_conv_2_bn_normal_right2_0, False\n",
      "Layer: normal_left3_0, False\n",
      "Layer: normal_left4_0, False\n",
      "Layer: normal_right4_0, False\n",
      "Layer: separable_conv_2_bn_normal_left5_0, False\n",
      "Layer: normal_add_1_0, False\n",
      "Layer: normal_add_2_0, False\n",
      "Layer: normal_add_3_0, False\n",
      "Layer: normal_add_4_0, False\n",
      "Layer: normal_add_5_0, False\n",
      "Layer: normal_concat_0, False\n",
      "Layer: activation_33, False\n",
      "Layer: activation_34, False\n",
      "Layer: adjust_conv_projection_1, False\n",
      "Layer: normal_conv_1_1, False\n",
      "Layer: adjust_bn_1, False\n",
      "Layer: normal_bn_1_1, False\n",
      "Layer: activation_35, False\n",
      "Layer: activation_37, False\n",
      "Layer: activation_39, False\n",
      "Layer: activation_41, False\n",
      "Layer: activation_43, False\n",
      "Layer: separable_conv_1_normal_left1_1, False\n",
      "Layer: separable_conv_1_normal_right1_1, False\n",
      "Layer: separable_conv_1_normal_left2_1, False\n",
      "Layer: separable_conv_1_normal_right2_1, False\n",
      "Layer: separable_conv_1_normal_left5_1, False\n",
      "Layer: separable_conv_1_bn_normal_left1_1, False\n",
      "Layer: separable_conv_1_bn_normal_right1_1, False\n",
      "Layer: separable_conv_1_bn_normal_left2_1, False\n",
      "Layer: separable_conv_1_bn_normal_right2_1, False\n",
      "Layer: separable_conv_1_bn_normal_left5_1, False\n",
      "Layer: activation_36, False\n",
      "Layer: activation_38, False\n",
      "Layer: activation_40, False\n",
      "Layer: activation_42, False\n",
      "Layer: activation_44, False\n",
      "Layer: separable_conv_2_normal_left1_1, False\n",
      "Layer: separable_conv_2_normal_right1_1, False\n",
      "Layer: separable_conv_2_normal_left2_1, False\n",
      "Layer: separable_conv_2_normal_right2_1, False\n",
      "Layer: separable_conv_2_normal_left5_1, False\n",
      "Layer: separable_conv_2_bn_normal_left1_1, False\n",
      "Layer: separable_conv_2_bn_normal_right1_1, False\n",
      "Layer: separable_conv_2_bn_normal_left2_1, False\n",
      "Layer: separable_conv_2_bn_normal_right2_1, False\n",
      "Layer: normal_left3_1, False\n",
      "Layer: normal_left4_1, False\n",
      "Layer: normal_right4_1, False\n",
      "Layer: separable_conv_2_bn_normal_left5_1, False\n",
      "Layer: normal_add_1_1, False\n",
      "Layer: normal_add_2_1, False\n",
      "Layer: normal_add_3_1, False\n",
      "Layer: normal_add_4_1, False\n",
      "Layer: normal_add_5_1, False\n",
      "Layer: normal_concat_1, False\n",
      "Layer: activation_45, False\n",
      "Layer: activation_46, False\n",
      "Layer: adjust_conv_projection_2, False\n",
      "Layer: normal_conv_1_2, False\n",
      "Layer: adjust_bn_2, False\n",
      "Layer: normal_bn_1_2, False\n",
      "Layer: activation_47, False\n",
      "Layer: activation_49, False\n",
      "Layer: activation_51, False\n",
      "Layer: activation_53, False\n",
      "Layer: activation_55, False\n",
      "Layer: separable_conv_1_normal_left1_2, False\n",
      "Layer: separable_conv_1_normal_right1_2, False\n",
      "Layer: separable_conv_1_normal_left2_2, False\n",
      "Layer: separable_conv_1_normal_right2_2, False\n",
      "Layer: separable_conv_1_normal_left5_2, False\n",
      "Layer: separable_conv_1_bn_normal_left1_2, False\n",
      "Layer: separable_conv_1_bn_normal_right1_2, False\n",
      "Layer: separable_conv_1_bn_normal_left2_2, False\n",
      "Layer: separable_conv_1_bn_normal_right2_2, False\n",
      "Layer: separable_conv_1_bn_normal_left5_2, False\n",
      "Layer: activation_48, False\n",
      "Layer: activation_50, False\n",
      "Layer: activation_52, False\n",
      "Layer: activation_54, False\n",
      "Layer: activation_56, False\n",
      "Layer: separable_conv_2_normal_left1_2, False\n",
      "Layer: separable_conv_2_normal_right1_2, False\n",
      "Layer: separable_conv_2_normal_left2_2, False\n",
      "Layer: separable_conv_2_normal_right2_2, False\n",
      "Layer: separable_conv_2_normal_left5_2, False\n",
      "Layer: separable_conv_2_bn_normal_left1_2, False\n",
      "Layer: separable_conv_2_bn_normal_right1_2, False\n",
      "Layer: separable_conv_2_bn_normal_left2_2, False\n",
      "Layer: separable_conv_2_bn_normal_right2_2, False\n",
      "Layer: normal_left3_2, False\n",
      "Layer: normal_left4_2, False\n",
      "Layer: normal_right4_2, False\n",
      "Layer: separable_conv_2_bn_normal_left5_2, False\n",
      "Layer: normal_add_1_2, False\n",
      "Layer: normal_add_2_2, False\n",
      "Layer: normal_add_3_2, False\n",
      "Layer: normal_add_4_2, False\n",
      "Layer: normal_add_5_2, False\n",
      "Layer: normal_concat_2, False\n",
      "Layer: activation_57, False\n",
      "Layer: activation_58, False\n",
      "Layer: adjust_conv_projection_3, False\n",
      "Layer: normal_conv_1_3, False\n",
      "Layer: adjust_bn_3, False\n",
      "Layer: normal_bn_1_3, False\n",
      "Layer: activation_59, False\n",
      "Layer: activation_61, False\n",
      "Layer: activation_63, False\n",
      "Layer: activation_65, False\n",
      "Layer: activation_67, False\n",
      "Layer: separable_conv_1_normal_left1_3, False\n",
      "Layer: separable_conv_1_normal_right1_3, False\n",
      "Layer: separable_conv_1_normal_left2_3, False\n",
      "Layer: separable_conv_1_normal_right2_3, False\n",
      "Layer: separable_conv_1_normal_left5_3, False\n",
      "Layer: separable_conv_1_bn_normal_left1_3, False\n",
      "Layer: separable_conv_1_bn_normal_right1_3, False\n",
      "Layer: separable_conv_1_bn_normal_left2_3, False\n",
      "Layer: separable_conv_1_bn_normal_right2_3, False\n",
      "Layer: separable_conv_1_bn_normal_left5_3, False\n",
      "Layer: activation_60, False\n",
      "Layer: activation_62, False\n",
      "Layer: activation_64, False\n",
      "Layer: activation_66, False\n",
      "Layer: activation_68, False\n",
      "Layer: separable_conv_2_normal_left1_3, False\n",
      "Layer: separable_conv_2_normal_right1_3, False\n",
      "Layer: separable_conv_2_normal_left2_3, False\n",
      "Layer: separable_conv_2_normal_right2_3, False\n",
      "Layer: separable_conv_2_normal_left5_3, False\n",
      "Layer: separable_conv_2_bn_normal_left1_3, False\n",
      "Layer: separable_conv_2_bn_normal_right1_3, False\n",
      "Layer: separable_conv_2_bn_normal_left2_3, False\n",
      "Layer: separable_conv_2_bn_normal_right2_3, False\n",
      "Layer: normal_left3_3, False\n",
      "Layer: normal_left4_3, False\n",
      "Layer: normal_right4_3, False\n",
      "Layer: separable_conv_2_bn_normal_left5_3, False\n",
      "Layer: normal_add_1_3, False\n",
      "Layer: normal_add_2_3, False\n",
      "Layer: normal_add_3_3, False\n",
      "Layer: normal_add_4_3, False\n",
      "Layer: normal_add_5_3, False\n",
      "Layer: normal_concat_3, False\n",
      "Layer: activation_69, False\n",
      "Layer: activation_70, False\n",
      "Layer: adjust_conv_projection_4, False\n",
      "Layer: normal_conv_1_4, False\n",
      "Layer: adjust_bn_4, False\n",
      "Layer: normal_bn_1_4, False\n",
      "Layer: activation_71, False\n",
      "Layer: activation_73, False\n",
      "Layer: activation_75, False\n",
      "Layer: activation_77, False\n",
      "Layer: activation_79, False\n",
      "Layer: separable_conv_1_normal_left1_4, False\n",
      "Layer: separable_conv_1_normal_right1_4, False\n",
      "Layer: separable_conv_1_normal_left2_4, False\n",
      "Layer: separable_conv_1_normal_right2_4, False\n",
      "Layer: separable_conv_1_normal_left5_4, False\n",
      "Layer: separable_conv_1_bn_normal_left1_4, False\n",
      "Layer: separable_conv_1_bn_normal_right1_4, False\n",
      "Layer: separable_conv_1_bn_normal_left2_4, False\n",
      "Layer: separable_conv_1_bn_normal_right2_4, False\n",
      "Layer: separable_conv_1_bn_normal_left5_4, False\n",
      "Layer: activation_72, False\n",
      "Layer: activation_74, False\n",
      "Layer: activation_76, False\n",
      "Layer: activation_78, False\n",
      "Layer: activation_80, False\n",
      "Layer: separable_conv_2_normal_left1_4, False\n",
      "Layer: separable_conv_2_normal_right1_4, False\n",
      "Layer: separable_conv_2_normal_left2_4, False\n",
      "Layer: separable_conv_2_normal_right2_4, False\n",
      "Layer: separable_conv_2_normal_left5_4, False\n",
      "Layer: separable_conv_2_bn_normal_left1_4, False\n",
      "Layer: separable_conv_2_bn_normal_right1_4, False\n",
      "Layer: separable_conv_2_bn_normal_left2_4, False\n",
      "Layer: separable_conv_2_bn_normal_right2_4, False\n",
      "Layer: normal_left3_4, False\n",
      "Layer: normal_left4_4, False\n",
      "Layer: normal_right4_4, False\n",
      "Layer: separable_conv_2_bn_normal_left5_4, False\n",
      "Layer: normal_add_1_4, False\n",
      "Layer: normal_add_2_4, False\n",
      "Layer: normal_add_3_4, False\n",
      "Layer: normal_add_4_4, False\n",
      "Layer: normal_add_5_4, False\n",
      "Layer: normal_concat_4, False\n",
      "Layer: activation_81, False\n",
      "Layer: activation_82, False\n",
      "Layer: adjust_conv_projection_5, False\n",
      "Layer: normal_conv_1_5, False\n",
      "Layer: adjust_bn_5, False\n",
      "Layer: normal_bn_1_5, False\n",
      "Layer: activation_83, False\n",
      "Layer: activation_85, False\n",
      "Layer: activation_87, False\n",
      "Layer: activation_89, False\n",
      "Layer: activation_91, False\n",
      "Layer: separable_conv_1_normal_left1_5, False\n",
      "Layer: separable_conv_1_normal_right1_5, False\n",
      "Layer: separable_conv_1_normal_left2_5, False\n",
      "Layer: separable_conv_1_normal_right2_5, False\n",
      "Layer: separable_conv_1_normal_left5_5, False\n",
      "Layer: separable_conv_1_bn_normal_left1_5, False\n",
      "Layer: separable_conv_1_bn_normal_right1_5, False\n",
      "Layer: separable_conv_1_bn_normal_left2_5, False\n",
      "Layer: separable_conv_1_bn_normal_right2_5, False\n",
      "Layer: separable_conv_1_bn_normal_left5_5, False\n",
      "Layer: activation_84, False\n",
      "Layer: activation_86, False\n",
      "Layer: activation_88, False\n",
      "Layer: activation_90, False\n",
      "Layer: activation_92, False\n",
      "Layer: separable_conv_2_normal_left1_5, False\n",
      "Layer: separable_conv_2_normal_right1_5, False\n",
      "Layer: separable_conv_2_normal_left2_5, False\n",
      "Layer: separable_conv_2_normal_right2_5, False\n",
      "Layer: separable_conv_2_normal_left5_5, False\n",
      "Layer: separable_conv_2_bn_normal_left1_5, False\n",
      "Layer: separable_conv_2_bn_normal_right1_5, False\n",
      "Layer: separable_conv_2_bn_normal_left2_5, False\n",
      "Layer: separable_conv_2_bn_normal_right2_5, False\n",
      "Layer: normal_left3_5, False\n",
      "Layer: normal_left4_5, False\n",
      "Layer: normal_right4_5, False\n",
      "Layer: separable_conv_2_bn_normal_left5_5, False\n",
      "Layer: normal_add_1_5, False\n",
      "Layer: normal_add_2_5, False\n",
      "Layer: normal_add_3_5, False\n",
      "Layer: normal_add_4_5, False\n",
      "Layer: normal_add_5_5, False\n",
      "Layer: normal_concat_5, False\n",
      "Layer: activation_94, False\n",
      "Layer: activation_93, False\n",
      "Layer: reduction_conv_1_reduce_6, False\n",
      "Layer: adjust_conv_projection_reduce_6, False\n",
      "Layer: reduction_bn_1_reduce_6, False\n",
      "Layer: adjust_bn_reduce_6, False\n",
      "Layer: activation_95, False\n",
      "Layer: activation_97, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_reduce_6, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_reduce_6, False\n",
      "Layer: separable_conv_1_reduction_left1_reduce_6, False\n",
      "Layer: separable_conv_1_reduction_right1_reduce_6, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_reduce_6, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_reduce_6, False\n",
      "Layer: activation_96, False\n",
      "Layer: activation_98, False\n",
      "Layer: separable_conv_2_reduction_left1_reduce_6, False\n",
      "Layer: separable_conv_2_reduction_right1_reduce_6, False\n",
      "Layer: activation_99, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_reduce_6, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_reduce_6, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_reduce_6, False\n",
      "Layer: activation_101, False\n",
      "Layer: reduction_add_1_reduce_6, False\n",
      "Layer: separable_conv_1_reduction_right2_reduce_6, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_reduce_6, False\n",
      "Layer: activation_103, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_reduce_6, False\n",
      "Layer: separable_conv_1_reduction_right3_reduce_6, False\n",
      "Layer: separable_conv_1_reduction_left4_reduce_6, False\n",
      "Layer: activation_100, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_reduce_6, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_reduce_6, False\n",
      "Layer: reduction_pad_1_reduce_6, False\n",
      "Layer: separable_conv_2_reduction_right2_reduce_6, False\n",
      "Layer: activation_102, False\n",
      "Layer: activation_104, False\n",
      "Layer: reduction_left2_reduce_6, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_reduce_6, False\n",
      "Layer: separable_conv_2_reduction_right3_reduce_6, False\n",
      "Layer: separable_conv_2_reduction_left4_reduce_6, False\n",
      "Layer: adjust_relu_1_7, False\n",
      "Layer: reduction_add_2_reduce_6, False\n",
      "Layer: reduction_left3_reduce_6, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_reduce_6, False\n",
      "Layer: reduction_left4_reduce_6, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_reduce_6, False\n",
      "Layer: reduction_right5_reduce_6, False\n",
      "Layer: zero_padding2d_2, False\n",
      "Layer: reduction_add3_reduce_6, False\n",
      "Layer: add_2, False\n",
      "Layer: reduction_add4_reduce_6, False\n",
      "Layer: cropping2d_2, False\n",
      "Layer: reduction_concat_reduce_6, False\n",
      "Layer: adjust_avg_pool_1_7, False\n",
      "Layer: adjust_avg_pool_2_7, False\n",
      "Layer: adjust_conv_1_7, False\n",
      "Layer: adjust_conv_2_7, False\n",
      "Layer: activation_105, False\n",
      "Layer: concatenate_2, False\n",
      "Layer: normal_conv_1_7, False\n",
      "Layer: adjust_bn_7, False\n",
      "Layer: normal_bn_1_7, False\n",
      "Layer: activation_106, False\n",
      "Layer: activation_108, False\n",
      "Layer: activation_110, False\n",
      "Layer: activation_112, False\n",
      "Layer: activation_114, False\n",
      "Layer: separable_conv_1_normal_left1_7, False\n",
      "Layer: separable_conv_1_normal_right1_7, False\n",
      "Layer: separable_conv_1_normal_left2_7, False\n",
      "Layer: separable_conv_1_normal_right2_7, False\n",
      "Layer: separable_conv_1_normal_left5_7, False\n",
      "Layer: separable_conv_1_bn_normal_left1_7, False\n",
      "Layer: separable_conv_1_bn_normal_right1_7, False\n",
      "Layer: separable_conv_1_bn_normal_left2_7, False\n",
      "Layer: separable_conv_1_bn_normal_right2_7, False\n",
      "Layer: separable_conv_1_bn_normal_left5_7, False\n",
      "Layer: activation_107, False\n",
      "Layer: activation_109, False\n",
      "Layer: activation_111, False\n",
      "Layer: activation_113, False\n",
      "Layer: activation_115, False\n",
      "Layer: separable_conv_2_normal_left1_7, False\n",
      "Layer: separable_conv_2_normal_right1_7, False\n",
      "Layer: separable_conv_2_normal_left2_7, False\n",
      "Layer: separable_conv_2_normal_right2_7, False\n",
      "Layer: separable_conv_2_normal_left5_7, False\n",
      "Layer: separable_conv_2_bn_normal_left1_7, False\n",
      "Layer: separable_conv_2_bn_normal_right1_7, False\n",
      "Layer: separable_conv_2_bn_normal_left2_7, False\n",
      "Layer: separable_conv_2_bn_normal_right2_7, False\n",
      "Layer: normal_left3_7, False\n",
      "Layer: normal_left4_7, False\n",
      "Layer: normal_right4_7, False\n",
      "Layer: separable_conv_2_bn_normal_left5_7, False\n",
      "Layer: normal_add_1_7, False\n",
      "Layer: normal_add_2_7, False\n",
      "Layer: normal_add_3_7, False\n",
      "Layer: normal_add_4_7, False\n",
      "Layer: normal_add_5_7, False\n",
      "Layer: normal_concat_7, False\n",
      "Layer: activation_116, False\n",
      "Layer: activation_117, False\n",
      "Layer: adjust_conv_projection_8, False\n",
      "Layer: normal_conv_1_8, False\n",
      "Layer: adjust_bn_8, False\n",
      "Layer: normal_bn_1_8, False\n",
      "Layer: activation_118, False\n",
      "Layer: activation_120, False\n",
      "Layer: activation_122, False\n",
      "Layer: activation_124, False\n",
      "Layer: activation_126, False\n",
      "Layer: separable_conv_1_normal_left1_8, False\n",
      "Layer: separable_conv_1_normal_right1_8, False\n",
      "Layer: separable_conv_1_normal_left2_8, False\n",
      "Layer: separable_conv_1_normal_right2_8, False\n",
      "Layer: separable_conv_1_normal_left5_8, False\n",
      "Layer: separable_conv_1_bn_normal_left1_8, False\n",
      "Layer: separable_conv_1_bn_normal_right1_8, False\n",
      "Layer: separable_conv_1_bn_normal_left2_8, False\n",
      "Layer: separable_conv_1_bn_normal_right2_8, False\n",
      "Layer: separable_conv_1_bn_normal_left5_8, False\n",
      "Layer: activation_119, False\n",
      "Layer: activation_121, False\n",
      "Layer: activation_123, False\n",
      "Layer: activation_125, False\n",
      "Layer: activation_127, False\n",
      "Layer: separable_conv_2_normal_left1_8, False\n",
      "Layer: separable_conv_2_normal_right1_8, False\n",
      "Layer: separable_conv_2_normal_left2_8, False\n",
      "Layer: separable_conv_2_normal_right2_8, False\n",
      "Layer: separable_conv_2_normal_left5_8, False\n",
      "Layer: separable_conv_2_bn_normal_left1_8, False\n",
      "Layer: separable_conv_2_bn_normal_right1_8, False\n",
      "Layer: separable_conv_2_bn_normal_left2_8, False\n",
      "Layer: separable_conv_2_bn_normal_right2_8, False\n",
      "Layer: normal_left3_8, False\n",
      "Layer: normal_left4_8, False\n",
      "Layer: normal_right4_8, False\n",
      "Layer: separable_conv_2_bn_normal_left5_8, False\n",
      "Layer: normal_add_1_8, False\n",
      "Layer: normal_add_2_8, False\n",
      "Layer: normal_add_3_8, False\n",
      "Layer: normal_add_4_8, False\n",
      "Layer: normal_add_5_8, False\n",
      "Layer: normal_concat_8, False\n",
      "Layer: activation_128, False\n",
      "Layer: activation_129, False\n",
      "Layer: adjust_conv_projection_9, False\n",
      "Layer: normal_conv_1_9, False\n",
      "Layer: adjust_bn_9, False\n",
      "Layer: normal_bn_1_9, False\n",
      "Layer: activation_130, False\n",
      "Layer: activation_132, False\n",
      "Layer: activation_134, False\n",
      "Layer: activation_136, False\n",
      "Layer: activation_138, False\n",
      "Layer: separable_conv_1_normal_left1_9, False\n",
      "Layer: separable_conv_1_normal_right1_9, False\n",
      "Layer: separable_conv_1_normal_left2_9, False\n",
      "Layer: separable_conv_1_normal_right2_9, False\n",
      "Layer: separable_conv_1_normal_left5_9, False\n",
      "Layer: separable_conv_1_bn_normal_left1_9, False\n",
      "Layer: separable_conv_1_bn_normal_right1_9, False\n",
      "Layer: separable_conv_1_bn_normal_left2_9, False\n",
      "Layer: separable_conv_1_bn_normal_right2_9, False\n",
      "Layer: separable_conv_1_bn_normal_left5_9, False\n",
      "Layer: activation_131, False\n",
      "Layer: activation_133, False\n",
      "Layer: activation_135, False\n",
      "Layer: activation_137, False\n",
      "Layer: activation_139, False\n",
      "Layer: separable_conv_2_normal_left1_9, False\n",
      "Layer: separable_conv_2_normal_right1_9, False\n",
      "Layer: separable_conv_2_normal_left2_9, False\n",
      "Layer: separable_conv_2_normal_right2_9, False\n",
      "Layer: separable_conv_2_normal_left5_9, False\n",
      "Layer: separable_conv_2_bn_normal_left1_9, False\n",
      "Layer: separable_conv_2_bn_normal_right1_9, False\n",
      "Layer: separable_conv_2_bn_normal_left2_9, False\n",
      "Layer: separable_conv_2_bn_normal_right2_9, False\n",
      "Layer: normal_left3_9, False\n",
      "Layer: normal_left4_9, False\n",
      "Layer: normal_right4_9, False\n",
      "Layer: separable_conv_2_bn_normal_left5_9, False\n",
      "Layer: normal_add_1_9, False\n",
      "Layer: normal_add_2_9, False\n",
      "Layer: normal_add_3_9, False\n",
      "Layer: normal_add_4_9, False\n",
      "Layer: normal_add_5_9, False\n",
      "Layer: normal_concat_9, False\n",
      "Layer: activation_140, False\n",
      "Layer: activation_141, False\n",
      "Layer: adjust_conv_projection_10, False\n",
      "Layer: normal_conv_1_10, False\n",
      "Layer: adjust_bn_10, False\n",
      "Layer: normal_bn_1_10, False\n",
      "Layer: activation_142, False\n",
      "Layer: activation_144, False\n",
      "Layer: activation_146, False\n",
      "Layer: activation_148, False\n",
      "Layer: activation_150, False\n",
      "Layer: separable_conv_1_normal_left1_10, False\n",
      "Layer: separable_conv_1_normal_right1_10, False\n",
      "Layer: separable_conv_1_normal_left2_10, False\n",
      "Layer: separable_conv_1_normal_right2_10, False\n",
      "Layer: separable_conv_1_normal_left5_10, False\n",
      "Layer: separable_conv_1_bn_normal_left1_10, False\n",
      "Layer: separable_conv_1_bn_normal_right1_10, False\n",
      "Layer: separable_conv_1_bn_normal_left2_10, False\n",
      "Layer: separable_conv_1_bn_normal_right2_10, False\n",
      "Layer: separable_conv_1_bn_normal_left5_10, False\n",
      "Layer: activation_143, False\n",
      "Layer: activation_145, False\n",
      "Layer: activation_147, False\n",
      "Layer: activation_149, False\n",
      "Layer: activation_151, False\n",
      "Layer: separable_conv_2_normal_left1_10, False\n",
      "Layer: separable_conv_2_normal_right1_10, False\n",
      "Layer: separable_conv_2_normal_left2_10, False\n",
      "Layer: separable_conv_2_normal_right2_10, False\n",
      "Layer: separable_conv_2_normal_left5_10, False\n",
      "Layer: separable_conv_2_bn_normal_left1_10, False\n",
      "Layer: separable_conv_2_bn_normal_right1_10, False\n",
      "Layer: separable_conv_2_bn_normal_left2_10, False\n",
      "Layer: separable_conv_2_bn_normal_right2_10, False\n",
      "Layer: normal_left3_10, False\n",
      "Layer: normal_left4_10, False\n",
      "Layer: normal_right4_10, False\n",
      "Layer: separable_conv_2_bn_normal_left5_10, False\n",
      "Layer: normal_add_1_10, False\n",
      "Layer: normal_add_2_10, False\n",
      "Layer: normal_add_3_10, False\n",
      "Layer: normal_add_4_10, False\n",
      "Layer: normal_add_5_10, False\n",
      "Layer: normal_concat_10, False\n",
      "Layer: activation_152, False\n",
      "Layer: activation_153, False\n",
      "Layer: adjust_conv_projection_11, False\n",
      "Layer: normal_conv_1_11, False\n",
      "Layer: adjust_bn_11, False\n",
      "Layer: normal_bn_1_11, False\n",
      "Layer: activation_154, False\n",
      "Layer: activation_156, False\n",
      "Layer: activation_158, False\n",
      "Layer: activation_160, False\n",
      "Layer: activation_162, False\n",
      "Layer: separable_conv_1_normal_left1_11, False\n",
      "Layer: separable_conv_1_normal_right1_11, False\n",
      "Layer: separable_conv_1_normal_left2_11, False\n",
      "Layer: separable_conv_1_normal_right2_11, False\n",
      "Layer: separable_conv_1_normal_left5_11, False\n",
      "Layer: separable_conv_1_bn_normal_left1_11, False\n",
      "Layer: separable_conv_1_bn_normal_right1_11, False\n",
      "Layer: separable_conv_1_bn_normal_left2_11, False\n",
      "Layer: separable_conv_1_bn_normal_right2_11, False\n",
      "Layer: separable_conv_1_bn_normal_left5_11, False\n",
      "Layer: activation_155, False\n",
      "Layer: activation_157, False\n",
      "Layer: activation_159, False\n",
      "Layer: activation_161, False\n",
      "Layer: activation_163, False\n",
      "Layer: separable_conv_2_normal_left1_11, False\n",
      "Layer: separable_conv_2_normal_right1_11, False\n",
      "Layer: separable_conv_2_normal_left2_11, False\n",
      "Layer: separable_conv_2_normal_right2_11, False\n",
      "Layer: separable_conv_2_normal_left5_11, False\n",
      "Layer: separable_conv_2_bn_normal_left1_11, False\n",
      "Layer: separable_conv_2_bn_normal_right1_11, False\n",
      "Layer: separable_conv_2_bn_normal_left2_11, False\n",
      "Layer: separable_conv_2_bn_normal_right2_11, False\n",
      "Layer: normal_left3_11, False\n",
      "Layer: normal_left4_11, False\n",
      "Layer: normal_right4_11, False\n",
      "Layer: separable_conv_2_bn_normal_left5_11, False\n",
      "Layer: normal_add_1_11, False\n",
      "Layer: normal_add_2_11, False\n",
      "Layer: normal_add_3_11, False\n",
      "Layer: normal_add_4_11, False\n",
      "Layer: normal_add_5_11, False\n",
      "Layer: normal_concat_11, False\n",
      "Layer: activation_164, False\n",
      "Layer: activation_165, False\n",
      "Layer: adjust_conv_projection_12, False\n",
      "Layer: normal_conv_1_12, False\n",
      "Layer: adjust_bn_12, False\n",
      "Layer: normal_bn_1_12, False\n",
      "Layer: activation_166, False\n",
      "Layer: activation_168, False\n",
      "Layer: activation_170, False\n",
      "Layer: activation_172, False\n",
      "Layer: activation_174, False\n",
      "Layer: separable_conv_1_normal_left1_12, False\n",
      "Layer: separable_conv_1_normal_right1_12, False\n",
      "Layer: separable_conv_1_normal_left2_12, False\n",
      "Layer: separable_conv_1_normal_right2_12, False\n",
      "Layer: separable_conv_1_normal_left5_12, False\n",
      "Layer: separable_conv_1_bn_normal_left1_12, False\n",
      "Layer: separable_conv_1_bn_normal_right1_12, False\n",
      "Layer: separable_conv_1_bn_normal_left2_12, False\n",
      "Layer: separable_conv_1_bn_normal_right2_12, False\n",
      "Layer: separable_conv_1_bn_normal_left5_12, False\n",
      "Layer: activation_167, False\n",
      "Layer: activation_169, False\n",
      "Layer: activation_171, False\n",
      "Layer: activation_173, False\n",
      "Layer: activation_175, False\n",
      "Layer: separable_conv_2_normal_left1_12, False\n",
      "Layer: separable_conv_2_normal_right1_12, False\n",
      "Layer: separable_conv_2_normal_left2_12, False\n",
      "Layer: separable_conv_2_normal_right2_12, False\n",
      "Layer: separable_conv_2_normal_left5_12, False\n",
      "Layer: separable_conv_2_bn_normal_left1_12, False\n",
      "Layer: separable_conv_2_bn_normal_right1_12, False\n",
      "Layer: separable_conv_2_bn_normal_left2_12, False\n",
      "Layer: separable_conv_2_bn_normal_right2_12, False\n",
      "Layer: normal_left3_12, False\n",
      "Layer: normal_left4_12, False\n",
      "Layer: normal_right4_12, False\n",
      "Layer: separable_conv_2_bn_normal_left5_12, False\n",
      "Layer: normal_add_1_12, False\n",
      "Layer: normal_add_2_12, False\n",
      "Layer: normal_add_3_12, False\n",
      "Layer: normal_add_4_12, False\n",
      "Layer: normal_add_5_12, False\n",
      "Layer: normal_concat_12, False\n",
      "Layer: activation_177, False\n",
      "Layer: activation_176, False\n",
      "Layer: reduction_conv_1_reduce_12, False\n",
      "Layer: adjust_conv_projection_reduce_12, False\n",
      "Layer: reduction_bn_1_reduce_12, False\n",
      "Layer: adjust_bn_reduce_12, False\n",
      "Layer: activation_178, False\n",
      "Layer: activation_180, False\n",
      "Layer: separable_conv_1_pad_reduction_left1_reduce_12, False\n",
      "Layer: separable_conv_1_pad_reduction_right1_reduce_12, False\n",
      "Layer: separable_conv_1_reduction_left1_reduce_12, False\n",
      "Layer: separable_conv_1_reduction_right1_reduce_12, False\n",
      "Layer: separable_conv_1_bn_reduction_left1_reduce_12, False\n",
      "Layer: separable_conv_1_bn_reduction_right1_reduce_12, False\n",
      "Layer: activation_179, False\n",
      "Layer: activation_181, False\n",
      "Layer: separable_conv_2_reduction_left1_reduce_12, False\n",
      "Layer: separable_conv_2_reduction_right1_reduce_12, False\n",
      "Layer: activation_182, False\n",
      "Layer: separable_conv_2_bn_reduction_left1_reduce_12, False\n",
      "Layer: separable_conv_2_bn_reduction_right1_reduce_12, False\n",
      "Layer: separable_conv_1_pad_reduction_right2_reduce_12, False\n",
      "Layer: activation_184, False\n",
      "Layer: reduction_add_1_reduce_12, False\n",
      "Layer: separable_conv_1_reduction_right2_reduce_12, False\n",
      "Layer: separable_conv_1_pad_reduction_right3_reduce_12, False\n",
      "Layer: activation_186, False\n",
      "Layer: separable_conv_1_bn_reduction_right2_reduce_12, False\n",
      "Layer: separable_conv_1_reduction_right3_reduce_12, False\n",
      "Layer: separable_conv_1_reduction_left4_reduce_12, False\n",
      "Layer: activation_183, False\n",
      "Layer: separable_conv_1_bn_reduction_right3_reduce_12, False\n",
      "Layer: separable_conv_1_bn_reduction_left4_reduce_12, False\n",
      "Layer: reduction_pad_1_reduce_12, False\n",
      "Layer: separable_conv_2_reduction_right2_reduce_12, False\n",
      "Layer: activation_185, False\n",
      "Layer: activation_187, False\n",
      "Layer: reduction_left2_reduce_12, False\n",
      "Layer: separable_conv_2_bn_reduction_right2_reduce_12, False\n",
      "Layer: separable_conv_2_reduction_right3_reduce_12, False\n",
      "Layer: separable_conv_2_reduction_left4_reduce_12, False\n",
      "Layer: adjust_relu_1_13, False\n",
      "Layer: reduction_add_2_reduce_12, False\n",
      "Layer: reduction_left3_reduce_12, False\n",
      "Layer: separable_conv_2_bn_reduction_right3_reduce_12, False\n",
      "Layer: reduction_left4_reduce_12, False\n",
      "Layer: separable_conv_2_bn_reduction_left4_reduce_12, False\n",
      "Layer: reduction_right5_reduce_12, False\n",
      "Layer: zero_padding2d_3, False\n",
      "Layer: reduction_add3_reduce_12, False\n",
      "Layer: add_3, False\n",
      "Layer: reduction_add4_reduce_12, False\n",
      "Layer: cropping2d_3, False\n",
      "Layer: reduction_concat_reduce_12, False\n",
      "Layer: adjust_avg_pool_1_13, False\n",
      "Layer: adjust_avg_pool_2_13, False\n",
      "Layer: adjust_conv_1_13, False\n",
      "Layer: adjust_conv_2_13, False\n",
      "Layer: activation_188, False\n",
      "Layer: concatenate_3, False\n",
      "Layer: normal_conv_1_13, False\n",
      "Layer: adjust_bn_13, False\n",
      "Layer: normal_bn_1_13, False\n",
      "Layer: activation_189, False\n",
      "Layer: activation_191, False\n",
      "Layer: activation_193, False\n",
      "Layer: activation_195, False\n",
      "Layer: activation_197, False\n",
      "Layer: separable_conv_1_normal_left1_13, False\n",
      "Layer: separable_conv_1_normal_right1_13, False\n",
      "Layer: separable_conv_1_normal_left2_13, False\n",
      "Layer: separable_conv_1_normal_right2_13, False\n",
      "Layer: separable_conv_1_normal_left5_13, False\n",
      "Layer: separable_conv_1_bn_normal_left1_13, False\n",
      "Layer: separable_conv_1_bn_normal_right1_13, False\n",
      "Layer: separable_conv_1_bn_normal_left2_13, False\n",
      "Layer: separable_conv_1_bn_normal_right2_13, False\n",
      "Layer: separable_conv_1_bn_normal_left5_13, False\n",
      "Layer: activation_190, False\n",
      "Layer: activation_192, False\n",
      "Layer: activation_194, False\n",
      "Layer: activation_196, False\n",
      "Layer: activation_198, False\n",
      "Layer: separable_conv_2_normal_left1_13, False\n",
      "Layer: separable_conv_2_normal_right1_13, False\n",
      "Layer: separable_conv_2_normal_left2_13, False\n",
      "Layer: separable_conv_2_normal_right2_13, False\n",
      "Layer: separable_conv_2_normal_left5_13, False\n",
      "Layer: separable_conv_2_bn_normal_left1_13, False\n",
      "Layer: separable_conv_2_bn_normal_right1_13, False\n",
      "Layer: separable_conv_2_bn_normal_left2_13, False\n",
      "Layer: separable_conv_2_bn_normal_right2_13, False\n",
      "Layer: normal_left3_13, False\n",
      "Layer: normal_left4_13, False\n",
      "Layer: normal_right4_13, False\n",
      "Layer: separable_conv_2_bn_normal_left5_13, False\n",
      "Layer: normal_add_1_13, False\n",
      "Layer: normal_add_2_13, False\n",
      "Layer: normal_add_3_13, False\n",
      "Layer: normal_add_4_13, False\n",
      "Layer: normal_add_5_13, False\n",
      "Layer: normal_concat_13, False\n",
      "Layer: activation_199, False\n",
      "Layer: activation_200, False\n",
      "Layer: adjust_conv_projection_14, False\n",
      "Layer: normal_conv_1_14, False\n",
      "Layer: adjust_bn_14, False\n",
      "Layer: normal_bn_1_14, False\n",
      "Layer: activation_201, False\n",
      "Layer: activation_203, False\n",
      "Layer: activation_205, False\n",
      "Layer: activation_207, False\n",
      "Layer: activation_209, False\n",
      "Layer: separable_conv_1_normal_left1_14, False\n",
      "Layer: separable_conv_1_normal_right1_14, False\n",
      "Layer: separable_conv_1_normal_left2_14, False\n",
      "Layer: separable_conv_1_normal_right2_14, False\n",
      "Layer: separable_conv_1_normal_left5_14, False\n",
      "Layer: separable_conv_1_bn_normal_left1_14, False\n",
      "Layer: separable_conv_1_bn_normal_right1_14, False\n",
      "Layer: separable_conv_1_bn_normal_left2_14, False\n",
      "Layer: separable_conv_1_bn_normal_right2_14, False\n",
      "Layer: separable_conv_1_bn_normal_left5_14, False\n",
      "Layer: activation_202, False\n",
      "Layer: activation_204, False\n",
      "Layer: activation_206, False\n",
      "Layer: activation_208, False\n",
      "Layer: activation_210, False\n",
      "Layer: separable_conv_2_normal_left1_14, False\n",
      "Layer: separable_conv_2_normal_right1_14, False\n",
      "Layer: separable_conv_2_normal_left2_14, False\n",
      "Layer: separable_conv_2_normal_right2_14, False\n",
      "Layer: separable_conv_2_normal_left5_14, False\n",
      "Layer: separable_conv_2_bn_normal_left1_14, False\n",
      "Layer: separable_conv_2_bn_normal_right1_14, False\n",
      "Layer: separable_conv_2_bn_normal_left2_14, False\n",
      "Layer: separable_conv_2_bn_normal_right2_14, False\n",
      "Layer: normal_left3_14, False\n",
      "Layer: normal_left4_14, False\n",
      "Layer: normal_right4_14, False\n",
      "Layer: separable_conv_2_bn_normal_left5_14, False\n",
      "Layer: normal_add_1_14, False\n",
      "Layer: normal_add_2_14, False\n",
      "Layer: normal_add_3_14, False\n",
      "Layer: normal_add_4_14, False\n",
      "Layer: normal_add_5_14, False\n",
      "Layer: normal_concat_14, False\n",
      "Layer: activation_211, False\n",
      "Layer: activation_212, False\n",
      "Layer: adjust_conv_projection_15, False\n",
      "Layer: normal_conv_1_15, False\n",
      "Layer: adjust_bn_15, False\n",
      "Layer: normal_bn_1_15, False\n",
      "Layer: activation_213, False\n",
      "Layer: activation_215, False\n",
      "Layer: activation_217, False\n",
      "Layer: activation_219, False\n",
      "Layer: activation_221, False\n",
      "Layer: separable_conv_1_normal_left1_15, False\n",
      "Layer: separable_conv_1_normal_right1_15, False\n",
      "Layer: separable_conv_1_normal_left2_15, False\n",
      "Layer: separable_conv_1_normal_right2_15, False\n",
      "Layer: separable_conv_1_normal_left5_15, False\n",
      "Layer: separable_conv_1_bn_normal_left1_15, False\n",
      "Layer: separable_conv_1_bn_normal_right1_15, False\n",
      "Layer: separable_conv_1_bn_normal_left2_15, False\n",
      "Layer: separable_conv_1_bn_normal_right2_15, False\n",
      "Layer: separable_conv_1_bn_normal_left5_15, False\n",
      "Layer: activation_214, False\n",
      "Layer: activation_216, False\n",
      "Layer: activation_218, False\n",
      "Layer: activation_220, False\n",
      "Layer: activation_222, False\n",
      "Layer: separable_conv_2_normal_left1_15, False\n",
      "Layer: separable_conv_2_normal_right1_15, False\n",
      "Layer: separable_conv_2_normal_left2_15, False\n",
      "Layer: separable_conv_2_normal_right2_15, False\n",
      "Layer: separable_conv_2_normal_left5_15, False\n",
      "Layer: separable_conv_2_bn_normal_left1_15, False\n",
      "Layer: separable_conv_2_bn_normal_right1_15, False\n",
      "Layer: separable_conv_2_bn_normal_left2_15, False\n",
      "Layer: separable_conv_2_bn_normal_right2_15, False\n",
      "Layer: normal_left3_15, False\n",
      "Layer: normal_left4_15, False\n",
      "Layer: normal_right4_15, False\n",
      "Layer: separable_conv_2_bn_normal_left5_15, False\n",
      "Layer: normal_add_1_15, False\n",
      "Layer: normal_add_2_15, False\n",
      "Layer: normal_add_3_15, False\n",
      "Layer: normal_add_4_15, False\n",
      "Layer: normal_add_5_15, False\n",
      "Layer: normal_concat_15, False\n",
      "Layer: activation_223, False\n",
      "Layer: activation_224, False\n",
      "Layer: adjust_conv_projection_16, False\n",
      "Layer: normal_conv_1_16, False\n",
      "Layer: adjust_bn_16, False\n",
      "Layer: normal_bn_1_16, False\n",
      "Layer: activation_225, False\n",
      "Layer: activation_227, False\n",
      "Layer: activation_229, False\n",
      "Layer: activation_231, False\n",
      "Layer: activation_233, False\n",
      "Layer: separable_conv_1_normal_left1_16, False\n",
      "Layer: separable_conv_1_normal_right1_16, False\n",
      "Layer: separable_conv_1_normal_left2_16, False\n",
      "Layer: separable_conv_1_normal_right2_16, False\n",
      "Layer: separable_conv_1_normal_left5_16, False\n",
      "Layer: separable_conv_1_bn_normal_left1_16, False\n",
      "Layer: separable_conv_1_bn_normal_right1_16, False\n",
      "Layer: separable_conv_1_bn_normal_left2_16, False\n",
      "Layer: separable_conv_1_bn_normal_right2_16, False\n",
      "Layer: separable_conv_1_bn_normal_left5_16, False\n",
      "Layer: activation_226, False\n",
      "Layer: activation_228, False\n",
      "Layer: activation_230, False\n",
      "Layer: activation_232, False\n",
      "Layer: activation_234, False\n",
      "Layer: separable_conv_2_normal_left1_16, False\n",
      "Layer: separable_conv_2_normal_right1_16, False\n",
      "Layer: separable_conv_2_normal_left2_16, False\n",
      "Layer: separable_conv_2_normal_right2_16, False\n",
      "Layer: separable_conv_2_normal_left5_16, False\n",
      "Layer: separable_conv_2_bn_normal_left1_16, False\n",
      "Layer: separable_conv_2_bn_normal_right1_16, False\n",
      "Layer: separable_conv_2_bn_normal_left2_16, False\n",
      "Layer: separable_conv_2_bn_normal_right2_16, False\n",
      "Layer: normal_left3_16, False\n",
      "Layer: normal_left4_16, False\n",
      "Layer: normal_right4_16, False\n",
      "Layer: separable_conv_2_bn_normal_left5_16, False\n",
      "Layer: normal_add_1_16, False\n",
      "Layer: normal_add_2_16, False\n",
      "Layer: normal_add_3_16, False\n",
      "Layer: normal_add_4_16, False\n",
      "Layer: normal_add_5_16, False\n",
      "Layer: normal_concat_16, False\n",
      "Layer: activation_235, False\n",
      "Layer: activation_236, False\n",
      "Layer: adjust_conv_projection_17, False\n",
      "Layer: normal_conv_1_17, False\n",
      "Layer: adjust_bn_17, False\n",
      "Layer: normal_bn_1_17, False\n",
      "Layer: activation_237, False\n",
      "Layer: activation_239, False\n",
      "Layer: activation_241, False\n",
      "Layer: activation_243, False\n",
      "Layer: activation_245, False\n",
      "Layer: separable_conv_1_normal_left1_17, False\n",
      "Layer: separable_conv_1_normal_right1_17, False\n",
      "Layer: separable_conv_1_normal_left2_17, False\n",
      "Layer: separable_conv_1_normal_right2_17, False\n",
      "Layer: separable_conv_1_normal_left5_17, False\n",
      "Layer: separable_conv_1_bn_normal_left1_17, False\n",
      "Layer: separable_conv_1_bn_normal_right1_17, False\n",
      "Layer: separable_conv_1_bn_normal_left2_17, False\n",
      "Layer: separable_conv_1_bn_normal_right2_17, False\n",
      "Layer: separable_conv_1_bn_normal_left5_17, False\n",
      "Layer: activation_238, False\n",
      "Layer: activation_240, False\n",
      "Layer: activation_242, False\n",
      "Layer: activation_244, False\n",
      "Layer: activation_246, False\n",
      "Layer: separable_conv_2_normal_left1_17, False\n",
      "Layer: separable_conv_2_normal_right1_17, False\n",
      "Layer: separable_conv_2_normal_left2_17, False\n",
      "Layer: separable_conv_2_normal_right2_17, False\n",
      "Layer: separable_conv_2_normal_left5_17, False\n",
      "Layer: separable_conv_2_bn_normal_left1_17, False\n",
      "Layer: separable_conv_2_bn_normal_right1_17, False\n",
      "Layer: separable_conv_2_bn_normal_left2_17, False\n",
      "Layer: separable_conv_2_bn_normal_right2_17, False\n",
      "Layer: normal_left3_17, False\n",
      "Layer: normal_left4_17, False\n",
      "Layer: normal_right4_17, False\n",
      "Layer: separable_conv_2_bn_normal_left5_17, False\n",
      "Layer: normal_add_1_17, False\n",
      "Layer: normal_add_2_17, False\n",
      "Layer: normal_add_3_17, False\n",
      "Layer: normal_add_4_17, False\n",
      "Layer: normal_add_5_17, False\n",
      "Layer: normal_concat_17, False\n",
      "Layer: activation_247, False\n",
      "Layer: activation_248, False\n",
      "Layer: adjust_conv_projection_18, False\n",
      "Layer: normal_conv_1_18, False\n",
      "Layer: adjust_bn_18, False\n",
      "Layer: normal_bn_1_18, False\n",
      "Layer: activation_249, False\n",
      "Layer: activation_251, False\n",
      "Layer: activation_253, False\n",
      "Layer: activation_255, False\n",
      "Layer: activation_257, False\n",
      "Layer: separable_conv_1_normal_left1_18, False\n",
      "Layer: separable_conv_1_normal_right1_18, False\n",
      "Layer: separable_conv_1_normal_left2_18, False\n",
      "Layer: separable_conv_1_normal_right2_18, False\n",
      "Layer: separable_conv_1_normal_left5_18, False\n",
      "Layer: separable_conv_1_bn_normal_left1_18, False\n",
      "Layer: separable_conv_1_bn_normal_right1_18, False\n",
      "Layer: separable_conv_1_bn_normal_left2_18, False\n",
      "Layer: separable_conv_1_bn_normal_right2_18, False\n",
      "Layer: separable_conv_1_bn_normal_left5_18, False\n",
      "Layer: activation_250, False\n",
      "Layer: activation_252, False\n",
      "Layer: activation_254, False\n",
      "Layer: activation_256, False\n",
      "Layer: activation_258, False\n",
      "Layer: separable_conv_2_normal_left1_18, False\n",
      "Layer: separable_conv_2_normal_right1_18, False\n",
      "Layer: separable_conv_2_normal_left2_18, False\n",
      "Layer: separable_conv_2_normal_right2_18, False\n",
      "Layer: separable_conv_2_normal_left5_18, False\n",
      "Layer: separable_conv_2_bn_normal_left1_18, False\n",
      "Layer: separable_conv_2_bn_normal_right1_18, False\n",
      "Layer: separable_conv_2_bn_normal_left2_18, False\n",
      "Layer: separable_conv_2_bn_normal_right2_18, False\n",
      "Layer: normal_left3_18, False\n",
      "Layer: normal_left4_18, False\n",
      "Layer: normal_right4_18, False\n",
      "Layer: separable_conv_2_bn_normal_left5_18, False\n",
      "Layer: normal_add_1_18, False\n",
      "Layer: normal_add_2_18, False\n",
      "Layer: normal_add_3_18, False\n",
      "Layer: normal_add_4_18, False\n",
      "Layer: normal_add_5_18, False\n",
      "Layer: normal_concat_18, False\n",
      "Layer: activation_259, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:19.275337Z",
     "start_time": "2024-07-29T19:53:19.271821Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1039"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:25.278462Z",
     "start_time": "2024-07-29T19:53:25.275637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:25.682470Z",
     "start_time": "2024-07-29T19:53:25.677358Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:44.388735Z",
     "start_time": "2024-07-29T19:53:43.113469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "#x = aug_layer(inputs)\n",
    "x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'NasnetLarge')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NasnetLarge\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 4032)        84916818  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 4032)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 4032)              16128     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2064896   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_260 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_261 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_262 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_263 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87174422 (332.54 MB)\n",
      "Trainable params: 2247620 (8.57 MB)\n",
      "Non-trainable params: 84926802 (323.97 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:50.476618Z",
     "start_time": "2024-07-29T19:53:50.474129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models',model_1.name), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:50.829829Z",
     "start_time": "2024-07-29T19:53:50.827911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=3) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:53:51.366153Z",
     "start_time": "2024-07-29T19:53:51.347991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:04:59.779610Z",
     "start_time": "2024-07-29T19:53:52.728709Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 15, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:54:00.632818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-29 15:54:00.797763: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-29 15:54:02.227057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x764aec003660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-29 15:54:02.227076: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-29 15:54:02.236336: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-29 15:54:02.314608: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 8.7334 - accuracy: 0.4723\n",
      "Epoch 1: val_loss improved from inf to 6.46049, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 63s 728ms/step - loss: 8.7334 - accuracy: 0.4723 - val_loss: 6.4605 - val_accuracy: 0.8497 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.3132 - accuracy: 0.5464\n",
      "Epoch 2: val_loss improved from 6.46049 to 4.57959, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 52s 705ms/step - loss: 5.3132 - accuracy: 0.5464 - val_loss: 4.5796 - val_accuracy: 0.8497 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 3.7903 - accuracy: 0.5972\n",
      "Epoch 3: val_loss improved from 4.57959 to 3.38280, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 53s 720ms/step - loss: 3.7903 - accuracy: 0.5972 - val_loss: 3.3828 - val_accuracy: 0.8497 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.8150 - accuracy: 0.6451\n",
      "Epoch 4: val_loss improved from 3.38280 to 2.57950, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 53s 718ms/step - loss: 2.8150 - accuracy: 0.6451 - val_loss: 2.5795 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.1937 - accuracy: 0.6798\n",
      "Epoch 5: val_loss improved from 2.57950 to 2.00327, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 53s 724ms/step - loss: 2.1937 - accuracy: 0.6798 - val_loss: 2.0033 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.8197 - accuracy: 0.6849\n",
      "Epoch 6: val_loss improved from 2.00327 to 1.68883, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 54s 729ms/step - loss: 1.8197 - accuracy: 0.6849 - val_loss: 1.6888 - val_accuracy: 0.9041 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.5544 - accuracy: 0.7065\n",
      "Epoch 7: val_loss improved from 1.68883 to 1.47148, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 54s 738ms/step - loss: 1.5544 - accuracy: 0.7065 - val_loss: 1.4715 - val_accuracy: 0.9110 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.4536 - accuracy: 0.6887\n",
      "Epoch 8: val_loss improved from 1.47148 to 1.33340, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 54s 735ms/step - loss: 1.4536 - accuracy: 0.6887 - val_loss: 1.3334 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.7234\n",
      "Epoch 9: val_loss improved from 1.33340 to 1.10994, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 55s 752ms/step - loss: 1.2242 - accuracy: 0.7234 - val_loss: 1.1099 - val_accuracy: 0.8615 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1775 - accuracy: 0.7099\n",
      "Epoch 10: val_loss did not improve from 1.10994\n",
      "74/74 [==============================] - 15s 205ms/step - loss: 1.1775 - accuracy: 0.7099 - val_loss: 1.1383 - val_accuracy: 0.8091 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1163 - accuracy: 0.7133\n",
      "Epoch 11: val_loss improved from 1.10994 to 0.96681, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 56s 763ms/step - loss: 1.1163 - accuracy: 0.7133 - val_loss: 0.9668 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0491 - accuracy: 0.7200\n",
      "Epoch 12: val_loss did not improve from 0.96681\n",
      "74/74 [==============================] - 16s 212ms/step - loss: 1.0491 - accuracy: 0.7200 - val_loss: 1.0090 - val_accuracy: 0.7745 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0419 - accuracy: 0.7205\n",
      "Epoch 13: val_loss did not improve from 0.96681\n",
      "74/74 [==============================] - 16s 211ms/step - loss: 1.0419 - accuracy: 0.7205 - val_loss: 1.9290 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0540 - accuracy: 0.7086\n",
      "Epoch 14: val_loss did not improve from 0.96681\n",
      "74/74 [==============================] - 16s 212ms/step - loss: 1.0540 - accuracy: 0.7086 - val_loss: 1.0245 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8959 - accuracy: 0.7709\n",
      "Epoch 15: val_loss improved from 0.96681 to 0.83712, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 56s 761ms/step - loss: 0.8959 - accuracy: 0.7709 - val_loss: 0.8371 - val_accuracy: 0.8605 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:08:06.362855Z",
     "start_time": "2024-07-29T20:08:02.736016Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "eb9cc0053cd28662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 130ms/step - loss: 0.9222 - accuracy: 0.7325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9222232103347778, 0.7325443625450134]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:08:10.473889Z",
     "start_time": "2024-07-29T20:08:10.459857Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:08:10.943273Z",
     "start_time": "2024-07-29T20:08:10.929897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-25]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:08:11.464021Z",
     "start_time": "2024-07-29T20:08:11.458508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:08:12.384834Z",
     "start_time": "2024-07-29T20:08:12.324131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 15\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NasnetLarge\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 4032)        84916818  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 4032)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 4032)              16128     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2064896   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_260 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_261 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_262 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_263 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87174422 (332.54 MB)\n",
      "Trainable params: 4564004 (17.41 MB)\n",
      "Non-trainable params: 82610418 (315.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:11:17.658861Z",
     "start_time": "2024-07-29T20:08:14.174438Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9986 - accuracy: 0.7200\n",
      "Epoch 16: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 27s 213ms/step - loss: 0.9986 - accuracy: 0.7200 - val_loss: 3.0628 - val_accuracy: 0.0425 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.7209\n",
      "Epoch 17: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.0095 - accuracy: 0.7209 - val_loss: 8.4239 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9584 - accuracy: 0.7315\n",
      "Epoch 18: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 0.9584 - accuracy: 0.7315 - val_loss: 2.3477 - val_accuracy: 0.0049 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9058 - accuracy: 0.7442\n",
      "Epoch 19: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 0.9058 - accuracy: 0.7442 - val_loss: 6.1657 - val_accuracy: 0.0406 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9442 - accuracy: 0.7319\n",
      "Epoch 20: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 0.9442 - accuracy: 0.7319 - val_loss: 9.4548 - val_accuracy: 0.0406 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9320 - accuracy: 0.7535\n",
      "Epoch 21: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 0.9320 - accuracy: 0.7535 - val_loss: 84.7759 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8402 - accuracy: 0.7781\n",
      "Epoch 22: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 168ms/step - loss: 0.8402 - accuracy: 0.7781 - val_loss: 3.1488 - val_accuracy: 0.0069 - lr: 3.0000e-04\n",
      "Epoch 23/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7501 - accuracy: 0.8014\n",
      "Epoch 23: val_loss did not improve from 0.83712\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 0.7501 - accuracy: 0.8014 - val_loss: 2.7097 - val_accuracy: 0.0040 - lr: 3.0000e-04\n",
      "Epoch 24/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.8175\n",
      "Epoch 24: val_loss improved from 0.83712 to 0.68436, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 53s 719ms/step - loss: 0.6992 - accuracy: 0.8175 - val_loss: 0.6844 - val_accuracy: 0.8882 - lr: 3.0000e-04\n",
      "Epoch 25/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.8009\n",
      "Epoch 25: val_loss did not improve from 0.68436\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 0.6843 - accuracy: 0.8009 - val_loss: 0.8966 - val_accuracy: 0.7893 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:11:20.851774Z",
     "start_time": "2024-07-29T20:11:17.659699Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "76e9cd11a6024452",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 116ms/step - loss: 1.2763 - accuracy: 0.5479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.276302456855774, 0.5479289889335632]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:41:38.971385Z",
     "start_time": "2024-07-29T19:41:38.968064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 25\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:41:40.344954Z",
     "start_time": "2024-07-29T19:41:40.296716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 1602708 (6.11 MB)\n",
      "Non-trainable params: 3388996 (12.93 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:14:40.018470Z",
     "start_time": "2024-07-29T20:11:47.621880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 25\n",
    "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))"
   ],
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.8179\n",
      "Epoch 26: val_loss improved from 0.68436 to 0.51696, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 54s 736ms/step - loss: 0.6569 - accuracy: 0.8179 - val_loss: 0.5170 - val_accuracy: 0.9228 - lr: 3.0000e-04\n",
      "Epoch 27/35\n",
      "50/74 [===================>..........] - ETA: 2s - loss: 0.6290 - accuracy: 0.8131\n",
      "Epoch 27: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 0.6199 - accuracy: 0.8234 - val_loss: 3.6452 - val_accuracy: 0.1612 - lr: 3.0000e-04\n",
      "Epoch 28/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.8225\n",
      "Epoch 28: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 0.6426 - accuracy: 0.8225 - val_loss: 6.8856 - val_accuracy: 0.1543 - lr: 3.0000e-04\n",
      "Epoch 29/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.8213\n",
      "Epoch 29: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 0.6279 - accuracy: 0.8213 - val_loss: 3.0274 - val_accuracy: 0.0079 - lr: 3.0000e-04\n",
      "Epoch 30/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.8433\n",
      "Epoch 30: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 168ms/step - loss: 0.5685 - accuracy: 0.8433 - val_loss: 0.6908 - val_accuracy: 0.8002 - lr: 9.0000e-05\n",
      "Epoch 31/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.8522\n",
      "Epoch 31: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 0.5519 - accuracy: 0.8522 - val_loss: 0.7917 - val_accuracy: 0.8506 - lr: 9.0000e-05\n",
      "Epoch 32/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5409 - accuracy: 0.8568\n",
      "Epoch 32: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 0.5409 - accuracy: 0.8568 - val_loss: 0.6194 - val_accuracy: 0.8952 - lr: 9.0000e-05\n",
      "Epoch 33/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5009 - accuracy: 0.8666\n",
      "Epoch 33: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 0.5009 - accuracy: 0.8666 - val_loss: 0.6994 - val_accuracy: 0.8398 - lr: 2.7000e-05\n",
      "Epoch 34/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8717\n",
      "Epoch 34: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 14s 181ms/step - loss: 0.4947 - accuracy: 0.8717 - val_loss: 0.5514 - val_accuracy: 0.8724 - lr: 2.7000e-05\n",
      "Epoch 35/35\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8683\n",
      "Epoch 35: val_loss did not improve from 0.51696\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 0.4914 - accuracy: 0.8683 - val_loss: 0.6572 - val_accuracy: 0.8348 - lr: 2.7000e-05\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:14:43.192670Z",
     "start_time": "2024-07-29T20:14:40.019277Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "cb9409c4dba63f27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 115ms/step - loss: 0.7482 - accuracy: 0.7704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7481857538223267, 0.7704141736030579]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:14:49.386960Z",
     "start_time": "2024-07-29T20:14:49.383372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 35\n",
    "\n",
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:14:50.027267Z",
     "start_time": "2024-07-29T20:14:49.957774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000075), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NasnetLarge\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 4032)        84916818  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 4032)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 4032)              16128     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2064896   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_260 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_261 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_262 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_263 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87174422 (332.54 MB)\n",
      "Trainable params: 22357892 (85.29 MB)\n",
      "Non-trainable params: 64816530 (247.26 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:18:09.148742Z",
     "start_time": "2024-07-29T20:14:52.742311Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7491 - accuracy: 0.7641\n",
      "Epoch 36: val_loss improved from 0.51696 to 0.39615, saving model to Trained_Models/NasnetLarge\n",
      "74/74 [==============================] - 72s 837ms/step - loss: 0.7491 - accuracy: 0.7641 - val_loss: 0.3962 - val_accuracy: 0.9268 - lr: 7.5000e-05\n",
      "Epoch 37/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.8030\n",
      "Epoch 37: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 0.6622 - accuracy: 0.8030 - val_loss: 2.1527 - val_accuracy: 0.5519 - lr: 7.5000e-05\n",
      "Epoch 38/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.8107\n",
      "Epoch 38: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 0.6301 - accuracy: 0.8107 - val_loss: 3.1047 - val_accuracy: 0.1790 - lr: 7.5000e-05\n",
      "Epoch 39/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.7992\n",
      "Epoch 39: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 0.6477 - accuracy: 0.7992 - val_loss: 0.6885 - val_accuracy: 0.8061 - lr: 7.5000e-05\n",
      "Epoch 40/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 0.8412\n",
      "Epoch 40: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 0.5554 - accuracy: 0.8412 - val_loss: 1.7442 - val_accuracy: 0.4332 - lr: 2.2500e-05\n",
      "Epoch 41/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8513\n",
      "Epoch 41: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 0.5319 - accuracy: 0.8513 - val_loss: 1.6967 - val_accuracy: 0.4105 - lr: 2.2500e-05\n",
      "Epoch 42/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8772\n",
      "Epoch 42: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 0.4936 - accuracy: 0.8772 - val_loss: 1.2526 - val_accuracy: 0.5272 - lr: 2.2500e-05\n",
      "Epoch 43/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.8818\n",
      "Epoch 43: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 181ms/step - loss: 0.4767 - accuracy: 0.8818 - val_loss: 0.5946 - val_accuracy: 0.8417 - lr: 6.7500e-06\n",
      "Epoch 44/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4560 - accuracy: 0.8865\n",
      "Epoch 44: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 181ms/step - loss: 0.4560 - accuracy: 0.8865 - val_loss: 0.8247 - val_accuracy: 0.7359 - lr: 6.7500e-06\n",
      "Epoch 45/45\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.8814\n",
      "Epoch 45: val_loss did not improve from 0.39615\n",
      "74/74 [==============================] - 14s 182ms/step - loss: 0.4602 - accuracy: 0.8814 - val_loss: 0.4521 - val_accuracy: 0.9149 - lr: 6.7500e-06\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:18:12.370678Z",
     "start_time": "2024-07-29T20:18:09.149784Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "572beefd899e12a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 117ms/step - loss: 0.6941 - accuracy: 0.7834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6940546631813049, 0.7834319472312927]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:47:38.807369Z",
     "start_time": "2024-07-29T19:47:38.801646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 45\n",
    "for layer in base_model.layers[-150:]:\n",
    "    layer.trainable = True"
   ],
   "id": "93ad3cc030c9c69",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:47:39.712985Z",
     "start_time": "2024-07-29T19:47:39.665045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000025), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "9ed4bf4a63f90d77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 4121356 (15.72 MB)\n",
      "Non-trainable params: 870348 (3.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:49:16.600177Z",
     "start_time": "2024-07-29T19:47:41.082633Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "b0794490c20e0209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9856\n",
      "Epoch 46: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 36s 107ms/step - loss: 0.1190 - accuracy: 0.9856 - val_loss: 0.2369 - val_accuracy: 0.9585 - lr: 2.5000e-05\n",
      "Epoch 47/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9894\n",
      "Epoch 47: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.1114 - accuracy: 0.9894 - val_loss: 0.4673 - val_accuracy: 0.8724 - lr: 2.5000e-05\n",
      "Epoch 48/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9886\n",
      "Epoch 48: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.1195 - accuracy: 0.9886 - val_loss: 0.2321 - val_accuracy: 0.9525 - lr: 2.5000e-05\n",
      "Epoch 49/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9936\n",
      "Epoch 49: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.0976 - accuracy: 0.9936 - val_loss: 0.1823 - val_accuracy: 0.9703 - lr: 2.5000e-05\n",
      "Epoch 50/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9941\n",
      "Epoch 50: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 84ms/step - loss: 0.0975 - accuracy: 0.9941 - val_loss: 0.1955 - val_accuracy: 0.9644 - lr: 2.5000e-05\n",
      "Epoch 51/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9915\n",
      "Epoch 51: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 84ms/step - loss: 0.1015 - accuracy: 0.9915 - val_loss: 0.2076 - val_accuracy: 0.9624 - lr: 2.5000e-05\n",
      "Epoch 52/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9924\n",
      "Epoch 52: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 91ms/step - loss: 0.0962 - accuracy: 0.9924 - val_loss: 0.1759 - val_accuracy: 0.9733 - lr: 2.5000e-05\n",
      "Epoch 53/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9920\n",
      "Epoch 53: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 88ms/step - loss: 0.1000 - accuracy: 0.9920 - val_loss: 0.2659 - val_accuracy: 0.9505 - lr: 2.5000e-05\n",
      "Epoch 54/55\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9915\n",
      "Epoch 54: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 7s 89ms/step - loss: 0.0947 - accuracy: 0.9915 - val_loss: 0.2483 - val_accuracy: 0.9525 - lr: 2.5000e-05\n",
      "Epoch 55/55\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9957\n",
      "Epoch 55: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 0.0838 - accuracy: 0.9958 - val_loss: 0.2698 - val_accuracy: 0.9496 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:49:44.279319Z",
     "start_time": "2024-07-29T19:49:44.269349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 55\n",
    "for layer in base_model.layers[-700:]:\n",
    "    layer.trainable = True"
   ],
   "id": "65b379ec652de956",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:49:45.195948Z",
     "start_time": "2024-07-29T19:49:45.117047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000025), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "c49c24beb9980801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nasnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1056)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1056)              4224      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               541184    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_188 (Activation  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_189 (Activation  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_190 (Activation  (None, 128)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_191 (Activation  (None, 64)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4991704 (19.04 MB)\n",
      "Trainable params: 4937116 (18.83 MB)\n",
      "Non-trainable params: 54588 (213.23 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-29T19:49:47.229317Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "5fd98f0c46842888",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9814\n",
      "Epoch 56: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 55s 148ms/step - loss: 0.1236 - accuracy: 0.9814 - val_loss: 0.3335 - val_accuracy: 0.9308 - lr: 2.5000e-05\n",
      "Epoch 57/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9809\n",
      "Epoch 57: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 0.1372 - accuracy: 0.9809 - val_loss: 0.1625 - val_accuracy: 0.9763 - lr: 2.5000e-05\n",
      "Epoch 58/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9903\n",
      "Epoch 58: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 108ms/step - loss: 0.1013 - accuracy: 0.9903 - val_loss: 0.2233 - val_accuracy: 0.9594 - lr: 2.5000e-05\n",
      "Epoch 59/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9911\n",
      "Epoch 59: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 108ms/step - loss: 0.0955 - accuracy: 0.9911 - val_loss: 0.2628 - val_accuracy: 0.9476 - lr: 2.5000e-05\n",
      "Epoch 60/65\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9932\n",
      "Epoch 60: val_loss did not improve from 0.16067\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 0.0850 - accuracy: 0.9932 - val_loss: 0.2176 - val_accuracy: 0.9585 - lr: 2.5000e-05\n",
      "Epoch 61/65\n",
      "63/74 [========================>.....] - ETA: 1s - loss: 0.0807 - accuracy: 0.9950"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "7accf2968e67a759",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:29:20.860931Z",
     "start_time": "2024-07-29T18:29:20.592463Z"
    }
   },
   "cell_type": "code",
   "source": "resnet = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m resnet \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/saving/saving_api.py:262\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    255\u001B[0m         filepath,\n\u001B[1;32m    256\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[1;32m    258\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[1;32m    259\u001B[0m     )\n\u001B[1;32m    261\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[0;32m--> 234\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[1;32m    235\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    236\u001B[0m         )\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[1;32m    239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[1;32m    240\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[1;32m    241\u001B[0m         )\n",
      "\u001B[0;31mOSError\u001B[0m: No file or directory found at /home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resnet.evaluate(val_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
