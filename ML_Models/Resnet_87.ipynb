{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:08.638206Z",
     "start_time": "2024-07-25T23:31:06.768867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 19:31:06.902335: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 19:31:06.927168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 19:31:06.927200: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 19:31:06.927225: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 19:31:06.932256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 19:31:07.507517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 19:31:08.600611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:08.629022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:08.631545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:08.633841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:08.642702Z",
     "start_time": "2024-07-25T23:31:08.639223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:08.649074Z",
     "start_time": "2024-07-25T23:31:08.643337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:08.776580Z",
     "start_time": "2024-07-25T23:31:08.774282Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:09.262502Z",
     "start_time": "2024-07-25T23:31:09.260277Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:10.681152Z",
     "start_time": "2024-07-25T23:31:09.749353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 19:31:09.810645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:09.813129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:09.815547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:09.945210: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:09.947107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:09.948854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 19:31:09.950581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5955 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-25 19:31:10.108568: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:10.684385Z",
     "start_time": "2024-07-25T23:31:10.682085Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:13.543632Z",
     "start_time": "2024-07-25T23:31:13.541652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.resnet.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:14.798362Z",
     "start_time": "2024-07-25T23:31:14.763292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:15.571255Z",
     "start_time": "2024-07-25T23:31:15.568733Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:19.578101Z",
     "start_time": "2024-07-25T23:31:17.099332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.ResNet152(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:19.582854Z",
     "start_time": "2024-07-25T23:31:19.578933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: conv1_pad, False\n",
      "Layer: conv1_conv, False\n",
      "Layer: conv1_bn, False\n",
      "Layer: conv1_relu, False\n",
      "Layer: pool1_pad, False\n",
      "Layer: pool1_pool, False\n",
      "Layer: conv2_block1_1_conv, False\n",
      "Layer: conv2_block1_1_bn, False\n",
      "Layer: conv2_block1_1_relu, False\n",
      "Layer: conv2_block1_2_conv, False\n",
      "Layer: conv2_block1_2_bn, False\n",
      "Layer: conv2_block1_2_relu, False\n",
      "Layer: conv2_block1_0_conv, False\n",
      "Layer: conv2_block1_3_conv, False\n",
      "Layer: conv2_block1_0_bn, False\n",
      "Layer: conv2_block1_3_bn, False\n",
      "Layer: conv2_block1_add, False\n",
      "Layer: conv2_block1_out, False\n",
      "Layer: conv2_block2_1_conv, False\n",
      "Layer: conv2_block2_1_bn, False\n",
      "Layer: conv2_block2_1_relu, False\n",
      "Layer: conv2_block2_2_conv, False\n",
      "Layer: conv2_block2_2_bn, False\n",
      "Layer: conv2_block2_2_relu, False\n",
      "Layer: conv2_block2_3_conv, False\n",
      "Layer: conv2_block2_3_bn, False\n",
      "Layer: conv2_block2_add, False\n",
      "Layer: conv2_block2_out, False\n",
      "Layer: conv2_block3_1_conv, False\n",
      "Layer: conv2_block3_1_bn, False\n",
      "Layer: conv2_block3_1_relu, False\n",
      "Layer: conv2_block3_2_conv, False\n",
      "Layer: conv2_block3_2_bn, False\n",
      "Layer: conv2_block3_2_relu, False\n",
      "Layer: conv2_block3_3_conv, False\n",
      "Layer: conv2_block3_3_bn, False\n",
      "Layer: conv2_block3_add, False\n",
      "Layer: conv2_block3_out, False\n",
      "Layer: conv3_block1_1_conv, False\n",
      "Layer: conv3_block1_1_bn, False\n",
      "Layer: conv3_block1_1_relu, False\n",
      "Layer: conv3_block1_2_conv, False\n",
      "Layer: conv3_block1_2_bn, False\n",
      "Layer: conv3_block1_2_relu, False\n",
      "Layer: conv3_block1_0_conv, False\n",
      "Layer: conv3_block1_3_conv, False\n",
      "Layer: conv3_block1_0_bn, False\n",
      "Layer: conv3_block1_3_bn, False\n",
      "Layer: conv3_block1_add, False\n",
      "Layer: conv3_block1_out, False\n",
      "Layer: conv3_block2_1_conv, False\n",
      "Layer: conv3_block2_1_bn, False\n",
      "Layer: conv3_block2_1_relu, False\n",
      "Layer: conv3_block2_2_conv, False\n",
      "Layer: conv3_block2_2_bn, False\n",
      "Layer: conv3_block2_2_relu, False\n",
      "Layer: conv3_block2_3_conv, False\n",
      "Layer: conv3_block2_3_bn, False\n",
      "Layer: conv3_block2_add, False\n",
      "Layer: conv3_block2_out, False\n",
      "Layer: conv3_block3_1_conv, False\n",
      "Layer: conv3_block3_1_bn, False\n",
      "Layer: conv3_block3_1_relu, False\n",
      "Layer: conv3_block3_2_conv, False\n",
      "Layer: conv3_block3_2_bn, False\n",
      "Layer: conv3_block3_2_relu, False\n",
      "Layer: conv3_block3_3_conv, False\n",
      "Layer: conv3_block3_3_bn, False\n",
      "Layer: conv3_block3_add, False\n",
      "Layer: conv3_block3_out, False\n",
      "Layer: conv3_block4_1_conv, False\n",
      "Layer: conv3_block4_1_bn, False\n",
      "Layer: conv3_block4_1_relu, False\n",
      "Layer: conv3_block4_2_conv, False\n",
      "Layer: conv3_block4_2_bn, False\n",
      "Layer: conv3_block4_2_relu, False\n",
      "Layer: conv3_block4_3_conv, False\n",
      "Layer: conv3_block4_3_bn, False\n",
      "Layer: conv3_block4_add, False\n",
      "Layer: conv3_block4_out, False\n",
      "Layer: conv3_block5_1_conv, False\n",
      "Layer: conv3_block5_1_bn, False\n",
      "Layer: conv3_block5_1_relu, False\n",
      "Layer: conv3_block5_2_conv, False\n",
      "Layer: conv3_block5_2_bn, False\n",
      "Layer: conv3_block5_2_relu, False\n",
      "Layer: conv3_block5_3_conv, False\n",
      "Layer: conv3_block5_3_bn, False\n",
      "Layer: conv3_block5_add, False\n",
      "Layer: conv3_block5_out, False\n",
      "Layer: conv3_block6_1_conv, False\n",
      "Layer: conv3_block6_1_bn, False\n",
      "Layer: conv3_block6_1_relu, False\n",
      "Layer: conv3_block6_2_conv, False\n",
      "Layer: conv3_block6_2_bn, False\n",
      "Layer: conv3_block6_2_relu, False\n",
      "Layer: conv3_block6_3_conv, False\n",
      "Layer: conv3_block6_3_bn, False\n",
      "Layer: conv3_block6_add, False\n",
      "Layer: conv3_block6_out, False\n",
      "Layer: conv3_block7_1_conv, False\n",
      "Layer: conv3_block7_1_bn, False\n",
      "Layer: conv3_block7_1_relu, False\n",
      "Layer: conv3_block7_2_conv, False\n",
      "Layer: conv3_block7_2_bn, False\n",
      "Layer: conv3_block7_2_relu, False\n",
      "Layer: conv3_block7_3_conv, False\n",
      "Layer: conv3_block7_3_bn, False\n",
      "Layer: conv3_block7_add, False\n",
      "Layer: conv3_block7_out, False\n",
      "Layer: conv3_block8_1_conv, False\n",
      "Layer: conv3_block8_1_bn, False\n",
      "Layer: conv3_block8_1_relu, False\n",
      "Layer: conv3_block8_2_conv, False\n",
      "Layer: conv3_block8_2_bn, False\n",
      "Layer: conv3_block8_2_relu, False\n",
      "Layer: conv3_block8_3_conv, False\n",
      "Layer: conv3_block8_3_bn, False\n",
      "Layer: conv3_block8_add, False\n",
      "Layer: conv3_block8_out, False\n",
      "Layer: conv4_block1_1_conv, False\n",
      "Layer: conv4_block1_1_bn, False\n",
      "Layer: conv4_block1_1_relu, False\n",
      "Layer: conv4_block1_2_conv, False\n",
      "Layer: conv4_block1_2_bn, False\n",
      "Layer: conv4_block1_2_relu, False\n",
      "Layer: conv4_block1_0_conv, False\n",
      "Layer: conv4_block1_3_conv, False\n",
      "Layer: conv4_block1_0_bn, False\n",
      "Layer: conv4_block1_3_bn, False\n",
      "Layer: conv4_block1_add, False\n",
      "Layer: conv4_block1_out, False\n",
      "Layer: conv4_block2_1_conv, False\n",
      "Layer: conv4_block2_1_bn, False\n",
      "Layer: conv4_block2_1_relu, False\n",
      "Layer: conv4_block2_2_conv, False\n",
      "Layer: conv4_block2_2_bn, False\n",
      "Layer: conv4_block2_2_relu, False\n",
      "Layer: conv4_block2_3_conv, False\n",
      "Layer: conv4_block2_3_bn, False\n",
      "Layer: conv4_block2_add, False\n",
      "Layer: conv4_block2_out, False\n",
      "Layer: conv4_block3_1_conv, False\n",
      "Layer: conv4_block3_1_bn, False\n",
      "Layer: conv4_block3_1_relu, False\n",
      "Layer: conv4_block3_2_conv, False\n",
      "Layer: conv4_block3_2_bn, False\n",
      "Layer: conv4_block3_2_relu, False\n",
      "Layer: conv4_block3_3_conv, False\n",
      "Layer: conv4_block3_3_bn, False\n",
      "Layer: conv4_block3_add, False\n",
      "Layer: conv4_block3_out, False\n",
      "Layer: conv4_block4_1_conv, False\n",
      "Layer: conv4_block4_1_bn, False\n",
      "Layer: conv4_block4_1_relu, False\n",
      "Layer: conv4_block4_2_conv, False\n",
      "Layer: conv4_block4_2_bn, False\n",
      "Layer: conv4_block4_2_relu, False\n",
      "Layer: conv4_block4_3_conv, False\n",
      "Layer: conv4_block4_3_bn, False\n",
      "Layer: conv4_block4_add, False\n",
      "Layer: conv4_block4_out, False\n",
      "Layer: conv4_block5_1_conv, False\n",
      "Layer: conv4_block5_1_bn, False\n",
      "Layer: conv4_block5_1_relu, False\n",
      "Layer: conv4_block5_2_conv, False\n",
      "Layer: conv4_block5_2_bn, False\n",
      "Layer: conv4_block5_2_relu, False\n",
      "Layer: conv4_block5_3_conv, False\n",
      "Layer: conv4_block5_3_bn, False\n",
      "Layer: conv4_block5_add, False\n",
      "Layer: conv4_block5_out, False\n",
      "Layer: conv4_block6_1_conv, False\n",
      "Layer: conv4_block6_1_bn, False\n",
      "Layer: conv4_block6_1_relu, False\n",
      "Layer: conv4_block6_2_conv, False\n",
      "Layer: conv4_block6_2_bn, False\n",
      "Layer: conv4_block6_2_relu, False\n",
      "Layer: conv4_block6_3_conv, False\n",
      "Layer: conv4_block6_3_bn, False\n",
      "Layer: conv4_block6_add, False\n",
      "Layer: conv4_block6_out, False\n",
      "Layer: conv4_block7_1_conv, False\n",
      "Layer: conv4_block7_1_bn, False\n",
      "Layer: conv4_block7_1_relu, False\n",
      "Layer: conv4_block7_2_conv, False\n",
      "Layer: conv4_block7_2_bn, False\n",
      "Layer: conv4_block7_2_relu, False\n",
      "Layer: conv4_block7_3_conv, False\n",
      "Layer: conv4_block7_3_bn, False\n",
      "Layer: conv4_block7_add, False\n",
      "Layer: conv4_block7_out, False\n",
      "Layer: conv4_block8_1_conv, False\n",
      "Layer: conv4_block8_1_bn, False\n",
      "Layer: conv4_block8_1_relu, False\n",
      "Layer: conv4_block8_2_conv, False\n",
      "Layer: conv4_block8_2_bn, False\n",
      "Layer: conv4_block8_2_relu, False\n",
      "Layer: conv4_block8_3_conv, False\n",
      "Layer: conv4_block8_3_bn, False\n",
      "Layer: conv4_block8_add, False\n",
      "Layer: conv4_block8_out, False\n",
      "Layer: conv4_block9_1_conv, False\n",
      "Layer: conv4_block9_1_bn, False\n",
      "Layer: conv4_block9_1_relu, False\n",
      "Layer: conv4_block9_2_conv, False\n",
      "Layer: conv4_block9_2_bn, False\n",
      "Layer: conv4_block9_2_relu, False\n",
      "Layer: conv4_block9_3_conv, False\n",
      "Layer: conv4_block9_3_bn, False\n",
      "Layer: conv4_block9_add, False\n",
      "Layer: conv4_block9_out, False\n",
      "Layer: conv4_block10_1_conv, False\n",
      "Layer: conv4_block10_1_bn, False\n",
      "Layer: conv4_block10_1_relu, False\n",
      "Layer: conv4_block10_2_conv, False\n",
      "Layer: conv4_block10_2_bn, False\n",
      "Layer: conv4_block10_2_relu, False\n",
      "Layer: conv4_block10_3_conv, False\n",
      "Layer: conv4_block10_3_bn, False\n",
      "Layer: conv4_block10_add, False\n",
      "Layer: conv4_block10_out, False\n",
      "Layer: conv4_block11_1_conv, False\n",
      "Layer: conv4_block11_1_bn, False\n",
      "Layer: conv4_block11_1_relu, False\n",
      "Layer: conv4_block11_2_conv, False\n",
      "Layer: conv4_block11_2_bn, False\n",
      "Layer: conv4_block11_2_relu, False\n",
      "Layer: conv4_block11_3_conv, False\n",
      "Layer: conv4_block11_3_bn, False\n",
      "Layer: conv4_block11_add, False\n",
      "Layer: conv4_block11_out, False\n",
      "Layer: conv4_block12_1_conv, False\n",
      "Layer: conv4_block12_1_bn, False\n",
      "Layer: conv4_block12_1_relu, False\n",
      "Layer: conv4_block12_2_conv, False\n",
      "Layer: conv4_block12_2_bn, False\n",
      "Layer: conv4_block12_2_relu, False\n",
      "Layer: conv4_block12_3_conv, False\n",
      "Layer: conv4_block12_3_bn, False\n",
      "Layer: conv4_block12_add, False\n",
      "Layer: conv4_block12_out, False\n",
      "Layer: conv4_block13_1_conv, False\n",
      "Layer: conv4_block13_1_bn, False\n",
      "Layer: conv4_block13_1_relu, False\n",
      "Layer: conv4_block13_2_conv, False\n",
      "Layer: conv4_block13_2_bn, False\n",
      "Layer: conv4_block13_2_relu, False\n",
      "Layer: conv4_block13_3_conv, False\n",
      "Layer: conv4_block13_3_bn, False\n",
      "Layer: conv4_block13_add, False\n",
      "Layer: conv4_block13_out, False\n",
      "Layer: conv4_block14_1_conv, False\n",
      "Layer: conv4_block14_1_bn, False\n",
      "Layer: conv4_block14_1_relu, False\n",
      "Layer: conv4_block14_2_conv, False\n",
      "Layer: conv4_block14_2_bn, False\n",
      "Layer: conv4_block14_2_relu, False\n",
      "Layer: conv4_block14_3_conv, False\n",
      "Layer: conv4_block14_3_bn, False\n",
      "Layer: conv4_block14_add, False\n",
      "Layer: conv4_block14_out, False\n",
      "Layer: conv4_block15_1_conv, False\n",
      "Layer: conv4_block15_1_bn, False\n",
      "Layer: conv4_block15_1_relu, False\n",
      "Layer: conv4_block15_2_conv, False\n",
      "Layer: conv4_block15_2_bn, False\n",
      "Layer: conv4_block15_2_relu, False\n",
      "Layer: conv4_block15_3_conv, False\n",
      "Layer: conv4_block15_3_bn, False\n",
      "Layer: conv4_block15_add, False\n",
      "Layer: conv4_block15_out, False\n",
      "Layer: conv4_block16_1_conv, False\n",
      "Layer: conv4_block16_1_bn, False\n",
      "Layer: conv4_block16_1_relu, False\n",
      "Layer: conv4_block16_2_conv, False\n",
      "Layer: conv4_block16_2_bn, False\n",
      "Layer: conv4_block16_2_relu, False\n",
      "Layer: conv4_block16_3_conv, False\n",
      "Layer: conv4_block16_3_bn, False\n",
      "Layer: conv4_block16_add, False\n",
      "Layer: conv4_block16_out, False\n",
      "Layer: conv4_block17_1_conv, False\n",
      "Layer: conv4_block17_1_bn, False\n",
      "Layer: conv4_block17_1_relu, False\n",
      "Layer: conv4_block17_2_conv, False\n",
      "Layer: conv4_block17_2_bn, False\n",
      "Layer: conv4_block17_2_relu, False\n",
      "Layer: conv4_block17_3_conv, False\n",
      "Layer: conv4_block17_3_bn, False\n",
      "Layer: conv4_block17_add, False\n",
      "Layer: conv4_block17_out, False\n",
      "Layer: conv4_block18_1_conv, False\n",
      "Layer: conv4_block18_1_bn, False\n",
      "Layer: conv4_block18_1_relu, False\n",
      "Layer: conv4_block18_2_conv, False\n",
      "Layer: conv4_block18_2_bn, False\n",
      "Layer: conv4_block18_2_relu, False\n",
      "Layer: conv4_block18_3_conv, False\n",
      "Layer: conv4_block18_3_bn, False\n",
      "Layer: conv4_block18_add, False\n",
      "Layer: conv4_block18_out, False\n",
      "Layer: conv4_block19_1_conv, False\n",
      "Layer: conv4_block19_1_bn, False\n",
      "Layer: conv4_block19_1_relu, False\n",
      "Layer: conv4_block19_2_conv, False\n",
      "Layer: conv4_block19_2_bn, False\n",
      "Layer: conv4_block19_2_relu, False\n",
      "Layer: conv4_block19_3_conv, False\n",
      "Layer: conv4_block19_3_bn, False\n",
      "Layer: conv4_block19_add, False\n",
      "Layer: conv4_block19_out, False\n",
      "Layer: conv4_block20_1_conv, False\n",
      "Layer: conv4_block20_1_bn, False\n",
      "Layer: conv4_block20_1_relu, False\n",
      "Layer: conv4_block20_2_conv, False\n",
      "Layer: conv4_block20_2_bn, False\n",
      "Layer: conv4_block20_2_relu, False\n",
      "Layer: conv4_block20_3_conv, False\n",
      "Layer: conv4_block20_3_bn, False\n",
      "Layer: conv4_block20_add, False\n",
      "Layer: conv4_block20_out, False\n",
      "Layer: conv4_block21_1_conv, False\n",
      "Layer: conv4_block21_1_bn, False\n",
      "Layer: conv4_block21_1_relu, False\n",
      "Layer: conv4_block21_2_conv, False\n",
      "Layer: conv4_block21_2_bn, False\n",
      "Layer: conv4_block21_2_relu, False\n",
      "Layer: conv4_block21_3_conv, False\n",
      "Layer: conv4_block21_3_bn, False\n",
      "Layer: conv4_block21_add, False\n",
      "Layer: conv4_block21_out, False\n",
      "Layer: conv4_block22_1_conv, False\n",
      "Layer: conv4_block22_1_bn, False\n",
      "Layer: conv4_block22_1_relu, False\n",
      "Layer: conv4_block22_2_conv, False\n",
      "Layer: conv4_block22_2_bn, False\n",
      "Layer: conv4_block22_2_relu, False\n",
      "Layer: conv4_block22_3_conv, False\n",
      "Layer: conv4_block22_3_bn, False\n",
      "Layer: conv4_block22_add, False\n",
      "Layer: conv4_block22_out, False\n",
      "Layer: conv4_block23_1_conv, False\n",
      "Layer: conv4_block23_1_bn, False\n",
      "Layer: conv4_block23_1_relu, False\n",
      "Layer: conv4_block23_2_conv, False\n",
      "Layer: conv4_block23_2_bn, False\n",
      "Layer: conv4_block23_2_relu, False\n",
      "Layer: conv4_block23_3_conv, False\n",
      "Layer: conv4_block23_3_bn, False\n",
      "Layer: conv4_block23_add, False\n",
      "Layer: conv4_block23_out, False\n",
      "Layer: conv4_block24_1_conv, False\n",
      "Layer: conv4_block24_1_bn, False\n",
      "Layer: conv4_block24_1_relu, False\n",
      "Layer: conv4_block24_2_conv, False\n",
      "Layer: conv4_block24_2_bn, False\n",
      "Layer: conv4_block24_2_relu, False\n",
      "Layer: conv4_block24_3_conv, False\n",
      "Layer: conv4_block24_3_bn, False\n",
      "Layer: conv4_block24_add, False\n",
      "Layer: conv4_block24_out, False\n",
      "Layer: conv4_block25_1_conv, False\n",
      "Layer: conv4_block25_1_bn, False\n",
      "Layer: conv4_block25_1_relu, False\n",
      "Layer: conv4_block25_2_conv, False\n",
      "Layer: conv4_block25_2_bn, False\n",
      "Layer: conv4_block25_2_relu, False\n",
      "Layer: conv4_block25_3_conv, False\n",
      "Layer: conv4_block25_3_bn, False\n",
      "Layer: conv4_block25_add, False\n",
      "Layer: conv4_block25_out, False\n",
      "Layer: conv4_block26_1_conv, False\n",
      "Layer: conv4_block26_1_bn, False\n",
      "Layer: conv4_block26_1_relu, False\n",
      "Layer: conv4_block26_2_conv, False\n",
      "Layer: conv4_block26_2_bn, False\n",
      "Layer: conv4_block26_2_relu, False\n",
      "Layer: conv4_block26_3_conv, False\n",
      "Layer: conv4_block26_3_bn, False\n",
      "Layer: conv4_block26_add, False\n",
      "Layer: conv4_block26_out, False\n",
      "Layer: conv4_block27_1_conv, False\n",
      "Layer: conv4_block27_1_bn, False\n",
      "Layer: conv4_block27_1_relu, False\n",
      "Layer: conv4_block27_2_conv, False\n",
      "Layer: conv4_block27_2_bn, False\n",
      "Layer: conv4_block27_2_relu, False\n",
      "Layer: conv4_block27_3_conv, False\n",
      "Layer: conv4_block27_3_bn, False\n",
      "Layer: conv4_block27_add, False\n",
      "Layer: conv4_block27_out, False\n",
      "Layer: conv4_block28_1_conv, False\n",
      "Layer: conv4_block28_1_bn, False\n",
      "Layer: conv4_block28_1_relu, False\n",
      "Layer: conv4_block28_2_conv, False\n",
      "Layer: conv4_block28_2_bn, False\n",
      "Layer: conv4_block28_2_relu, False\n",
      "Layer: conv4_block28_3_conv, False\n",
      "Layer: conv4_block28_3_bn, False\n",
      "Layer: conv4_block28_add, False\n",
      "Layer: conv4_block28_out, False\n",
      "Layer: conv4_block29_1_conv, False\n",
      "Layer: conv4_block29_1_bn, False\n",
      "Layer: conv4_block29_1_relu, False\n",
      "Layer: conv4_block29_2_conv, False\n",
      "Layer: conv4_block29_2_bn, False\n",
      "Layer: conv4_block29_2_relu, False\n",
      "Layer: conv4_block29_3_conv, False\n",
      "Layer: conv4_block29_3_bn, False\n",
      "Layer: conv4_block29_add, False\n",
      "Layer: conv4_block29_out, False\n",
      "Layer: conv4_block30_1_conv, False\n",
      "Layer: conv4_block30_1_bn, False\n",
      "Layer: conv4_block30_1_relu, False\n",
      "Layer: conv4_block30_2_conv, False\n",
      "Layer: conv4_block30_2_bn, False\n",
      "Layer: conv4_block30_2_relu, False\n",
      "Layer: conv4_block30_3_conv, False\n",
      "Layer: conv4_block30_3_bn, False\n",
      "Layer: conv4_block30_add, False\n",
      "Layer: conv4_block30_out, False\n",
      "Layer: conv4_block31_1_conv, False\n",
      "Layer: conv4_block31_1_bn, False\n",
      "Layer: conv4_block31_1_relu, False\n",
      "Layer: conv4_block31_2_conv, False\n",
      "Layer: conv4_block31_2_bn, False\n",
      "Layer: conv4_block31_2_relu, False\n",
      "Layer: conv4_block31_3_conv, False\n",
      "Layer: conv4_block31_3_bn, False\n",
      "Layer: conv4_block31_add, False\n",
      "Layer: conv4_block31_out, False\n",
      "Layer: conv4_block32_1_conv, False\n",
      "Layer: conv4_block32_1_bn, False\n",
      "Layer: conv4_block32_1_relu, False\n",
      "Layer: conv4_block32_2_conv, False\n",
      "Layer: conv4_block32_2_bn, False\n",
      "Layer: conv4_block32_2_relu, False\n",
      "Layer: conv4_block32_3_conv, False\n",
      "Layer: conv4_block32_3_bn, False\n",
      "Layer: conv4_block32_add, False\n",
      "Layer: conv4_block32_out, False\n",
      "Layer: conv4_block33_1_conv, False\n",
      "Layer: conv4_block33_1_bn, False\n",
      "Layer: conv4_block33_1_relu, False\n",
      "Layer: conv4_block33_2_conv, False\n",
      "Layer: conv4_block33_2_bn, False\n",
      "Layer: conv4_block33_2_relu, False\n",
      "Layer: conv4_block33_3_conv, False\n",
      "Layer: conv4_block33_3_bn, False\n",
      "Layer: conv4_block33_add, False\n",
      "Layer: conv4_block33_out, False\n",
      "Layer: conv4_block34_1_conv, False\n",
      "Layer: conv4_block34_1_bn, False\n",
      "Layer: conv4_block34_1_relu, False\n",
      "Layer: conv4_block34_2_conv, False\n",
      "Layer: conv4_block34_2_bn, False\n",
      "Layer: conv4_block34_2_relu, False\n",
      "Layer: conv4_block34_3_conv, False\n",
      "Layer: conv4_block34_3_bn, False\n",
      "Layer: conv4_block34_add, False\n",
      "Layer: conv4_block34_out, False\n",
      "Layer: conv4_block35_1_conv, False\n",
      "Layer: conv4_block35_1_bn, False\n",
      "Layer: conv4_block35_1_relu, False\n",
      "Layer: conv4_block35_2_conv, False\n",
      "Layer: conv4_block35_2_bn, False\n",
      "Layer: conv4_block35_2_relu, False\n",
      "Layer: conv4_block35_3_conv, False\n",
      "Layer: conv4_block35_3_bn, False\n",
      "Layer: conv4_block35_add, False\n",
      "Layer: conv4_block35_out, False\n",
      "Layer: conv4_block36_1_conv, False\n",
      "Layer: conv4_block36_1_bn, False\n",
      "Layer: conv4_block36_1_relu, False\n",
      "Layer: conv4_block36_2_conv, False\n",
      "Layer: conv4_block36_2_bn, False\n",
      "Layer: conv4_block36_2_relu, False\n",
      "Layer: conv4_block36_3_conv, False\n",
      "Layer: conv4_block36_3_bn, False\n",
      "Layer: conv4_block36_add, False\n",
      "Layer: conv4_block36_out, False\n",
      "Layer: conv5_block1_1_conv, False\n",
      "Layer: conv5_block1_1_bn, False\n",
      "Layer: conv5_block1_1_relu, False\n",
      "Layer: conv5_block1_2_conv, False\n",
      "Layer: conv5_block1_2_bn, False\n",
      "Layer: conv5_block1_2_relu, False\n",
      "Layer: conv5_block1_0_conv, False\n",
      "Layer: conv5_block1_3_conv, False\n",
      "Layer: conv5_block1_0_bn, False\n",
      "Layer: conv5_block1_3_bn, False\n",
      "Layer: conv5_block1_add, False\n",
      "Layer: conv5_block1_out, False\n",
      "Layer: conv5_block2_1_conv, False\n",
      "Layer: conv5_block2_1_bn, False\n",
      "Layer: conv5_block2_1_relu, False\n",
      "Layer: conv5_block2_2_conv, False\n",
      "Layer: conv5_block2_2_bn, False\n",
      "Layer: conv5_block2_2_relu, False\n",
      "Layer: conv5_block2_3_conv, False\n",
      "Layer: conv5_block2_3_bn, False\n",
      "Layer: conv5_block2_add, False\n",
      "Layer: conv5_block2_out, False\n",
      "Layer: conv5_block3_1_conv, False\n",
      "Layer: conv5_block3_1_bn, False\n",
      "Layer: conv5_block3_1_relu, False\n",
      "Layer: conv5_block3_2_conv, False\n",
      "Layer: conv5_block3_2_bn, False\n",
      "Layer: conv5_block3_2_relu, False\n",
      "Layer: conv5_block3_3_conv, False\n",
      "Layer: conv5_block3_3_bn, False\n",
      "Layer: conv5_block3_add, False\n",
      "Layer: conv5_block3_out, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:19.587515Z",
     "start_time": "2024-07-25T23:31:19.583618Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:20.327369Z",
     "start_time": "2024-07-25T23:31:20.324512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:31:21.372315Z",
     "start_time": "2024-07-25T23:31:21.366279Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:32:23.969104Z",
     "start_time": "2024-07-25T23:32:23.307713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "x = aug_layer(inputs)\n",
    "#x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'Resnet')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 565956 (2.16 MB)\n",
      "Non-trainable params: 58370944 (222.67 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:32:26.632793Z",
     "start_time": "2024-07-25T23:32:26.630540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models',model_1.name), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:32:27.859922Z",
     "start_time": "2024-07-25T23:32:27.857707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=3) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:32:30.638312Z",
     "start_time": "2024-07-25T23:32:30.620884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:37:08.182515Z",
     "start_time": "2024-07-25T23:32:34.707840Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 10, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 19:32:39.730883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-25 19:32:39.814778: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-25 19:32:40.773586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x75d3f04c4520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-25 19:32:40.773610: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-25 19:32:40.777418: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-25 19:32:40.844581: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 1.1837 - accuracy: 0.4824\n",
      "Epoch 1: val_loss improved from inf to 1.29870, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 65s 795ms/step - loss: 1.1837 - accuracy: 0.4824 - val_loss: 1.2987 - val_accuracy: 0.1523 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8603 - accuracy: 0.6171\n",
      "Epoch 2: val_loss improved from 1.29870 to 1.22425, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 47s 636ms/step - loss: 0.8603 - accuracy: 0.6171 - val_loss: 1.2242 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.7061\n",
      "Epoch 3: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 24s 313ms/step - loss: 0.7279 - accuracy: 0.7061 - val_loss: 1.2307 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.7518\n",
      "Epoch 4: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 23s 304ms/step - loss: 0.6461 - accuracy: 0.7518 - val_loss: 1.5811 - val_accuracy: 0.3769 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.7772\n",
      "Epoch 5: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 21s 275ms/step - loss: 0.6181 - accuracy: 0.7772 - val_loss: 2.0851 - val_accuracy: 0.3165 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.8018\n",
      "Epoch 6: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 20s 266ms/step - loss: 0.5244 - accuracy: 0.8018 - val_loss: 1.5103 - val_accuracy: 0.4293 - lr: 3.0000e-04\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8081\n",
      "Epoch 7: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 20s 260ms/step - loss: 0.4994 - accuracy: 0.8081 - val_loss: 1.2683 - val_accuracy: 0.5153 - lr: 3.0000e-04\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.8098\n",
      "Epoch 8: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 19s 251ms/step - loss: 0.4898 - accuracy: 0.8098 - val_loss: 1.9213 - val_accuracy: 0.3482 - lr: 3.0000e-04\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.8153\n",
      "Epoch 9: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 18s 240ms/step - loss: 0.4854 - accuracy: 0.8153 - val_loss: 2.0711 - val_accuracy: 0.3116 - lr: 9.0000e-05\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.8251\n",
      "Epoch 10: val_loss did not improve from 1.22425\n",
      "74/74 [==============================] - 18s 232ms/step - loss: 0.4733 - accuracy: 0.8251 - val_loss: 1.7814 - val_accuracy: 0.3680 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:37:08.191601Z",
     "start_time": "2024-07-25T23:37:08.183793Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:37:08.203751Z",
     "start_time": "2024-07-25T23:37:08.192174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-100]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:37:08.209953Z",
     "start_time": "2024-07-25T23:37:08.204561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:37:15.059630Z",
     "start_time": "2024-07-25T23:37:15.019906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 10\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 23110084 (88.16 MB)\n",
      "Non-trainable params: 35826816 (136.67 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:42:53.533941Z",
     "start_time": "2024-07-25T23:37:21.070571Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.8245 - accuracy: 0.4807\n",
      "Epoch 11: val_loss improved from 1.22425 to 1.12950, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 68s 720ms/step - loss: 1.8245 - accuracy: 0.4807 - val_loss: 1.1295 - val_accuracy: 0.5391 - lr: 3.0000e-04\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7034 - accuracy: 0.7188\n",
      "Epoch 12: val_loss did not improve from 1.12950\n",
      "74/74 [==============================] - 21s 285ms/step - loss: 0.7034 - accuracy: 0.7188 - val_loss: 1.2388 - val_accuracy: 0.3848 - lr: 3.0000e-04\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.7442\n",
      "Epoch 13: val_loss did not improve from 1.12950\n",
      "74/74 [==============================] - 20s 265ms/step - loss: 0.6494 - accuracy: 0.7442 - val_loss: 2.6194 - val_accuracy: 0.2087 - lr: 3.0000e-04\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.8090\n",
      "Epoch 14: val_loss did not improve from 1.12950\n",
      "74/74 [==============================] - 18s 243ms/step - loss: 0.5506 - accuracy: 0.8090 - val_loss: 1.2195 - val_accuracy: 0.4045 - lr: 3.0000e-04\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.8458\n",
      "Epoch 15: val_loss improved from 1.12950 to 1.00640, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 44s 595ms/step - loss: 0.4385 - accuracy: 0.8458 - val_loss: 1.0064 - val_accuracy: 0.5213 - lr: 9.0000e-05\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.8539\n",
      "Epoch 16: val_loss improved from 1.00640 to 0.72831, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 42s 565ms/step - loss: 0.4099 - accuracy: 0.8539 - val_loss: 0.7283 - val_accuracy: 0.6706 - lr: 9.0000e-05\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8526\n",
      "Epoch 17: val_loss did not improve from 0.72831\n",
      "74/74 [==============================] - 18s 234ms/step - loss: 0.4087 - accuracy: 0.8526 - val_loss: 1.4958 - val_accuracy: 0.3877 - lr: 9.0000e-05\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8738\n",
      "Epoch 18: val_loss improved from 0.72831 to 0.57274, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 42s 571ms/step - loss: 0.3658 - accuracy: 0.8738 - val_loss: 0.5727 - val_accuracy: 0.7765 - lr: 9.0000e-05\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8577\n",
      "Epoch 19: val_loss improved from 0.57274 to 0.48563, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 40s 540ms/step - loss: 0.3837 - accuracy: 0.8577 - val_loss: 0.4856 - val_accuracy: 0.8892 - lr: 9.0000e-05\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8789\n",
      "Epoch 20: val_loss did not improve from 0.48563\n",
      "74/74 [==============================] - 19s 250ms/step - loss: 0.3530 - accuracy: 0.8789 - val_loss: 0.6559 - val_accuracy: 0.7300 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:43:47.861149Z",
     "start_time": "2024-07-25T23:43:47.856587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 20\n",
    "for layer in base_model.layers[-200:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:43:58.150733Z",
     "start_time": "2024-07-25T23:43:58.094509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00005), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 34297284 (130.83 MB)\n",
      "Non-trainable params: 24639616 (93.99 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:49:11.109979Z",
     "start_time": "2024-07-25T23:44:07.901004Z"
    }
   },
   "cell_type": "code",
   "source": "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8683\n",
      "Epoch 21: val_loss did not improve from 0.48563\n",
      "74/74 [==============================] - 45s 300ms/step - loss: 0.3866 - accuracy: 0.8683 - val_loss: 0.6606 - val_accuracy: 0.7310 - lr: 5.0000e-05\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8759\n",
      "Epoch 22: val_loss improved from 0.48563 to 0.12277, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 46s 625ms/step - loss: 0.3513 - accuracy: 0.8759 - val_loss: 0.1228 - val_accuracy: 0.9753 - lr: 5.0000e-05\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8797\n",
      "Epoch 23: val_loss did not improve from 0.12277\n",
      "74/74 [==============================] - 20s 261ms/step - loss: 0.3255 - accuracy: 0.8797 - val_loss: 0.3729 - val_accuracy: 0.8645 - lr: 5.0000e-05\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.9055\n",
      "Epoch 24: val_loss did not improve from 0.12277\n",
      "74/74 [==============================] - 20s 264ms/step - loss: 0.2965 - accuracy: 0.9055 - val_loss: 0.1655 - val_accuracy: 0.9436 - lr: 5.0000e-05\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.9022\n",
      "Epoch 25: val_loss did not improve from 0.12277\n",
      "74/74 [==============================] - 19s 258ms/step - loss: 0.2912 - accuracy: 0.9022 - val_loss: 0.2188 - val_accuracy: 0.9318 - lr: 5.0000e-05\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9233\n",
      "Epoch 26: val_loss improved from 0.12277 to 0.08150, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 48s 644ms/step - loss: 0.2335 - accuracy: 0.9233 - val_loss: 0.0815 - val_accuracy: 0.9733 - lr: 1.5000e-05\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9250\n",
      "Epoch 27: val_loss improved from 0.08150 to 0.08031, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 48s 646ms/step - loss: 0.2114 - accuracy: 0.9250 - val_loss: 0.0803 - val_accuracy: 0.9802 - lr: 1.5000e-05\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9267\n",
      "Epoch 28: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 20s 258ms/step - loss: 0.2135 - accuracy: 0.9267 - val_loss: 0.1165 - val_accuracy: 0.9674 - lr: 1.5000e-05\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.9318\n",
      "Epoch 29: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 19s 254ms/step - loss: 0.2009 - accuracy: 0.9318 - val_loss: 0.0870 - val_accuracy: 0.9782 - lr: 1.5000e-05\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9348\n",
      "Epoch 30: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 18s 244ms/step - loss: 0.1968 - accuracy: 0.9348 - val_loss: 0.1110 - val_accuracy: 0.9693 - lr: 1.5000e-05\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:49:11.117505Z",
     "start_time": "2024-07-25T23:49:11.111064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 30\n",
    "for layer in base_model.layers[-300:]:\n",
    "    layer.trainable = True"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:49:11.194870Z",
     "start_time": "2024-07-25T23:49:11.118218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00009), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 45484484 (173.51 MB)\n",
      "Non-trainable params: 13452416 (51.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:54:03.897112Z",
     "start_time": "2024-07-25T23:49:11.195700Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.8619\n",
      "Epoch 31: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 54s 291ms/step - loss: 0.4440 - accuracy: 0.8619 - val_loss: 0.1423 - val_accuracy: 0.9594 - lr: 9.0000e-05\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.8937\n",
      "Epoch 32: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 19s 256ms/step - loss: 0.3214 - accuracy: 0.8937 - val_loss: 0.1051 - val_accuracy: 0.9674 - lr: 9.0000e-05\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.8967\n",
      "Epoch 33: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 20s 266ms/step - loss: 0.3136 - accuracy: 0.8967 - val_loss: 0.2196 - val_accuracy: 0.9357 - lr: 9.0000e-05\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.8920\n",
      "Epoch 34: val_loss did not improve from 0.08031\n",
      "74/74 [==============================] - 19s 258ms/step - loss: 0.3187 - accuracy: 0.8920 - val_loss: 0.1450 - val_accuracy: 0.9664 - lr: 9.0000e-05\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9153\n",
      "Epoch 35: val_loss improved from 0.08031 to 0.07935, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 56s 753ms/step - loss: 0.2571 - accuracy: 0.9153 - val_loss: 0.0793 - val_accuracy: 0.9713 - lr: 9.0000e-05\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.9030\n",
      "Epoch 36: val_loss did not improve from 0.07935\n",
      "74/74 [==============================] - 20s 268ms/step - loss: 0.3020 - accuracy: 0.9030 - val_loss: 0.1073 - val_accuracy: 0.9723 - lr: 9.0000e-05\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9225\n",
      "Epoch 37: val_loss improved from 0.07935 to 0.05755, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 48s 644ms/step - loss: 0.2405 - accuracy: 0.9225 - val_loss: 0.0576 - val_accuracy: 0.9832 - lr: 9.0000e-05\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9178\n",
      "Epoch 38: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 18s 243ms/step - loss: 0.2280 - accuracy: 0.9178 - val_loss: 0.1797 - val_accuracy: 0.9525 - lr: 9.0000e-05\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2480 - accuracy: 0.9166\n",
      "Epoch 39: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 18s 241ms/step - loss: 0.2480 - accuracy: 0.9166 - val_loss: 0.0798 - val_accuracy: 0.9753 - lr: 9.0000e-05\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.9322\n",
      "Epoch 40: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 20s 265ms/step - loss: 0.2166 - accuracy: 0.9322 - val_loss: 0.1572 - val_accuracy: 0.9594 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:54:03.906374Z",
     "start_time": "2024-07-25T23:54:03.898184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 40\n",
    "for layer in base_model.layers[-450:]:\n",
    "    layer.trainable = True"
   ],
   "id": "5a4cd9a6567e4701",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:54:03.970717Z",
     "start_time": "2024-07-25T23:54:03.907078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00005), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "23a1c345daf87a3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 57683652 (220.05 MB)\n",
      "Non-trainable params: 1253248 (4.78 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:59:37.318129Z",
     "start_time": "2024-07-25T23:54:08.797812Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "6d8eb63102e1de90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.9000\n",
      "Epoch 41: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 84s 489ms/step - loss: 0.3006 - accuracy: 0.9000 - val_loss: 0.1595 - val_accuracy: 0.9555 - lr: 5.0000e-05\n",
      "Epoch 42/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9238\n",
      "Epoch 42: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 29s 388ms/step - loss: 0.2307 - accuracy: 0.9238 - val_loss: 0.0795 - val_accuracy: 0.9743 - lr: 5.0000e-05\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9327\n",
      "Epoch 43: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 27s 355ms/step - loss: 0.2274 - accuracy: 0.9327 - val_loss: 0.0609 - val_accuracy: 0.9842 - lr: 5.0000e-05\n",
      "Epoch 44/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.8916\n",
      "Epoch 44: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 25s 337ms/step - loss: 0.3318 - accuracy: 0.8916 - val_loss: 0.1507 - val_accuracy: 0.9525 - lr: 5.0000e-05\n",
      "Epoch 45/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.9187\n",
      "Epoch 45: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 24s 324ms/step - loss: 0.2501 - accuracy: 0.9187 - val_loss: 0.0856 - val_accuracy: 0.9723 - lr: 5.0000e-05\n",
      "Epoch 46/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9411\n",
      "Epoch 46: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 23s 305ms/step - loss: 0.1764 - accuracy: 0.9411 - val_loss: 0.1330 - val_accuracy: 0.9674 - lr: 5.0000e-05\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9593\n",
      "Epoch 47: val_loss did not improve from 0.05755\n",
      "74/74 [==============================] - 24s 313ms/step - loss: 0.1448 - accuracy: 0.9593 - val_loss: 0.0819 - val_accuracy: 0.9693 - lr: 1.5000e-05\n",
      "Epoch 48/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9636\n",
      "Epoch 48: val_loss improved from 0.05755 to 0.04952, saving model to Trained_Models/Resnet\n",
      "74/74 [==============================] - 50s 681ms/step - loss: 0.1125 - accuracy: 0.9636 - val_loss: 0.0495 - val_accuracy: 0.9842 - lr: 1.5000e-05\n",
      "Epoch 49/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9678\n",
      "Epoch 49: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 21s 279ms/step - loss: 0.0960 - accuracy: 0.9678 - val_loss: 0.0886 - val_accuracy: 0.9723 - lr: 1.5000e-05\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9695\n",
      "Epoch 50: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 21s 280ms/step - loss: 0.0953 - accuracy: 0.9695 - val_loss: 0.0846 - val_accuracy: 0.9713 - lr: 1.5000e-05\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:01:09.040648Z",
     "start_time": "2024-07-26T00:01:09.032554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 50\n",
    "for layer in base_model.layers[-510:]:\n",
    "    layer.trainable = True"
   ],
   "id": "93ad3cc030c9c69",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:01:14.096107Z",
     "start_time": "2024-07-26T00:01:14.039694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000005), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "9ed4bf4a63f90d77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 7, 7, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58936900 (224.83 MB)\n",
      "Trainable params: 58775876 (224.21 MB)\n",
      "Non-trainable params: 161024 (629.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:04:45.822727Z",
     "start_time": "2024-07-26T00:01:22.262325Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "b0794490c20e0209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9788\n",
      "Epoch 51: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 86s 581ms/step - loss: 0.0817 - accuracy: 0.9788 - val_loss: 0.0766 - val_accuracy: 0.9773 - lr: 5.0000e-06\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9818\n",
      "Epoch 52: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 39s 521ms/step - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.1039 - val_accuracy: 0.9753 - lr: 5.0000e-06\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9818\n",
      "Epoch 53: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 38s 506ms/step - loss: 0.0651 - accuracy: 0.9818 - val_loss: 0.0727 - val_accuracy: 0.9763 - lr: 5.0000e-06\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9792\n",
      "Epoch 54: val_loss did not improve from 0.04952\n",
      "74/74 [==============================] - 34s 447ms/step - loss: 0.0696 - accuracy: 0.9792 - val_loss: 0.0556 - val_accuracy: 0.9792 - lr: 5.0000e-06\n",
      "Epoch 55/60\n",
      "10/74 [===>..........................] - ETA: 34s - loss: 0.0599 - accuracy: 0.9812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history_500 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_1chkpt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:05:26.202107Z",
     "start_time": "2024-07-26T00:05:11.958054Z"
    }
   },
   "cell_type": "code",
   "source": "resnet = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T00:05:46.917207Z",
     "start_time": "2024-07-26T00:05:44.665455Z"
    }
   },
   "cell_type": "code",
   "source": "resnet.evaluate(val_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 67ms/step - loss: 0.0495 - accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04952496290206909, 0.9841740727424622]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
