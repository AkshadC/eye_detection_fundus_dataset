{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:31.155693Z",
     "start_time": "2024-07-25T22:50:29.299699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:50:29.443669: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 18:50:29.468501: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 18:50:29.468529: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 18:50:29.468555: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 18:50:29.473893: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 18:50:30.053018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:50:31.119907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:31.143959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:31.147237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:31.150160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:31.160878Z",
     "start_time": "2024-07-25T22:50:31.156599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:33.511906Z",
     "start_time": "2024-07-25T22:50:33.509015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:34.654841Z",
     "start_time": "2024-07-25T22:50:34.652114Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:35.275009Z",
     "start_time": "2024-07-25T22:50:35.272967Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:36.656891Z",
     "start_time": "2024-07-25T22:50:35.719197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:50:35.782371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:35.786517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:35.790135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:35.913897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:35.915576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:35.917393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:50:35.919126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5984 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-25 18:50:36.072955: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:37.120053Z",
     "start_time": "2024-07-25T22:50:37.117010Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:37.650631Z",
     "start_time": "2024-07-25T22:50:37.648700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.mobilenet_v3.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:43.053118Z",
     "start_time": "2024-07-25T22:50:43.021124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:43.437770Z",
     "start_time": "2024-07-25T22:50:43.434766Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:45.488282Z",
     "start_time": "2024-07-25T22:50:44.347464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.MobileNetV3Large(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:45.492760Z",
     "start_time": "2024-07-25T22:50:45.489216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: rescaling, False\n",
      "Layer: Conv, False\n",
      "Layer: Conv/BatchNorm, False\n",
      "Layer: tf.math.add, False\n",
      "Layer: re_lu, False\n",
      "Layer: tf.math.multiply, False\n",
      "Layer: multiply, False\n",
      "Layer: expanded_conv/depthwise, False\n",
      "Layer: expanded_conv/depthwise/BatchNorm, False\n",
      "Layer: re_lu_1, False\n",
      "Layer: expanded_conv/project, False\n",
      "Layer: expanded_conv/project/BatchNorm, False\n",
      "Layer: expanded_conv/Add, False\n",
      "Layer: expanded_conv_1/expand, False\n",
      "Layer: expanded_conv_1/expand/BatchNorm, False\n",
      "Layer: re_lu_2, False\n",
      "Layer: expanded_conv_1/depthwise/pad, False\n",
      "Layer: expanded_conv_1/depthwise, False\n",
      "Layer: expanded_conv_1/depthwise/BatchNorm, False\n",
      "Layer: re_lu_3, False\n",
      "Layer: expanded_conv_1/project, False\n",
      "Layer: expanded_conv_1/project/BatchNorm, False\n",
      "Layer: expanded_conv_2/expand, False\n",
      "Layer: expanded_conv_2/expand/BatchNorm, False\n",
      "Layer: re_lu_4, False\n",
      "Layer: expanded_conv_2/depthwise, False\n",
      "Layer: expanded_conv_2/depthwise/BatchNorm, False\n",
      "Layer: re_lu_5, False\n",
      "Layer: expanded_conv_2/project, False\n",
      "Layer: expanded_conv_2/project/BatchNorm, False\n",
      "Layer: expanded_conv_2/Add, False\n",
      "Layer: expanded_conv_3/expand, False\n",
      "Layer: expanded_conv_3/expand/BatchNorm, False\n",
      "Layer: re_lu_6, False\n",
      "Layer: expanded_conv_3/depthwise/pad, False\n",
      "Layer: expanded_conv_3/depthwise, False\n",
      "Layer: expanded_conv_3/depthwise/BatchNorm, False\n",
      "Layer: re_lu_7, False\n",
      "Layer: expanded_conv_3/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_3/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_3/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_3/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_1, False\n",
      "Layer: re_lu_8, False\n",
      "Layer: tf.math.multiply_1, False\n",
      "Layer: expanded_conv_3/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_3/project, False\n",
      "Layer: expanded_conv_3/project/BatchNorm, False\n",
      "Layer: expanded_conv_4/expand, False\n",
      "Layer: expanded_conv_4/expand/BatchNorm, False\n",
      "Layer: re_lu_9, False\n",
      "Layer: expanded_conv_4/depthwise, False\n",
      "Layer: expanded_conv_4/depthwise/BatchNorm, False\n",
      "Layer: re_lu_10, False\n",
      "Layer: expanded_conv_4/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_4/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_4/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_4/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_2, False\n",
      "Layer: re_lu_11, False\n",
      "Layer: tf.math.multiply_2, False\n",
      "Layer: expanded_conv_4/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_4/project, False\n",
      "Layer: expanded_conv_4/project/BatchNorm, False\n",
      "Layer: expanded_conv_4/Add, False\n",
      "Layer: expanded_conv_5/expand, False\n",
      "Layer: expanded_conv_5/expand/BatchNorm, False\n",
      "Layer: re_lu_12, False\n",
      "Layer: expanded_conv_5/depthwise, False\n",
      "Layer: expanded_conv_5/depthwise/BatchNorm, False\n",
      "Layer: re_lu_13, False\n",
      "Layer: expanded_conv_5/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_5/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_5/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_5/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_3, False\n",
      "Layer: re_lu_14, False\n",
      "Layer: tf.math.multiply_3, False\n",
      "Layer: expanded_conv_5/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_5/project, False\n",
      "Layer: expanded_conv_5/project/BatchNorm, False\n",
      "Layer: expanded_conv_5/Add, False\n",
      "Layer: expanded_conv_6/expand, False\n",
      "Layer: expanded_conv_6/expand/BatchNorm, False\n",
      "Layer: tf.math.add_4, False\n",
      "Layer: re_lu_15, False\n",
      "Layer: tf.math.multiply_4, False\n",
      "Layer: multiply_1, False\n",
      "Layer: expanded_conv_6/depthwise/pad, False\n",
      "Layer: expanded_conv_6/depthwise, False\n",
      "Layer: expanded_conv_6/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_5, False\n",
      "Layer: re_lu_16, False\n",
      "Layer: tf.math.multiply_5, False\n",
      "Layer: multiply_2, False\n",
      "Layer: expanded_conv_6/project, False\n",
      "Layer: expanded_conv_6/project/BatchNorm, False\n",
      "Layer: expanded_conv_7/expand, False\n",
      "Layer: expanded_conv_7/expand/BatchNorm, False\n",
      "Layer: tf.math.add_6, False\n",
      "Layer: re_lu_17, False\n",
      "Layer: tf.math.multiply_6, False\n",
      "Layer: multiply_3, False\n",
      "Layer: expanded_conv_7/depthwise, False\n",
      "Layer: expanded_conv_7/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_7, False\n",
      "Layer: re_lu_18, False\n",
      "Layer: tf.math.multiply_7, False\n",
      "Layer: multiply_4, False\n",
      "Layer: expanded_conv_7/project, False\n",
      "Layer: expanded_conv_7/project/BatchNorm, False\n",
      "Layer: expanded_conv_7/Add, False\n",
      "Layer: expanded_conv_8/expand, False\n",
      "Layer: expanded_conv_8/expand/BatchNorm, False\n",
      "Layer: tf.math.add_8, False\n",
      "Layer: re_lu_19, False\n",
      "Layer: tf.math.multiply_8, False\n",
      "Layer: multiply_5, False\n",
      "Layer: expanded_conv_8/depthwise, False\n",
      "Layer: expanded_conv_8/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_9, False\n",
      "Layer: re_lu_20, False\n",
      "Layer: tf.math.multiply_9, False\n",
      "Layer: multiply_6, False\n",
      "Layer: expanded_conv_8/project, False\n",
      "Layer: expanded_conv_8/project/BatchNorm, False\n",
      "Layer: expanded_conv_8/Add, False\n",
      "Layer: expanded_conv_9/expand, False\n",
      "Layer: expanded_conv_9/expand/BatchNorm, False\n",
      "Layer: tf.math.add_10, False\n",
      "Layer: re_lu_21, False\n",
      "Layer: tf.math.multiply_10, False\n",
      "Layer: multiply_7, False\n",
      "Layer: expanded_conv_9/depthwise, False\n",
      "Layer: expanded_conv_9/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_11, False\n",
      "Layer: re_lu_22, False\n",
      "Layer: tf.math.multiply_11, False\n",
      "Layer: multiply_8, False\n",
      "Layer: expanded_conv_9/project, False\n",
      "Layer: expanded_conv_9/project/BatchNorm, False\n",
      "Layer: expanded_conv_9/Add, False\n",
      "Layer: expanded_conv_10/expand, False\n",
      "Layer: expanded_conv_10/expand/BatchNorm, False\n",
      "Layer: tf.math.add_12, False\n",
      "Layer: re_lu_23, False\n",
      "Layer: tf.math.multiply_12, False\n",
      "Layer: multiply_9, False\n",
      "Layer: expanded_conv_10/depthwise, False\n",
      "Layer: expanded_conv_10/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_13, False\n",
      "Layer: re_lu_24, False\n",
      "Layer: tf.math.multiply_13, False\n",
      "Layer: multiply_10, False\n",
      "Layer: expanded_conv_10/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_10/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_10/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_10/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_14, False\n",
      "Layer: re_lu_25, False\n",
      "Layer: tf.math.multiply_14, False\n",
      "Layer: expanded_conv_10/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_10/project, False\n",
      "Layer: expanded_conv_10/project/BatchNorm, False\n",
      "Layer: expanded_conv_11/expand, False\n",
      "Layer: expanded_conv_11/expand/BatchNorm, False\n",
      "Layer: tf.math.add_15, False\n",
      "Layer: re_lu_26, False\n",
      "Layer: tf.math.multiply_15, False\n",
      "Layer: multiply_11, False\n",
      "Layer: expanded_conv_11/depthwise, False\n",
      "Layer: expanded_conv_11/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_16, False\n",
      "Layer: re_lu_27, False\n",
      "Layer: tf.math.multiply_16, False\n",
      "Layer: multiply_12, False\n",
      "Layer: expanded_conv_11/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_11/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_11/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_11/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_17, False\n",
      "Layer: re_lu_28, False\n",
      "Layer: tf.math.multiply_17, False\n",
      "Layer: expanded_conv_11/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_11/project, False\n",
      "Layer: expanded_conv_11/project/BatchNorm, False\n",
      "Layer: expanded_conv_11/Add, False\n",
      "Layer: expanded_conv_12/expand, False\n",
      "Layer: expanded_conv_12/expand/BatchNorm, False\n",
      "Layer: tf.math.add_18, False\n",
      "Layer: re_lu_29, False\n",
      "Layer: tf.math.multiply_18, False\n",
      "Layer: multiply_13, False\n",
      "Layer: expanded_conv_12/depthwise/pad, False\n",
      "Layer: expanded_conv_12/depthwise, False\n",
      "Layer: expanded_conv_12/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_19, False\n",
      "Layer: re_lu_30, False\n",
      "Layer: tf.math.multiply_19, False\n",
      "Layer: multiply_14, False\n",
      "Layer: expanded_conv_12/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_12/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_12/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_12/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_20, False\n",
      "Layer: re_lu_31, False\n",
      "Layer: tf.math.multiply_20, False\n",
      "Layer: expanded_conv_12/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_12/project, False\n",
      "Layer: expanded_conv_12/project/BatchNorm, False\n",
      "Layer: expanded_conv_13/expand, False\n",
      "Layer: expanded_conv_13/expand/BatchNorm, False\n",
      "Layer: tf.math.add_21, False\n",
      "Layer: re_lu_32, False\n",
      "Layer: tf.math.multiply_21, False\n",
      "Layer: multiply_15, False\n",
      "Layer: expanded_conv_13/depthwise, False\n",
      "Layer: expanded_conv_13/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_22, False\n",
      "Layer: re_lu_33, False\n",
      "Layer: tf.math.multiply_22, False\n",
      "Layer: multiply_16, False\n",
      "Layer: expanded_conv_13/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_13/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_13/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_13/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_23, False\n",
      "Layer: re_lu_34, False\n",
      "Layer: tf.math.multiply_23, False\n",
      "Layer: expanded_conv_13/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_13/project, False\n",
      "Layer: expanded_conv_13/project/BatchNorm, False\n",
      "Layer: expanded_conv_13/Add, False\n",
      "Layer: expanded_conv_14/expand, False\n",
      "Layer: expanded_conv_14/expand/BatchNorm, False\n",
      "Layer: tf.math.add_24, False\n",
      "Layer: re_lu_35, False\n",
      "Layer: tf.math.multiply_24, False\n",
      "Layer: multiply_17, False\n",
      "Layer: expanded_conv_14/depthwise, False\n",
      "Layer: expanded_conv_14/depthwise/BatchNorm, False\n",
      "Layer: tf.math.add_25, False\n",
      "Layer: re_lu_36, False\n",
      "Layer: tf.math.multiply_25, False\n",
      "Layer: multiply_18, False\n",
      "Layer: expanded_conv_14/squeeze_excite/AvgPool, False\n",
      "Layer: expanded_conv_14/squeeze_excite/Conv, False\n",
      "Layer: expanded_conv_14/squeeze_excite/Relu, False\n",
      "Layer: expanded_conv_14/squeeze_excite/Conv_1, False\n",
      "Layer: tf.math.add_26, False\n",
      "Layer: re_lu_37, False\n",
      "Layer: tf.math.multiply_26, False\n",
      "Layer: expanded_conv_14/squeeze_excite/Mul, False\n",
      "Layer: expanded_conv_14/project, False\n",
      "Layer: expanded_conv_14/project/BatchNorm, False\n",
      "Layer: expanded_conv_14/Add, False\n",
      "Layer: Conv_1, False\n",
      "Layer: Conv_1/BatchNorm, False\n",
      "Layer: tf.math.add_27, False\n",
      "Layer: re_lu_38, False\n",
      "Layer: tf.math.multiply_27, False\n",
      "Layer: multiply_19, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:45.682448Z",
     "start_time": "2024-07-25T22:50:45.679596Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:46.912852Z",
     "start_time": "2024-07-25T22:50:46.909702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:47.931549Z",
     "start_time": "2024-07-25T22:50:47.924652Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:48.888231Z",
     "start_time": "2024-07-25T22:50:48.463171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "x = aug_layer(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'MobilenetV3L_87.7')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3L\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3283780 (12.53 MB)\n",
      "Trainable params: 287428 (1.10 MB)\n",
      "Non-trainable params: 2996352 (11.43 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:51.182004Z",
     "start_time": "2024-07-25T22:50:51.179502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models','MobilenetV3L_87.7'), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:51.989034Z",
     "start_time": "2024-07-25T22:50:51.986783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=2) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:50:59.407746Z",
     "start_time": "2024-07-25T22:50:59.393921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:54:05.363471Z",
     "start_time": "2024-07-25T22:51:00.375137Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 10, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:51:03.075647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-25 18:51:03.149120: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-25 18:51:03.972906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7da0800036e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-25 18:51:03.972944: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-25 18:51:03.979510: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-25 18:51:04.045269: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 1.1401 - accuracy: 0.4833\n",
      "Epoch 1: val_loss improved from inf to 1.27264, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 30s 355ms/step - loss: 1.1401 - accuracy: 0.4833 - val_loss: 1.2726 - val_accuracy: 0.3947 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8293 - accuracy: 0.6485\n",
      "Epoch 2: val_loss improved from 1.27264 to 0.84173, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 24s 322ms/step - loss: 0.8293 - accuracy: 0.6485 - val_loss: 0.8417 - val_accuracy: 0.7052 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.7319\n",
      "Epoch 3: val_loss did not improve from 0.84173\n",
      "74/74 [==============================] - 15s 198ms/step - loss: 0.6703 - accuracy: 0.7319 - val_loss: 1.2022 - val_accuracy: 0.4332 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.7590\n",
      "Epoch 4: val_loss did not improve from 0.84173\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 0.6276 - accuracy: 0.7590 - val_loss: 0.9165 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.7997\n",
      "Epoch 5: val_loss improved from 0.84173 to 0.77363, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 22s 294ms/step - loss: 0.5357 - accuracy: 0.7997 - val_loss: 0.7736 - val_accuracy: 0.7003 - lr: 3.0000e-04\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8187\n",
      "Epoch 6: val_loss did not improve from 0.77363\n",
      "74/74 [==============================] - 15s 191ms/step - loss: 0.5104 - accuracy: 0.8187 - val_loss: 1.0661 - val_accuracy: 0.5084 - lr: 3.0000e-04\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5063 - accuracy: 0.8098\n",
      "Epoch 7: val_loss improved from 0.77363 to 0.74714, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 20s 272ms/step - loss: 0.5063 - accuracy: 0.8098 - val_loss: 0.7471 - val_accuracy: 0.7052 - lr: 3.0000e-04\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8306\n",
      "Epoch 8: val_loss did not improve from 0.74714\n",
      "74/74 [==============================] - 12s 162ms/step - loss: 0.4635 - accuracy: 0.8306 - val_loss: 0.8675 - val_accuracy: 0.6222 - lr: 3.0000e-04\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8399\n",
      "Epoch 9: val_loss improved from 0.74714 to 0.66410, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 19s 260ms/step - loss: 0.4492 - accuracy: 0.8399 - val_loss: 0.6641 - val_accuracy: 0.7359 - lr: 3.0000e-04\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8365\n",
      "Epoch 10: val_loss did not improve from 0.66410\n",
      "74/74 [==============================] - 13s 177ms/step - loss: 0.4520 - accuracy: 0.8365 - val_loss: 0.7124 - val_accuracy: 0.7062 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:54:26.720225Z",
     "start_time": "2024-07-25T22:54:26.713630Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:54:27.093730Z",
     "start_time": "2024-07-25T22:54:27.089043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:54:27.736308Z",
     "start_time": "2024-07-25T22:54:27.732342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:54:49.607134Z",
     "start_time": "2024-07-25T22:54:49.563833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 10\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3L\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3283780 (12.53 MB)\n",
      "Trainable params: 1882148 (7.18 MB)\n",
      "Non-trainable params: 1401632 (5.35 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:58:03.839179Z",
     "start_time": "2024-07-25T22:55:13.426780Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+15, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8115\n",
      "Epoch 11: val_loss did not improve from 0.66410\n",
      "74/74 [==============================] - 17s 163ms/step - loss: 0.5216 - accuracy: 0.8115 - val_loss: 0.7823 - val_accuracy: 0.6706 - lr: 3.0000e-04\n",
      "Epoch 12/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8348\n",
      "Epoch 12: val_loss did not improve from 0.66410\n",
      "74/74 [==============================] - 11s 150ms/step - loss: 0.4415 - accuracy: 0.8348 - val_loss: 0.8056 - val_accuracy: 0.6736 - lr: 3.0000e-04\n",
      "Epoch 13/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4236 - accuracy: 0.8399\n",
      "Epoch 13: val_loss did not improve from 0.66410\n",
      "74/74 [==============================] - 13s 163ms/step - loss: 0.4236 - accuracy: 0.8399 - val_loss: 1.0192 - val_accuracy: 0.4807 - lr: 3.0000e-04\n",
      "Epoch 14/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8767\n",
      "Epoch 14: val_loss improved from 0.66410 to 0.41639, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 18s 246ms/step - loss: 0.3411 - accuracy: 0.8767 - val_loss: 0.4164 - val_accuracy: 0.8803 - lr: 9.0000e-05\n",
      "Epoch 15/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.9005\n",
      "Epoch 15: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 136ms/step - loss: 0.3085 - accuracy: 0.9005 - val_loss: 0.7664 - val_accuracy: 0.6775 - lr: 9.0000e-05\n",
      "Epoch 16/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.8886\n",
      "Epoch 16: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 127ms/step - loss: 0.3023 - accuracy: 0.8886 - val_loss: 0.5381 - val_accuracy: 0.8061 - lr: 9.0000e-05\n",
      "Epoch 17/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.9009\n",
      "Epoch 17: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 124ms/step - loss: 0.2839 - accuracy: 0.9009 - val_loss: 0.5524 - val_accuracy: 0.7844 - lr: 2.7000e-05\n",
      "Epoch 18/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.8967\n",
      "Epoch 18: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 126ms/step - loss: 0.2828 - accuracy: 0.8967 - val_loss: 0.7270 - val_accuracy: 0.6825 - lr: 2.7000e-05\n",
      "Epoch 19/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.8996\n",
      "Epoch 19: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 130ms/step - loss: 0.2753 - accuracy: 0.8996 - val_loss: 0.6174 - val_accuracy: 0.7349 - lr: 8.1000e-06\n",
      "Epoch 20/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9034\n",
      "Epoch 20: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 125ms/step - loss: 0.2708 - accuracy: 0.9034 - val_loss: 0.6482 - val_accuracy: 0.7250 - lr: 8.1000e-06\n",
      "Epoch 21/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.9089\n",
      "Epoch 21: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 12s 160ms/step - loss: 0.2680 - accuracy: 0.9089 - val_loss: 0.6531 - val_accuracy: 0.7230 - lr: 2.4300e-06\n",
      "Epoch 22/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.9064\n",
      "Epoch 22: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 0.2631 - accuracy: 0.9064 - val_loss: 0.6325 - val_accuracy: 0.7310 - lr: 2.4300e-06\n",
      "Epoch 23/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.9089\n",
      "Epoch 23: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 9s 106ms/step - loss: 0.2559 - accuracy: 0.9089 - val_loss: 0.6235 - val_accuracy: 0.7319 - lr: 7.2900e-07\n",
      "Epoch 24/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.9072\n",
      "Epoch 24: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 9s 123ms/step - loss: 0.2618 - accuracy: 0.9072 - val_loss: 0.6186 - val_accuracy: 0.7329 - lr: 7.2900e-07\n",
      "Epoch 25/25\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.9081\n",
      "Epoch 25: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 0.2639 - accuracy: 0.9081 - val_loss: 0.6141 - val_accuracy: 0.7349 - lr: 2.1870e-07\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:58:05.887916Z",
     "start_time": "2024-07-25T22:58:05.883743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 25\n",
    "for layer in base_model.layers[-125:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:58:06.478511Z",
     "start_time": "2024-07-25T22:58:06.453209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3L\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3283780 (12.53 MB)\n",
      "Trainable params: 3082316 (11.76 MB)\n",
      "Non-trainable params: 201464 (786.97 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:01:17.117087Z",
     "start_time": "2024-07-25T22:58:15.021286Z"
    }
   },
   "cell_type": "code",
   "source": "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+15, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9068\n",
      "Epoch 26: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 23s 186ms/step - loss: 0.2685 - accuracy: 0.9068 - val_loss: 0.7870 - val_accuracy: 0.6726 - lr: 3.0000e-05\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9123\n",
      "Epoch 27: val_loss did not improve from 0.41639\n",
      "74/74 [==============================] - 10s 127ms/step - loss: 0.2541 - accuracy: 0.9123 - val_loss: 0.4772 - val_accuracy: 0.8358 - lr: 3.0000e-05\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9047\n",
      "Epoch 28: val_loss improved from 0.41639 to 0.32292, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 17s 232ms/step - loss: 0.2478 - accuracy: 0.9047 - val_loss: 0.3229 - val_accuracy: 0.9050 - lr: 3.0000e-05\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.9081\n",
      "Epoch 29: val_loss improved from 0.32292 to 0.26771, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 18s 236ms/step - loss: 0.2519 - accuracy: 0.9081 - val_loss: 0.2677 - val_accuracy: 0.9268 - lr: 3.0000e-05\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9208\n",
      "Epoch 30: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 9s 116ms/step - loss: 0.2286 - accuracy: 0.9208 - val_loss: 0.5871 - val_accuracy: 0.7715 - lr: 3.0000e-05\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9183\n",
      "Epoch 31: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 8s 109ms/step - loss: 0.2332 - accuracy: 0.9183 - val_loss: 0.2701 - val_accuracy: 0.9179 - lr: 3.0000e-05\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9263\n",
      "Epoch 32: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 9s 122ms/step - loss: 0.2271 - accuracy: 0.9263 - val_loss: 0.4340 - val_accuracy: 0.8417 - lr: 9.0000e-06\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9271\n",
      "Epoch 33: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 0.2172 - accuracy: 0.9271 - val_loss: 0.3483 - val_accuracy: 0.8833 - lr: 9.0000e-06\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2074 - accuracy: 0.9331\n",
      "Epoch 34: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 0.2074 - accuracy: 0.9331 - val_loss: 0.3969 - val_accuracy: 0.8615 - lr: 2.7000e-06\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9305\n",
      "Epoch 35: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 9s 116ms/step - loss: 0.2082 - accuracy: 0.9305 - val_loss: 0.4309 - val_accuracy: 0.8437 - lr: 2.7000e-06\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9310\n",
      "Epoch 36: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 12s 152ms/step - loss: 0.1844 - accuracy: 0.9310 - val_loss: 0.4367 - val_accuracy: 0.8427 - lr: 8.1000e-07\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.9322\n",
      "Epoch 37: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 0.1840 - accuracy: 0.9322 - val_loss: 0.4508 - val_accuracy: 0.8289 - lr: 8.1000e-07\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9331\n",
      "Epoch 38: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 12s 165ms/step - loss: 0.1829 - accuracy: 0.9331 - val_loss: 0.4642 - val_accuracy: 0.8259 - lr: 2.4300e-07\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9271\n",
      "Epoch 39: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 0.2098 - accuracy: 0.9271 - val_loss: 0.4617 - val_accuracy: 0.8269 - lr: 2.4300e-07\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9310\n",
      "Epoch 40: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 13s 165ms/step - loss: 0.2042 - accuracy: 0.9310 - val_loss: 0.4577 - val_accuracy: 0.8289 - lr: 7.2900e-08\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:01:28.324577Z",
     "start_time": "2024-07-25T23:01:28.317459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 40\n",
    "for layer in base_model.layers[-250:]:\n",
    "    layer.trainable = True"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:01:34.959676Z",
     "start_time": "2024-07-25T23:01:34.922577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00009), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MobilenetV3L\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               246016    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3283780 (12.53 MB)\n",
      "Trainable params: 3258452 (12.43 MB)\n",
      "Non-trainable params: 25328 (98.94 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:10:41.276172Z",
     "start_time": "2024-07-25T23:01:42.343228Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+50, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.8937\n",
      "Epoch 41: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 42s 421ms/step - loss: 0.3224 - accuracy: 0.8937 - val_loss: 0.4803 - val_accuracy: 0.8694 - lr: 9.0000e-05\n",
      "Epoch 42/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.9119\n",
      "Epoch 42: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 23s 306ms/step - loss: 0.2550 - accuracy: 0.9119 - val_loss: 0.7618 - val_accuracy: 0.7201 - lr: 9.0000e-05\n",
      "Epoch 43/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9111\n",
      "Epoch 43: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 20s 272ms/step - loss: 0.2707 - accuracy: 0.9111 - val_loss: 0.3554 - val_accuracy: 0.8912 - lr: 9.0000e-05\n",
      "Epoch 44/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9123\n",
      "Epoch 44: val_loss did not improve from 0.26771\n",
      "74/74 [==============================] - 19s 252ms/step - loss: 0.2477 - accuracy: 0.9123 - val_loss: 0.3106 - val_accuracy: 0.9021 - lr: 9.0000e-05\n",
      "Epoch 45/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9271\n",
      "Epoch 45: val_loss improved from 0.26771 to 0.23266, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 29s 384ms/step - loss: 0.2178 - accuracy: 0.9271 - val_loss: 0.2327 - val_accuracy: 0.9436 - lr: 9.0000e-05\n",
      "Epoch 46/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9288\n",
      "Epoch 46: val_loss did not improve from 0.23266\n",
      "74/74 [==============================] - 19s 253ms/step - loss: 0.2072 - accuracy: 0.9288 - val_loss: 0.3261 - val_accuracy: 0.8882 - lr: 9.0000e-05\n",
      "Epoch 47/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9293\n",
      "Epoch 47: val_loss improved from 0.23266 to 0.16496, saving model to Trained_Models/MobilenetV3L\n",
      "74/74 [==============================] - 30s 408ms/step - loss: 0.1918 - accuracy: 0.9293 - val_loss: 0.1650 - val_accuracy: 0.9525 - lr: 9.0000e-05\n",
      "Epoch 48/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9225\n",
      "Epoch 48: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 16s 217ms/step - loss: 0.2244 - accuracy: 0.9225 - val_loss: 0.3277 - val_accuracy: 0.8991 - lr: 9.0000e-05\n",
      "Epoch 49/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9352\n",
      "Epoch 49: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 16s 216ms/step - loss: 0.1980 - accuracy: 0.9352 - val_loss: 0.1753 - val_accuracy: 0.9565 - lr: 9.0000e-05\n",
      "Epoch 50/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9598\n",
      "Epoch 50: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 14s 181ms/step - loss: 0.1327 - accuracy: 0.9598 - val_loss: 0.2079 - val_accuracy: 0.9436 - lr: 2.7000e-05\n",
      "Epoch 51/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9602\n",
      "Epoch 51: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 0.1221 - accuracy: 0.9602 - val_loss: 0.1805 - val_accuracy: 0.9545 - lr: 2.7000e-05\n",
      "Epoch 52/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9598\n",
      "Epoch 52: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 16s 208ms/step - loss: 0.1074 - accuracy: 0.9598 - val_loss: 0.1698 - val_accuracy: 0.9585 - lr: 8.1000e-06\n",
      "Epoch 53/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9657\n",
      "Epoch 53: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 14s 178ms/step - loss: 0.1055 - accuracy: 0.9657 - val_loss: 0.2402 - val_accuracy: 0.9377 - lr: 8.1000e-06\n",
      "Epoch 54/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9644\n",
      "Epoch 54: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 13s 166ms/step - loss: 0.1018 - accuracy: 0.9644 - val_loss: 0.2133 - val_accuracy: 0.9446 - lr: 2.4300e-06\n",
      "Epoch 55/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9699\n",
      "Epoch 55: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 0.0888 - accuracy: 0.9699 - val_loss: 0.1992 - val_accuracy: 0.9446 - lr: 2.4300e-06\n",
      "Epoch 56/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9661\n",
      "Epoch 56: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 12s 165ms/step - loss: 0.0976 - accuracy: 0.9661 - val_loss: 0.1977 - val_accuracy: 0.9456 - lr: 7.2900e-07\n",
      "Epoch 57/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9746\n",
      "Epoch 57: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 0.0989 - accuracy: 0.9746 - val_loss: 0.1914 - val_accuracy: 0.9476 - lr: 7.2900e-07\n",
      "Epoch 58/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9712\n",
      "Epoch 58: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 0.0937 - accuracy: 0.9712 - val_loss: 0.1921 - val_accuracy: 0.9476 - lr: 2.1870e-07\n",
      "Epoch 59/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9619\n",
      "Epoch 59: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 12s 162ms/step - loss: 0.0995 - accuracy: 0.9619 - val_loss: 0.1927 - val_accuracy: 0.9476 - lr: 2.1870e-07\n",
      "Epoch 60/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9661\n",
      "Epoch 60: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 13s 164ms/step - loss: 0.0966 - accuracy: 0.9661 - val_loss: 0.1923 - val_accuracy: 0.9476 - lr: 6.5610e-08\n",
      "Epoch 61/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9674\n",
      "Epoch 61: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 11s 139ms/step - loss: 0.0952 - accuracy: 0.9674 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 6.5610e-08\n",
      "Epoch 62/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9627\n",
      "Epoch 62: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 12s 154ms/step - loss: 0.1029 - accuracy: 0.9627 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.9683e-08\n",
      "Epoch 63/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9670\n",
      "Epoch 63: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 12s 152ms/step - loss: 0.0971 - accuracy: 0.9670 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.9683e-08\n",
      "Epoch 64/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9665\n",
      "Epoch 64: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 10s 133ms/step - loss: 0.1010 - accuracy: 0.9665 - val_loss: 0.1911 - val_accuracy: 0.9486 - lr: 5.9049e-09\n",
      "Epoch 65/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9653\n",
      "Epoch 65: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 12s 155ms/step - loss: 0.0919 - accuracy: 0.9653 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 5.9049e-09\n",
      "Epoch 66/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9648\n",
      "Epoch 66: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 9s 122ms/step - loss: 0.0935 - accuracy: 0.9648 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.7715e-09\n",
      "Epoch 67/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9682\n",
      "Epoch 67: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 12s 158ms/step - loss: 0.0979 - accuracy: 0.9682 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.7715e-09\n",
      "Epoch 68/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9704\n",
      "Epoch 68: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 10s 131ms/step - loss: 0.0847 - accuracy: 0.9704 - val_loss: 0.1911 - val_accuracy: 0.9486 - lr: 5.3144e-10\n",
      "Epoch 69/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9687\n",
      "Epoch 69: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 11s 141ms/step - loss: 0.0940 - accuracy: 0.9687 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 5.3144e-10\n",
      "Epoch 70/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9691\n",
      "Epoch 70: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 10s 131ms/step - loss: 0.1048 - accuracy: 0.9691 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.5943e-10\n",
      "Epoch 71/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9644\n",
      "Epoch 71: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 10s 136ms/step - loss: 0.0951 - accuracy: 0.9644 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.5943e-10\n",
      "Epoch 72/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9682\n",
      "Epoch 72: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 0.0935 - accuracy: 0.9682 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 4.7830e-11\n",
      "Epoch 73/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9648\n",
      "Epoch 73: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 13s 168ms/step - loss: 0.1084 - accuracy: 0.9648 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 4.7830e-11\n",
      "Epoch 74/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9708\n",
      "Epoch 74: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 0.0861 - accuracy: 0.9708 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.4349e-11\n",
      "Epoch 75/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9623\n",
      "Epoch 75: val_loss did not improve from 0.16496\n",
      "74/74 [==============================] - 10s 128ms/step - loss: 0.0982 - accuracy: 0.9623 - val_loss: 0.1910 - val_accuracy: 0.9486 - lr: 1.4349e-11\n",
      "Epoch 76/90\n",
      "18/74 [======>.......................] - ETA: 6s - loss: 0.0903 - accuracy: 0.9722"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history_200 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_1chkpt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mval_datagen\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:10:50.950474Z",
     "start_time": "2024-07-25T23:10:46.646295Z"
    }
   },
   "cell_type": "code",
   "source": "MobileNet_Best = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/MobilenetV3L_87.7\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:11:00.876834Z",
     "start_time": "2024-07-25T23:10:59.671946Z"
    }
   },
   "cell_type": "code",
   "source": "MobileNet_Best.evaluate(test_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 25ms/step - loss: 0.3689 - accuracy: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36894628405570984, 0.8769230842590332]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
