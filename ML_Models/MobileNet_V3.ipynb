{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:33.808406Z",
     "start_time": "2024-07-27T03:40:31.951814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 23:40:32.098551: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-26 23:40:32.125564: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 23:40:32.125614: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 23:40:32.125645: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 23:40:32.133015: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 23:40:32.749863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 23:40:33.775189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 23:40:33.799224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 23:40:33.801078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-26 23:40:33.803099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:33.814459Z",
     "start_time": "2024-07-27T03:40:33.809938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:53.435777Z",
     "start_time": "2024-07-27T03:40:53.433112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "#IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:53.620880Z",
     "start_time": "2024-07-27T03:40:53.617826Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:53.787868Z",
     "start_time": "2024-07-27T03:40:53.785436Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:54.111684Z",
     "start_time": "2024-07-27T03:40:53.942662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n",
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:54.115724Z",
     "start_time": "2024-07-27T03:40:54.113237Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:54.298824Z",
     "start_time": "2024-07-27T03:40:54.296756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:55.165838Z",
     "start_time": "2024-07-27T03:40:55.147247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:56.439294Z",
     "start_time": "2024-07-27T03:40:56.436180Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:58.627641Z",
     "start_time": "2024-07-27T03:40:57.787202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "base_model = apps.MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:58.632542Z",
     "start_time": "2024-07-27T03:40:58.629177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: Conv1, False\n",
      "Layer: bn_Conv1, False\n",
      "Layer: Conv1_relu, False\n",
      "Layer: expanded_conv_depthwise, False\n",
      "Layer: expanded_conv_depthwise_BN, False\n",
      "Layer: expanded_conv_depthwise_relu, False\n",
      "Layer: expanded_conv_project, False\n",
      "Layer: expanded_conv_project_BN, False\n",
      "Layer: block_1_expand, False\n",
      "Layer: block_1_expand_BN, False\n",
      "Layer: block_1_expand_relu, False\n",
      "Layer: block_1_pad, False\n",
      "Layer: block_1_depthwise, False\n",
      "Layer: block_1_depthwise_BN, False\n",
      "Layer: block_1_depthwise_relu, False\n",
      "Layer: block_1_project, False\n",
      "Layer: block_1_project_BN, False\n",
      "Layer: block_2_expand, False\n",
      "Layer: block_2_expand_BN, False\n",
      "Layer: block_2_expand_relu, False\n",
      "Layer: block_2_depthwise, False\n",
      "Layer: block_2_depthwise_BN, False\n",
      "Layer: block_2_depthwise_relu, False\n",
      "Layer: block_2_project, False\n",
      "Layer: block_2_project_BN, False\n",
      "Layer: block_2_add, False\n",
      "Layer: block_3_expand, False\n",
      "Layer: block_3_expand_BN, False\n",
      "Layer: block_3_expand_relu, False\n",
      "Layer: block_3_pad, False\n",
      "Layer: block_3_depthwise, False\n",
      "Layer: block_3_depthwise_BN, False\n",
      "Layer: block_3_depthwise_relu, False\n",
      "Layer: block_3_project, False\n",
      "Layer: block_3_project_BN, False\n",
      "Layer: block_4_expand, False\n",
      "Layer: block_4_expand_BN, False\n",
      "Layer: block_4_expand_relu, False\n",
      "Layer: block_4_depthwise, False\n",
      "Layer: block_4_depthwise_BN, False\n",
      "Layer: block_4_depthwise_relu, False\n",
      "Layer: block_4_project, False\n",
      "Layer: block_4_project_BN, False\n",
      "Layer: block_4_add, False\n",
      "Layer: block_5_expand, False\n",
      "Layer: block_5_expand_BN, False\n",
      "Layer: block_5_expand_relu, False\n",
      "Layer: block_5_depthwise, False\n",
      "Layer: block_5_depthwise_BN, False\n",
      "Layer: block_5_depthwise_relu, False\n",
      "Layer: block_5_project, False\n",
      "Layer: block_5_project_BN, False\n",
      "Layer: block_5_add, False\n",
      "Layer: block_6_expand, False\n",
      "Layer: block_6_expand_BN, False\n",
      "Layer: block_6_expand_relu, False\n",
      "Layer: block_6_pad, False\n",
      "Layer: block_6_depthwise, False\n",
      "Layer: block_6_depthwise_BN, False\n",
      "Layer: block_6_depthwise_relu, False\n",
      "Layer: block_6_project, False\n",
      "Layer: block_6_project_BN, False\n",
      "Layer: block_7_expand, False\n",
      "Layer: block_7_expand_BN, False\n",
      "Layer: block_7_expand_relu, False\n",
      "Layer: block_7_depthwise, False\n",
      "Layer: block_7_depthwise_BN, False\n",
      "Layer: block_7_depthwise_relu, False\n",
      "Layer: block_7_project, False\n",
      "Layer: block_7_project_BN, False\n",
      "Layer: block_7_add, False\n",
      "Layer: block_8_expand, False\n",
      "Layer: block_8_expand_BN, False\n",
      "Layer: block_8_expand_relu, False\n",
      "Layer: block_8_depthwise, False\n",
      "Layer: block_8_depthwise_BN, False\n",
      "Layer: block_8_depthwise_relu, False\n",
      "Layer: block_8_project, False\n",
      "Layer: block_8_project_BN, False\n",
      "Layer: block_8_add, False\n",
      "Layer: block_9_expand, False\n",
      "Layer: block_9_expand_BN, False\n",
      "Layer: block_9_expand_relu, False\n",
      "Layer: block_9_depthwise, False\n",
      "Layer: block_9_depthwise_BN, False\n",
      "Layer: block_9_depthwise_relu, False\n",
      "Layer: block_9_project, False\n",
      "Layer: block_9_project_BN, False\n",
      "Layer: block_9_add, False\n",
      "Layer: block_10_expand, False\n",
      "Layer: block_10_expand_BN, False\n",
      "Layer: block_10_expand_relu, False\n",
      "Layer: block_10_depthwise, False\n",
      "Layer: block_10_depthwise_BN, False\n",
      "Layer: block_10_depthwise_relu, False\n",
      "Layer: block_10_project, False\n",
      "Layer: block_10_project_BN, False\n",
      "Layer: block_11_expand, False\n",
      "Layer: block_11_expand_BN, False\n",
      "Layer: block_11_expand_relu, False\n",
      "Layer: block_11_depthwise, False\n",
      "Layer: block_11_depthwise_BN, False\n",
      "Layer: block_11_depthwise_relu, False\n",
      "Layer: block_11_project, False\n",
      "Layer: block_11_project_BN, False\n",
      "Layer: block_11_add, False\n",
      "Layer: block_12_expand, False\n",
      "Layer: block_12_expand_BN, False\n",
      "Layer: block_12_expand_relu, False\n",
      "Layer: block_12_depthwise, False\n",
      "Layer: block_12_depthwise_BN, False\n",
      "Layer: block_12_depthwise_relu, False\n",
      "Layer: block_12_project, False\n",
      "Layer: block_12_project_BN, False\n",
      "Layer: block_12_add, False\n",
      "Layer: block_13_expand, False\n",
      "Layer: block_13_expand_BN, False\n",
      "Layer: block_13_expand_relu, False\n",
      "Layer: block_13_pad, False\n",
      "Layer: block_13_depthwise, False\n",
      "Layer: block_13_depthwise_BN, False\n",
      "Layer: block_13_depthwise_relu, False\n",
      "Layer: block_13_project, False\n",
      "Layer: block_13_project_BN, False\n",
      "Layer: block_14_expand, False\n",
      "Layer: block_14_expand_BN, False\n",
      "Layer: block_14_expand_relu, False\n",
      "Layer: block_14_depthwise, False\n",
      "Layer: block_14_depthwise_BN, False\n",
      "Layer: block_14_depthwise_relu, False\n",
      "Layer: block_14_project, False\n",
      "Layer: block_14_project_BN, False\n",
      "Layer: block_14_add, False\n",
      "Layer: block_15_expand, False\n",
      "Layer: block_15_expand_BN, False\n",
      "Layer: block_15_expand_relu, False\n",
      "Layer: block_15_depthwise, False\n",
      "Layer: block_15_depthwise_BN, False\n",
      "Layer: block_15_depthwise_relu, False\n",
      "Layer: block_15_project, False\n",
      "Layer: block_15_project_BN, False\n",
      "Layer: block_15_add, False\n",
      "Layer: block_16_expand, False\n",
      "Layer: block_16_expand_BN, False\n",
      "Layer: block_16_expand_relu, False\n",
      "Layer: block_16_depthwise, False\n",
      "Layer: block_16_depthwise_BN, False\n",
      "Layer: block_16_depthwise_relu, False\n",
      "Layer: block_16_project, False\n",
      "Layer: block_16_project_BN, False\n",
      "Layer: Conv_1, False\n",
      "Layer: Conv_1_bn, False\n",
      "Layer: out_relu, False\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:40:59.605231Z",
     "start_time": "2024-07-27T03:40:59.601993Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:41:00.904322Z",
     "start_time": "2024-07-27T03:41:00.900951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:41:11.865174Z",
     "start_time": "2024-07-27T03:41:11.859191Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net(random_width=0.3, random_height=0.3, random_zoom=0.3, random_rotation=0.3)",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:41:20.848798Z",
     "start_time": "2024-07-27T03:41:20.549254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name='Input_layer')\n",
    "x = aug_layer(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = GlobalAvgPool2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "outputs = Dense(No_of_classes, activation='softmax', dtype=tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, outputs, name='Mobilenetv3lnew')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Mobilenetv3lnew\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 1280)              5120      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               655872    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3095556 (11.81 MB)\n",
      "Trainable params: 833092 (3.18 MB)\n",
      "Non-trainable params: 2262464 (8.63 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:41:29.885998Z",
     "start_time": "2024-07-27T03:41:29.883733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models',model_1.name), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:41:30.199465Z",
     "start_time": "2024-07-27T03:41:30.197344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=2) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:41:31.850553Z",
     "start_time": "2024-07-27T03:41:31.837349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:48:44.016787Z",
     "start_time": "2024-07-27T03:41:37.663165Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 20, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 23:41:40.853393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-26 23:41:40.935542: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-26 23:41:42.028228: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563cf216b4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-26 23:41:42.028243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-26 23:41:42.038326: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-26 23:41:42.119472: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 12.6077 - accuracy: 0.5693\n",
      "Epoch 1: val_loss improved from inf to 10.28566, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 36s 431ms/step - loss: 12.6077 - accuracy: 0.5693 - val_loss: 10.2857 - val_accuracy: 0.8497 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2778 - accuracy: 0.6874\n",
      "Epoch 2: val_loss improved from 10.28566 to 6.54520, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 29s 385ms/step - loss: 8.2778 - accuracy: 0.6874 - val_loss: 6.5452 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.2534 - accuracy: 0.7366\n",
      "Epoch 3: val_loss improved from 6.54520 to 4.39690, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 27s 366ms/step - loss: 5.2534 - accuracy: 0.7366 - val_loss: 4.3969 - val_accuracy: 0.7122 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 3.4775 - accuracy: 0.7446\n",
      "Epoch 4: val_loss improved from 4.39690 to 2.76580, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 26s 349ms/step - loss: 3.4775 - accuracy: 0.7446 - val_loss: 2.7658 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.5079 - accuracy: 0.7332\n",
      "Epoch 5: val_loss improved from 2.76580 to 2.14385, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 27s 362ms/step - loss: 2.5079 - accuracy: 0.7332 - val_loss: 2.1438 - val_accuracy: 0.8497 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.8509 - accuracy: 0.7573\n",
      "Epoch 6: val_loss improved from 2.14385 to 1.80503, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 26s 355ms/step - loss: 1.8509 - accuracy: 0.7573 - val_loss: 1.8050 - val_accuracy: 0.6686 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.5714 - accuracy: 0.7306\n",
      "Epoch 7: val_loss improved from 1.80503 to 1.42776, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 23s 312ms/step - loss: 1.5714 - accuracy: 0.7306 - val_loss: 1.4278 - val_accuracy: 0.7498 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.3712 - accuracy: 0.7412\n",
      "Epoch 8: val_loss improved from 1.42776 to 1.42767, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 25s 339ms/step - loss: 1.3712 - accuracy: 0.7412 - val_loss: 1.4277 - val_accuracy: 0.5915 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2521 - accuracy: 0.7361\n",
      "Epoch 9: val_loss improved from 1.42767 to 1.02628, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 25s 328ms/step - loss: 1.2521 - accuracy: 0.7361 - val_loss: 1.0263 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1488 - accuracy: 0.7454\n",
      "Epoch 10: val_loss did not improve from 1.02628\n",
      "74/74 [==============================] - 16s 209ms/step - loss: 1.1488 - accuracy: 0.7454 - val_loss: 1.2112 - val_accuracy: 0.7112 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0931 - accuracy: 0.7391\n",
      "Epoch 11: val_loss did not improve from 1.02628\n",
      "74/74 [==============================] - 18s 234ms/step - loss: 1.0931 - accuracy: 0.7391 - val_loss: 1.2773 - val_accuracy: 0.5529 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9869 - accuracy: 0.7819\n",
      "Epoch 12: val_loss did not improve from 1.02628\n",
      "74/74 [==============================] - 19s 255ms/step - loss: 0.9869 - accuracy: 0.7819 - val_loss: 1.4449 - val_accuracy: 0.3729 - lr: 3.0000e-04\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9243 - accuracy: 0.7759\n",
      "Epoch 13: val_loss improved from 1.02628 to 0.77880, saving model to Trained_Models/Mobilenetv3lnew\n",
      "74/74 [==============================] - 28s 371ms/step - loss: 0.9243 - accuracy: 0.7759 - val_loss: 0.7788 - val_accuracy: 0.9139 - lr: 3.0000e-04\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8648 - accuracy: 0.7802\n",
      "Epoch 14: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 0.8648 - accuracy: 0.7802 - val_loss: 0.9044 - val_accuracy: 0.7685 - lr: 3.0000e-04\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8515 - accuracy: 0.7683\n",
      "Epoch 15: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 0.8515 - accuracy: 0.7683 - val_loss: 1.0878 - val_accuracy: 0.6004 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7995 - accuracy: 0.7903\n",
      "Epoch 16: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 14s 181ms/step - loss: 0.7995 - accuracy: 0.7903 - val_loss: 1.0194 - val_accuracy: 0.6637 - lr: 9.0000e-05\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.8081\n",
      "Epoch 17: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 14s 179ms/step - loss: 0.7486 - accuracy: 0.8081 - val_loss: 0.9364 - val_accuracy: 0.7033 - lr: 9.0000e-05\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7253 - accuracy: 0.8115\n",
      "Epoch 18: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 0.7253 - accuracy: 0.8115 - val_loss: 1.0025 - val_accuracy: 0.6508 - lr: 2.7000e-05\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7067 - accuracy: 0.8170\n",
      "Epoch 19: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 0.7067 - accuracy: 0.8170 - val_loss: 0.9392 - val_accuracy: 0.7033 - lr: 2.7000e-05\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7043 - accuracy: 0.8208\n",
      "Epoch 20: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 0.7043 - accuracy: 0.8208 - val_loss: 0.9422 - val_accuracy: 0.6944 - lr: 8.1000e-06\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:51:40.164965Z",
     "start_time": "2024-07-27T03:51:39.409789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.evaluate(test_datagen)\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False"
   ],
   "id": "8410178448b1c2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 25ms/step - loss: 30.8310 - accuracy: 0.2462\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:51:41.055009Z",
     "start_time": "2024-07-27T03:51:41.051576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a3cb437871bdd239",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T03:51:41.534807Z",
     "start_time": "2024-07-27T03:51:41.508658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 20\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "efdaa00ce19e11f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Mobilenetv3lnew\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 1280)              5120      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               655872    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3095556 (11.81 MB)\n",
      "Trainable params: 1553092 (5.92 MB)\n",
      "Non-trainable params: 1542464 (5.88 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-27T03:51:42.200935Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10,initial_epoch=start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "bbd1e3d1fb5f2deb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8288 - accuracy: 0.7048\n",
      "Epoch 21: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 16s 173ms/step - loss: 0.8288 - accuracy: 0.7048 - val_loss: 132.9536 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7970 - accuracy: 0.7048\n",
      "Epoch 22: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 12s 160ms/step - loss: 0.7970 - accuracy: 0.7048 - val_loss: 103.5913 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8362 - accuracy: 0.6997\n",
      "Epoch 23: val_loss did not improve from 0.77880\n",
      "74/74 [==============================] - 12s 157ms/step - loss: 0.8362 - accuracy: 0.6997 - val_loss: 184.3490 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "Epoch 24/30\n",
      "17/74 [=====>........................] - ETA: 8s - loss: 0.9017 - accuracy: 0.6581"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T01:07:09.012630Z",
     "start_time": "2024-07-26T01:07:06.314689Z"
    }
   },
   "cell_type": "code",
   "source": "MobileNet_Best = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Mobilenetv2\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T01:07:12.350707Z",
     "start_time": "2024-07-26T01:07:09.013720Z"
    }
   },
   "cell_type": "code",
   "source": "MobileNet_Best.evaluate(test_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 104ms/step - loss: 0.2928 - accuracy: 0.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2927977740764618, 0.8828402161598206]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
