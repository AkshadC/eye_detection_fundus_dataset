{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:46.191014Z",
     "start_time": "2024-07-25T22:47:44.349055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:47:44.505355: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 18:47:44.529899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 18:47:44.529924: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 18:47:44.529949: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 18:47:44.535256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 18:47:45.113085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:47:46.156920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.180591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.183472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.186350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:46.195805Z",
     "start_time": "2024-07-25T22:47:46.191855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:46.199957Z",
     "start_time": "2024-07-25T22:47:46.196435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:46.203483Z",
     "start_time": "2024-07-25T22:47:46.201353Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:46.369005Z",
     "start_time": "2024-07-25T22:47:46.366503Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:47.535522Z",
     "start_time": "2024-07-25T22:47:46.590168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:47:46.659001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.661678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.664430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.800708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.802582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.804299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-25 18:47:46.805987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5965 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-25 18:47:46.955773: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:47.658232Z",
     "start_time": "2024-07-25T22:47:47.654735Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:48.260933Z",
     "start_time": "2024-07-25T22:47:48.258480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:47:48.680731Z",
     "start_time": "2024-07-25T22:47:48.648236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:40:19.274568Z",
     "start_time": "2024-07-25T22:40:19.272385Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:40:23.303472Z",
     "start_time": "2024-07-25T22:40:19.275085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:40:23.310287Z",
     "start_time": "2024-07-25T22:40:23.304433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: rescaling, False\n",
      "Layer: normalization, False\n",
      "Layer: rescaling_1, False\n",
      "Layer: stem_conv_pad, False\n",
      "Layer: stem_conv, False\n",
      "Layer: stem_bn, False\n",
      "Layer: stem_activation, False\n",
      "Layer: block1a_dwconv, False\n",
      "Layer: block1a_bn, False\n",
      "Layer: block1a_activation, False\n",
      "Layer: block1a_se_squeeze, False\n",
      "Layer: block1a_se_reshape, False\n",
      "Layer: block1a_se_reduce, False\n",
      "Layer: block1a_se_expand, False\n",
      "Layer: block1a_se_excite, False\n",
      "Layer: block1a_project_conv, False\n",
      "Layer: block1a_project_bn, False\n",
      "Layer: block1b_dwconv, False\n",
      "Layer: block1b_bn, False\n",
      "Layer: block1b_activation, False\n",
      "Layer: block1b_se_squeeze, False\n",
      "Layer: block1b_se_reshape, False\n",
      "Layer: block1b_se_reduce, False\n",
      "Layer: block1b_se_expand, False\n",
      "Layer: block1b_se_excite, False\n",
      "Layer: block1b_project_conv, False\n",
      "Layer: block1b_project_bn, False\n",
      "Layer: block1b_drop, False\n",
      "Layer: block1b_add, False\n",
      "Layer: block1c_dwconv, False\n",
      "Layer: block1c_bn, False\n",
      "Layer: block1c_activation, False\n",
      "Layer: block1c_se_squeeze, False\n",
      "Layer: block1c_se_reshape, False\n",
      "Layer: block1c_se_reduce, False\n",
      "Layer: block1c_se_expand, False\n",
      "Layer: block1c_se_excite, False\n",
      "Layer: block1c_project_conv, False\n",
      "Layer: block1c_project_bn, False\n",
      "Layer: block1c_drop, False\n",
      "Layer: block1c_add, False\n",
      "Layer: block1d_dwconv, False\n",
      "Layer: block1d_bn, False\n",
      "Layer: block1d_activation, False\n",
      "Layer: block1d_se_squeeze, False\n",
      "Layer: block1d_se_reshape, False\n",
      "Layer: block1d_se_reduce, False\n",
      "Layer: block1d_se_expand, False\n",
      "Layer: block1d_se_excite, False\n",
      "Layer: block1d_project_conv, False\n",
      "Layer: block1d_project_bn, False\n",
      "Layer: block1d_drop, False\n",
      "Layer: block1d_add, False\n",
      "Layer: block2a_expand_conv, False\n",
      "Layer: block2a_expand_bn, False\n",
      "Layer: block2a_expand_activation, False\n",
      "Layer: block2a_dwconv_pad, False\n",
      "Layer: block2a_dwconv, False\n",
      "Layer: block2a_bn, False\n",
      "Layer: block2a_activation, False\n",
      "Layer: block2a_se_squeeze, False\n",
      "Layer: block2a_se_reshape, False\n",
      "Layer: block2a_se_reduce, False\n",
      "Layer: block2a_se_expand, False\n",
      "Layer: block2a_se_excite, False\n",
      "Layer: block2a_project_conv, False\n",
      "Layer: block2a_project_bn, False\n",
      "Layer: block2b_expand_conv, False\n",
      "Layer: block2b_expand_bn, False\n",
      "Layer: block2b_expand_activation, False\n",
      "Layer: block2b_dwconv, False\n",
      "Layer: block2b_bn, False\n",
      "Layer: block2b_activation, False\n",
      "Layer: block2b_se_squeeze, False\n",
      "Layer: block2b_se_reshape, False\n",
      "Layer: block2b_se_reduce, False\n",
      "Layer: block2b_se_expand, False\n",
      "Layer: block2b_se_excite, False\n",
      "Layer: block2b_project_conv, False\n",
      "Layer: block2b_project_bn, False\n",
      "Layer: block2b_drop, False\n",
      "Layer: block2b_add, False\n",
      "Layer: block2c_expand_conv, False\n",
      "Layer: block2c_expand_bn, False\n",
      "Layer: block2c_expand_activation, False\n",
      "Layer: block2c_dwconv, False\n",
      "Layer: block2c_bn, False\n",
      "Layer: block2c_activation, False\n",
      "Layer: block2c_se_squeeze, False\n",
      "Layer: block2c_se_reshape, False\n",
      "Layer: block2c_se_reduce, False\n",
      "Layer: block2c_se_expand, False\n",
      "Layer: block2c_se_excite, False\n",
      "Layer: block2c_project_conv, False\n",
      "Layer: block2c_project_bn, False\n",
      "Layer: block2c_drop, False\n",
      "Layer: block2c_add, False\n",
      "Layer: block2d_expand_conv, False\n",
      "Layer: block2d_expand_bn, False\n",
      "Layer: block2d_expand_activation, False\n",
      "Layer: block2d_dwconv, False\n",
      "Layer: block2d_bn, False\n",
      "Layer: block2d_activation, False\n",
      "Layer: block2d_se_squeeze, False\n",
      "Layer: block2d_se_reshape, False\n",
      "Layer: block2d_se_reduce, False\n",
      "Layer: block2d_se_expand, False\n",
      "Layer: block2d_se_excite, False\n",
      "Layer: block2d_project_conv, False\n",
      "Layer: block2d_project_bn, False\n",
      "Layer: block2d_drop, False\n",
      "Layer: block2d_add, False\n",
      "Layer: block2e_expand_conv, False\n",
      "Layer: block2e_expand_bn, False\n",
      "Layer: block2e_expand_activation, False\n",
      "Layer: block2e_dwconv, False\n",
      "Layer: block2e_bn, False\n",
      "Layer: block2e_activation, False\n",
      "Layer: block2e_se_squeeze, False\n",
      "Layer: block2e_se_reshape, False\n",
      "Layer: block2e_se_reduce, False\n",
      "Layer: block2e_se_expand, False\n",
      "Layer: block2e_se_excite, False\n",
      "Layer: block2e_project_conv, False\n",
      "Layer: block2e_project_bn, False\n",
      "Layer: block2e_drop, False\n",
      "Layer: block2e_add, False\n",
      "Layer: block2f_expand_conv, False\n",
      "Layer: block2f_expand_bn, False\n",
      "Layer: block2f_expand_activation, False\n",
      "Layer: block2f_dwconv, False\n",
      "Layer: block2f_bn, False\n",
      "Layer: block2f_activation, False\n",
      "Layer: block2f_se_squeeze, False\n",
      "Layer: block2f_se_reshape, False\n",
      "Layer: block2f_se_reduce, False\n",
      "Layer: block2f_se_expand, False\n",
      "Layer: block2f_se_excite, False\n",
      "Layer: block2f_project_conv, False\n",
      "Layer: block2f_project_bn, False\n",
      "Layer: block2f_drop, False\n",
      "Layer: block2f_add, False\n",
      "Layer: block2g_expand_conv, False\n",
      "Layer: block2g_expand_bn, False\n",
      "Layer: block2g_expand_activation, False\n",
      "Layer: block2g_dwconv, False\n",
      "Layer: block2g_bn, False\n",
      "Layer: block2g_activation, False\n",
      "Layer: block2g_se_squeeze, False\n",
      "Layer: block2g_se_reshape, False\n",
      "Layer: block2g_se_reduce, False\n",
      "Layer: block2g_se_expand, False\n",
      "Layer: block2g_se_excite, False\n",
      "Layer: block2g_project_conv, False\n",
      "Layer: block2g_project_bn, False\n",
      "Layer: block2g_drop, False\n",
      "Layer: block2g_add, False\n",
      "Layer: block3a_expand_conv, False\n",
      "Layer: block3a_expand_bn, False\n",
      "Layer: block3a_expand_activation, False\n",
      "Layer: block3a_dwconv_pad, False\n",
      "Layer: block3a_dwconv, False\n",
      "Layer: block3a_bn, False\n",
      "Layer: block3a_activation, False\n",
      "Layer: block3a_se_squeeze, False\n",
      "Layer: block3a_se_reshape, False\n",
      "Layer: block3a_se_reduce, False\n",
      "Layer: block3a_se_expand, False\n",
      "Layer: block3a_se_excite, False\n",
      "Layer: block3a_project_conv, False\n",
      "Layer: block3a_project_bn, False\n",
      "Layer: block3b_expand_conv, False\n",
      "Layer: block3b_expand_bn, False\n",
      "Layer: block3b_expand_activation, False\n",
      "Layer: block3b_dwconv, False\n",
      "Layer: block3b_bn, False\n",
      "Layer: block3b_activation, False\n",
      "Layer: block3b_se_squeeze, False\n",
      "Layer: block3b_se_reshape, False\n",
      "Layer: block3b_se_reduce, False\n",
      "Layer: block3b_se_expand, False\n",
      "Layer: block3b_se_excite, False\n",
      "Layer: block3b_project_conv, False\n",
      "Layer: block3b_project_bn, False\n",
      "Layer: block3b_drop, False\n",
      "Layer: block3b_add, False\n",
      "Layer: block3c_expand_conv, False\n",
      "Layer: block3c_expand_bn, False\n",
      "Layer: block3c_expand_activation, False\n",
      "Layer: block3c_dwconv, False\n",
      "Layer: block3c_bn, False\n",
      "Layer: block3c_activation, False\n",
      "Layer: block3c_se_squeeze, False\n",
      "Layer: block3c_se_reshape, False\n",
      "Layer: block3c_se_reduce, False\n",
      "Layer: block3c_se_expand, False\n",
      "Layer: block3c_se_excite, False\n",
      "Layer: block3c_project_conv, False\n",
      "Layer: block3c_project_bn, False\n",
      "Layer: block3c_drop, False\n",
      "Layer: block3c_add, False\n",
      "Layer: block3d_expand_conv, False\n",
      "Layer: block3d_expand_bn, False\n",
      "Layer: block3d_expand_activation, False\n",
      "Layer: block3d_dwconv, False\n",
      "Layer: block3d_bn, False\n",
      "Layer: block3d_activation, False\n",
      "Layer: block3d_se_squeeze, False\n",
      "Layer: block3d_se_reshape, False\n",
      "Layer: block3d_se_reduce, False\n",
      "Layer: block3d_se_expand, False\n",
      "Layer: block3d_se_excite, False\n",
      "Layer: block3d_project_conv, False\n",
      "Layer: block3d_project_bn, False\n",
      "Layer: block3d_drop, False\n",
      "Layer: block3d_add, False\n",
      "Layer: block3e_expand_conv, False\n",
      "Layer: block3e_expand_bn, False\n",
      "Layer: block3e_expand_activation, False\n",
      "Layer: block3e_dwconv, False\n",
      "Layer: block3e_bn, False\n",
      "Layer: block3e_activation, False\n",
      "Layer: block3e_se_squeeze, False\n",
      "Layer: block3e_se_reshape, False\n",
      "Layer: block3e_se_reduce, False\n",
      "Layer: block3e_se_expand, False\n",
      "Layer: block3e_se_excite, False\n",
      "Layer: block3e_project_conv, False\n",
      "Layer: block3e_project_bn, False\n",
      "Layer: block3e_drop, False\n",
      "Layer: block3e_add, False\n",
      "Layer: block3f_expand_conv, False\n",
      "Layer: block3f_expand_bn, False\n",
      "Layer: block3f_expand_activation, False\n",
      "Layer: block3f_dwconv, False\n",
      "Layer: block3f_bn, False\n",
      "Layer: block3f_activation, False\n",
      "Layer: block3f_se_squeeze, False\n",
      "Layer: block3f_se_reshape, False\n",
      "Layer: block3f_se_reduce, False\n",
      "Layer: block3f_se_expand, False\n",
      "Layer: block3f_se_excite, False\n",
      "Layer: block3f_project_conv, False\n",
      "Layer: block3f_project_bn, False\n",
      "Layer: block3f_drop, False\n",
      "Layer: block3f_add, False\n",
      "Layer: block3g_expand_conv, False\n",
      "Layer: block3g_expand_bn, False\n",
      "Layer: block3g_expand_activation, False\n",
      "Layer: block3g_dwconv, False\n",
      "Layer: block3g_bn, False\n",
      "Layer: block3g_activation, False\n",
      "Layer: block3g_se_squeeze, False\n",
      "Layer: block3g_se_reshape, False\n",
      "Layer: block3g_se_reduce, False\n",
      "Layer: block3g_se_expand, False\n",
      "Layer: block3g_se_excite, False\n",
      "Layer: block3g_project_conv, False\n",
      "Layer: block3g_project_bn, False\n",
      "Layer: block3g_drop, False\n",
      "Layer: block3g_add, False\n",
      "Layer: block4a_expand_conv, False\n",
      "Layer: block4a_expand_bn, False\n",
      "Layer: block4a_expand_activation, False\n",
      "Layer: block4a_dwconv_pad, False\n",
      "Layer: block4a_dwconv, False\n",
      "Layer: block4a_bn, False\n",
      "Layer: block4a_activation, False\n",
      "Layer: block4a_se_squeeze, False\n",
      "Layer: block4a_se_reshape, False\n",
      "Layer: block4a_se_reduce, False\n",
      "Layer: block4a_se_expand, False\n",
      "Layer: block4a_se_excite, False\n",
      "Layer: block4a_project_conv, False\n",
      "Layer: block4a_project_bn, False\n",
      "Layer: block4b_expand_conv, False\n",
      "Layer: block4b_expand_bn, False\n",
      "Layer: block4b_expand_activation, False\n",
      "Layer: block4b_dwconv, False\n",
      "Layer: block4b_bn, False\n",
      "Layer: block4b_activation, False\n",
      "Layer: block4b_se_squeeze, False\n",
      "Layer: block4b_se_reshape, False\n",
      "Layer: block4b_se_reduce, False\n",
      "Layer: block4b_se_expand, False\n",
      "Layer: block4b_se_excite, False\n",
      "Layer: block4b_project_conv, False\n",
      "Layer: block4b_project_bn, False\n",
      "Layer: block4b_drop, False\n",
      "Layer: block4b_add, False\n",
      "Layer: block4c_expand_conv, False\n",
      "Layer: block4c_expand_bn, False\n",
      "Layer: block4c_expand_activation, False\n",
      "Layer: block4c_dwconv, False\n",
      "Layer: block4c_bn, False\n",
      "Layer: block4c_activation, False\n",
      "Layer: block4c_se_squeeze, False\n",
      "Layer: block4c_se_reshape, False\n",
      "Layer: block4c_se_reduce, False\n",
      "Layer: block4c_se_expand, False\n",
      "Layer: block4c_se_excite, False\n",
      "Layer: block4c_project_conv, False\n",
      "Layer: block4c_project_bn, False\n",
      "Layer: block4c_drop, False\n",
      "Layer: block4c_add, False\n",
      "Layer: block4d_expand_conv, False\n",
      "Layer: block4d_expand_bn, False\n",
      "Layer: block4d_expand_activation, False\n",
      "Layer: block4d_dwconv, False\n",
      "Layer: block4d_bn, False\n",
      "Layer: block4d_activation, False\n",
      "Layer: block4d_se_squeeze, False\n",
      "Layer: block4d_se_reshape, False\n",
      "Layer: block4d_se_reduce, False\n",
      "Layer: block4d_se_expand, False\n",
      "Layer: block4d_se_excite, False\n",
      "Layer: block4d_project_conv, False\n",
      "Layer: block4d_project_bn, False\n",
      "Layer: block4d_drop, False\n",
      "Layer: block4d_add, False\n",
      "Layer: block4e_expand_conv, False\n",
      "Layer: block4e_expand_bn, False\n",
      "Layer: block4e_expand_activation, False\n",
      "Layer: block4e_dwconv, False\n",
      "Layer: block4e_bn, False\n",
      "Layer: block4e_activation, False\n",
      "Layer: block4e_se_squeeze, False\n",
      "Layer: block4e_se_reshape, False\n",
      "Layer: block4e_se_reduce, False\n",
      "Layer: block4e_se_expand, False\n",
      "Layer: block4e_se_excite, False\n",
      "Layer: block4e_project_conv, False\n",
      "Layer: block4e_project_bn, False\n",
      "Layer: block4e_drop, False\n",
      "Layer: block4e_add, False\n",
      "Layer: block4f_expand_conv, False\n",
      "Layer: block4f_expand_bn, False\n",
      "Layer: block4f_expand_activation, False\n",
      "Layer: block4f_dwconv, False\n",
      "Layer: block4f_bn, False\n",
      "Layer: block4f_activation, False\n",
      "Layer: block4f_se_squeeze, False\n",
      "Layer: block4f_se_reshape, False\n",
      "Layer: block4f_se_reduce, False\n",
      "Layer: block4f_se_expand, False\n",
      "Layer: block4f_se_excite, False\n",
      "Layer: block4f_project_conv, False\n",
      "Layer: block4f_project_bn, False\n",
      "Layer: block4f_drop, False\n",
      "Layer: block4f_add, False\n",
      "Layer: block4g_expand_conv, False\n",
      "Layer: block4g_expand_bn, False\n",
      "Layer: block4g_expand_activation, False\n",
      "Layer: block4g_dwconv, False\n",
      "Layer: block4g_bn, False\n",
      "Layer: block4g_activation, False\n",
      "Layer: block4g_se_squeeze, False\n",
      "Layer: block4g_se_reshape, False\n",
      "Layer: block4g_se_reduce, False\n",
      "Layer: block4g_se_expand, False\n",
      "Layer: block4g_se_excite, False\n",
      "Layer: block4g_project_conv, False\n",
      "Layer: block4g_project_bn, False\n",
      "Layer: block4g_drop, False\n",
      "Layer: block4g_add, False\n",
      "Layer: block4h_expand_conv, False\n",
      "Layer: block4h_expand_bn, False\n",
      "Layer: block4h_expand_activation, False\n",
      "Layer: block4h_dwconv, False\n",
      "Layer: block4h_bn, False\n",
      "Layer: block4h_activation, False\n",
      "Layer: block4h_se_squeeze, False\n",
      "Layer: block4h_se_reshape, False\n",
      "Layer: block4h_se_reduce, False\n",
      "Layer: block4h_se_expand, False\n",
      "Layer: block4h_se_excite, False\n",
      "Layer: block4h_project_conv, False\n",
      "Layer: block4h_project_bn, False\n",
      "Layer: block4h_drop, False\n",
      "Layer: block4h_add, False\n",
      "Layer: block4i_expand_conv, False\n",
      "Layer: block4i_expand_bn, False\n",
      "Layer: block4i_expand_activation, False\n",
      "Layer: block4i_dwconv, False\n",
      "Layer: block4i_bn, False\n",
      "Layer: block4i_activation, False\n",
      "Layer: block4i_se_squeeze, False\n",
      "Layer: block4i_se_reshape, False\n",
      "Layer: block4i_se_reduce, False\n",
      "Layer: block4i_se_expand, False\n",
      "Layer: block4i_se_excite, False\n",
      "Layer: block4i_project_conv, False\n",
      "Layer: block4i_project_bn, False\n",
      "Layer: block4i_drop, False\n",
      "Layer: block4i_add, False\n",
      "Layer: block4j_expand_conv, False\n",
      "Layer: block4j_expand_bn, False\n",
      "Layer: block4j_expand_activation, False\n",
      "Layer: block4j_dwconv, False\n",
      "Layer: block4j_bn, False\n",
      "Layer: block4j_activation, False\n",
      "Layer: block4j_se_squeeze, False\n",
      "Layer: block4j_se_reshape, False\n",
      "Layer: block4j_se_reduce, False\n",
      "Layer: block4j_se_expand, False\n",
      "Layer: block4j_se_excite, False\n",
      "Layer: block4j_project_conv, False\n",
      "Layer: block4j_project_bn, False\n",
      "Layer: block4j_drop, False\n",
      "Layer: block4j_add, False\n",
      "Layer: block5a_expand_conv, False\n",
      "Layer: block5a_expand_bn, False\n",
      "Layer: block5a_expand_activation, False\n",
      "Layer: block5a_dwconv, False\n",
      "Layer: block5a_bn, False\n",
      "Layer: block5a_activation, False\n",
      "Layer: block5a_se_squeeze, False\n",
      "Layer: block5a_se_reshape, False\n",
      "Layer: block5a_se_reduce, False\n",
      "Layer: block5a_se_expand, False\n",
      "Layer: block5a_se_excite, False\n",
      "Layer: block5a_project_conv, False\n",
      "Layer: block5a_project_bn, False\n",
      "Layer: block5b_expand_conv, False\n",
      "Layer: block5b_expand_bn, False\n",
      "Layer: block5b_expand_activation, False\n",
      "Layer: block5b_dwconv, False\n",
      "Layer: block5b_bn, False\n",
      "Layer: block5b_activation, False\n",
      "Layer: block5b_se_squeeze, False\n",
      "Layer: block5b_se_reshape, False\n",
      "Layer: block5b_se_reduce, False\n",
      "Layer: block5b_se_expand, False\n",
      "Layer: block5b_se_excite, False\n",
      "Layer: block5b_project_conv, False\n",
      "Layer: block5b_project_bn, False\n",
      "Layer: block5b_drop, False\n",
      "Layer: block5b_add, False\n",
      "Layer: block5c_expand_conv, False\n",
      "Layer: block5c_expand_bn, False\n",
      "Layer: block5c_expand_activation, False\n",
      "Layer: block5c_dwconv, False\n",
      "Layer: block5c_bn, False\n",
      "Layer: block5c_activation, False\n",
      "Layer: block5c_se_squeeze, False\n",
      "Layer: block5c_se_reshape, False\n",
      "Layer: block5c_se_reduce, False\n",
      "Layer: block5c_se_expand, False\n",
      "Layer: block5c_se_excite, False\n",
      "Layer: block5c_project_conv, False\n",
      "Layer: block5c_project_bn, False\n",
      "Layer: block5c_drop, False\n",
      "Layer: block5c_add, False\n",
      "Layer: block5d_expand_conv, False\n",
      "Layer: block5d_expand_bn, False\n",
      "Layer: block5d_expand_activation, False\n",
      "Layer: block5d_dwconv, False\n",
      "Layer: block5d_bn, False\n",
      "Layer: block5d_activation, False\n",
      "Layer: block5d_se_squeeze, False\n",
      "Layer: block5d_se_reshape, False\n",
      "Layer: block5d_se_reduce, False\n",
      "Layer: block5d_se_expand, False\n",
      "Layer: block5d_se_excite, False\n",
      "Layer: block5d_project_conv, False\n",
      "Layer: block5d_project_bn, False\n",
      "Layer: block5d_drop, False\n",
      "Layer: block5d_add, False\n",
      "Layer: block5e_expand_conv, False\n",
      "Layer: block5e_expand_bn, False\n",
      "Layer: block5e_expand_activation, False\n",
      "Layer: block5e_dwconv, False\n",
      "Layer: block5e_bn, False\n",
      "Layer: block5e_activation, False\n",
      "Layer: block5e_se_squeeze, False\n",
      "Layer: block5e_se_reshape, False\n",
      "Layer: block5e_se_reduce, False\n",
      "Layer: block5e_se_expand, False\n",
      "Layer: block5e_se_excite, False\n",
      "Layer: block5e_project_conv, False\n",
      "Layer: block5e_project_bn, False\n",
      "Layer: block5e_drop, False\n",
      "Layer: block5e_add, False\n",
      "Layer: block5f_expand_conv, False\n",
      "Layer: block5f_expand_bn, False\n",
      "Layer: block5f_expand_activation, False\n",
      "Layer: block5f_dwconv, False\n",
      "Layer: block5f_bn, False\n",
      "Layer: block5f_activation, False\n",
      "Layer: block5f_se_squeeze, False\n",
      "Layer: block5f_se_reshape, False\n",
      "Layer: block5f_se_reduce, False\n",
      "Layer: block5f_se_expand, False\n",
      "Layer: block5f_se_excite, False\n",
      "Layer: block5f_project_conv, False\n",
      "Layer: block5f_project_bn, False\n",
      "Layer: block5f_drop, False\n",
      "Layer: block5f_add, False\n",
      "Layer: block5g_expand_conv, False\n",
      "Layer: block5g_expand_bn, False\n",
      "Layer: block5g_expand_activation, False\n",
      "Layer: block5g_dwconv, False\n",
      "Layer: block5g_bn, False\n",
      "Layer: block5g_activation, False\n",
      "Layer: block5g_se_squeeze, False\n",
      "Layer: block5g_se_reshape, False\n",
      "Layer: block5g_se_reduce, False\n",
      "Layer: block5g_se_expand, False\n",
      "Layer: block5g_se_excite, False\n",
      "Layer: block5g_project_conv, False\n",
      "Layer: block5g_project_bn, False\n",
      "Layer: block5g_drop, False\n",
      "Layer: block5g_add, False\n",
      "Layer: block5h_expand_conv, False\n",
      "Layer: block5h_expand_bn, False\n",
      "Layer: block5h_expand_activation, False\n",
      "Layer: block5h_dwconv, False\n",
      "Layer: block5h_bn, False\n",
      "Layer: block5h_activation, False\n",
      "Layer: block5h_se_squeeze, False\n",
      "Layer: block5h_se_reshape, False\n",
      "Layer: block5h_se_reduce, False\n",
      "Layer: block5h_se_expand, False\n",
      "Layer: block5h_se_excite, False\n",
      "Layer: block5h_project_conv, False\n",
      "Layer: block5h_project_bn, False\n",
      "Layer: block5h_drop, False\n",
      "Layer: block5h_add, False\n",
      "Layer: block5i_expand_conv, False\n",
      "Layer: block5i_expand_bn, False\n",
      "Layer: block5i_expand_activation, False\n",
      "Layer: block5i_dwconv, False\n",
      "Layer: block5i_bn, False\n",
      "Layer: block5i_activation, False\n",
      "Layer: block5i_se_squeeze, False\n",
      "Layer: block5i_se_reshape, False\n",
      "Layer: block5i_se_reduce, False\n",
      "Layer: block5i_se_expand, False\n",
      "Layer: block5i_se_excite, False\n",
      "Layer: block5i_project_conv, False\n",
      "Layer: block5i_project_bn, False\n",
      "Layer: block5i_drop, False\n",
      "Layer: block5i_add, False\n",
      "Layer: block5j_expand_conv, False\n",
      "Layer: block5j_expand_bn, False\n",
      "Layer: block5j_expand_activation, False\n",
      "Layer: block5j_dwconv, False\n",
      "Layer: block5j_bn, False\n",
      "Layer: block5j_activation, False\n",
      "Layer: block5j_se_squeeze, False\n",
      "Layer: block5j_se_reshape, False\n",
      "Layer: block5j_se_reduce, False\n",
      "Layer: block5j_se_expand, False\n",
      "Layer: block5j_se_excite, False\n",
      "Layer: block5j_project_conv, False\n",
      "Layer: block5j_project_bn, False\n",
      "Layer: block5j_drop, False\n",
      "Layer: block5j_add, False\n",
      "Layer: block6a_expand_conv, False\n",
      "Layer: block6a_expand_bn, False\n",
      "Layer: block6a_expand_activation, False\n",
      "Layer: block6a_dwconv_pad, False\n",
      "Layer: block6a_dwconv, False\n",
      "Layer: block6a_bn, False\n",
      "Layer: block6a_activation, False\n",
      "Layer: block6a_se_squeeze, False\n",
      "Layer: block6a_se_reshape, False\n",
      "Layer: block6a_se_reduce, False\n",
      "Layer: block6a_se_expand, False\n",
      "Layer: block6a_se_excite, False\n",
      "Layer: block6a_project_conv, False\n",
      "Layer: block6a_project_bn, False\n",
      "Layer: block6b_expand_conv, False\n",
      "Layer: block6b_expand_bn, False\n",
      "Layer: block6b_expand_activation, False\n",
      "Layer: block6b_dwconv, False\n",
      "Layer: block6b_bn, False\n",
      "Layer: block6b_activation, False\n",
      "Layer: block6b_se_squeeze, False\n",
      "Layer: block6b_se_reshape, False\n",
      "Layer: block6b_se_reduce, False\n",
      "Layer: block6b_se_expand, False\n",
      "Layer: block6b_se_excite, False\n",
      "Layer: block6b_project_conv, False\n",
      "Layer: block6b_project_bn, False\n",
      "Layer: block6b_drop, False\n",
      "Layer: block6b_add, False\n",
      "Layer: block6c_expand_conv, False\n",
      "Layer: block6c_expand_bn, False\n",
      "Layer: block6c_expand_activation, False\n",
      "Layer: block6c_dwconv, False\n",
      "Layer: block6c_bn, False\n",
      "Layer: block6c_activation, False\n",
      "Layer: block6c_se_squeeze, False\n",
      "Layer: block6c_se_reshape, False\n",
      "Layer: block6c_se_reduce, False\n",
      "Layer: block6c_se_expand, False\n",
      "Layer: block6c_se_excite, False\n",
      "Layer: block6c_project_conv, False\n",
      "Layer: block6c_project_bn, False\n",
      "Layer: block6c_drop, False\n",
      "Layer: block6c_add, False\n",
      "Layer: block6d_expand_conv, False\n",
      "Layer: block6d_expand_bn, False\n",
      "Layer: block6d_expand_activation, False\n",
      "Layer: block6d_dwconv, False\n",
      "Layer: block6d_bn, False\n",
      "Layer: block6d_activation, False\n",
      "Layer: block6d_se_squeeze, False\n",
      "Layer: block6d_se_reshape, False\n",
      "Layer: block6d_se_reduce, False\n",
      "Layer: block6d_se_expand, False\n",
      "Layer: block6d_se_excite, False\n",
      "Layer: block6d_project_conv, False\n",
      "Layer: block6d_project_bn, False\n",
      "Layer: block6d_drop, False\n",
      "Layer: block6d_add, False\n",
      "Layer: block6e_expand_conv, False\n",
      "Layer: block6e_expand_bn, False\n",
      "Layer: block6e_expand_activation, False\n",
      "Layer: block6e_dwconv, False\n",
      "Layer: block6e_bn, False\n",
      "Layer: block6e_activation, False\n",
      "Layer: block6e_se_squeeze, False\n",
      "Layer: block6e_se_reshape, False\n",
      "Layer: block6e_se_reduce, False\n",
      "Layer: block6e_se_expand, False\n",
      "Layer: block6e_se_excite, False\n",
      "Layer: block6e_project_conv, False\n",
      "Layer: block6e_project_bn, False\n",
      "Layer: block6e_drop, False\n",
      "Layer: block6e_add, False\n",
      "Layer: block6f_expand_conv, False\n",
      "Layer: block6f_expand_bn, False\n",
      "Layer: block6f_expand_activation, False\n",
      "Layer: block6f_dwconv, False\n",
      "Layer: block6f_bn, False\n",
      "Layer: block6f_activation, False\n",
      "Layer: block6f_se_squeeze, False\n",
      "Layer: block6f_se_reshape, False\n",
      "Layer: block6f_se_reduce, False\n",
      "Layer: block6f_se_expand, False\n",
      "Layer: block6f_se_excite, False\n",
      "Layer: block6f_project_conv, False\n",
      "Layer: block6f_project_bn, False\n",
      "Layer: block6f_drop, False\n",
      "Layer: block6f_add, False\n",
      "Layer: block6g_expand_conv, False\n",
      "Layer: block6g_expand_bn, False\n",
      "Layer: block6g_expand_activation, False\n",
      "Layer: block6g_dwconv, False\n",
      "Layer: block6g_bn, False\n",
      "Layer: block6g_activation, False\n",
      "Layer: block6g_se_squeeze, False\n",
      "Layer: block6g_se_reshape, False\n",
      "Layer: block6g_se_reduce, False\n",
      "Layer: block6g_se_expand, False\n",
      "Layer: block6g_se_excite, False\n",
      "Layer: block6g_project_conv, False\n",
      "Layer: block6g_project_bn, False\n",
      "Layer: block6g_drop, False\n",
      "Layer: block6g_add, False\n",
      "Layer: block6h_expand_conv, False\n",
      "Layer: block6h_expand_bn, False\n",
      "Layer: block6h_expand_activation, False\n",
      "Layer: block6h_dwconv, False\n",
      "Layer: block6h_bn, False\n",
      "Layer: block6h_activation, False\n",
      "Layer: block6h_se_squeeze, False\n",
      "Layer: block6h_se_reshape, False\n",
      "Layer: block6h_se_reduce, False\n",
      "Layer: block6h_se_expand, False\n",
      "Layer: block6h_se_excite, False\n",
      "Layer: block6h_project_conv, False\n",
      "Layer: block6h_project_bn, False\n",
      "Layer: block6h_drop, False\n",
      "Layer: block6h_add, False\n",
      "Layer: block6i_expand_conv, False\n",
      "Layer: block6i_expand_bn, False\n",
      "Layer: block6i_expand_activation, False\n",
      "Layer: block6i_dwconv, False\n",
      "Layer: block6i_bn, False\n",
      "Layer: block6i_activation, False\n",
      "Layer: block6i_se_squeeze, False\n",
      "Layer: block6i_se_reshape, False\n",
      "Layer: block6i_se_reduce, False\n",
      "Layer: block6i_se_expand, False\n",
      "Layer: block6i_se_excite, False\n",
      "Layer: block6i_project_conv, False\n",
      "Layer: block6i_project_bn, False\n",
      "Layer: block6i_drop, False\n",
      "Layer: block6i_add, False\n",
      "Layer: block6j_expand_conv, False\n",
      "Layer: block6j_expand_bn, False\n",
      "Layer: block6j_expand_activation, False\n",
      "Layer: block6j_dwconv, False\n",
      "Layer: block6j_bn, False\n",
      "Layer: block6j_activation, False\n",
      "Layer: block6j_se_squeeze, False\n",
      "Layer: block6j_se_reshape, False\n",
      "Layer: block6j_se_reduce, False\n",
      "Layer: block6j_se_expand, False\n",
      "Layer: block6j_se_excite, False\n",
      "Layer: block6j_project_conv, False\n",
      "Layer: block6j_project_bn, False\n",
      "Layer: block6j_drop, False\n",
      "Layer: block6j_add, False\n",
      "Layer: block6k_expand_conv, False\n",
      "Layer: block6k_expand_bn, False\n",
      "Layer: block6k_expand_activation, False\n",
      "Layer: block6k_dwconv, False\n",
      "Layer: block6k_bn, False\n",
      "Layer: block6k_activation, False\n",
      "Layer: block6k_se_squeeze, False\n",
      "Layer: block6k_se_reshape, False\n",
      "Layer: block6k_se_reduce, False\n",
      "Layer: block6k_se_expand, False\n",
      "Layer: block6k_se_excite, False\n",
      "Layer: block6k_project_conv, False\n",
      "Layer: block6k_project_bn, False\n",
      "Layer: block6k_drop, False\n",
      "Layer: block6k_add, False\n",
      "Layer: block6l_expand_conv, False\n",
      "Layer: block6l_expand_bn, False\n",
      "Layer: block6l_expand_activation, False\n",
      "Layer: block6l_dwconv, False\n",
      "Layer: block6l_bn, False\n",
      "Layer: block6l_activation, False\n",
      "Layer: block6l_se_squeeze, False\n",
      "Layer: block6l_se_reshape, False\n",
      "Layer: block6l_se_reduce, False\n",
      "Layer: block6l_se_expand, False\n",
      "Layer: block6l_se_excite, False\n",
      "Layer: block6l_project_conv, False\n",
      "Layer: block6l_project_bn, False\n",
      "Layer: block6l_drop, False\n",
      "Layer: block6l_add, False\n",
      "Layer: block6m_expand_conv, False\n",
      "Layer: block6m_expand_bn, False\n",
      "Layer: block6m_expand_activation, False\n",
      "Layer: block6m_dwconv, False\n",
      "Layer: block6m_bn, False\n",
      "Layer: block6m_activation, False\n",
      "Layer: block6m_se_squeeze, False\n",
      "Layer: block6m_se_reshape, False\n",
      "Layer: block6m_se_reduce, False\n",
      "Layer: block6m_se_expand, False\n",
      "Layer: block6m_se_excite, False\n",
      "Layer: block6m_project_conv, False\n",
      "Layer: block6m_project_bn, False\n",
      "Layer: block6m_drop, False\n",
      "Layer: block6m_add, False\n",
      "Layer: block7a_expand_conv, False\n",
      "Layer: block7a_expand_bn, False\n",
      "Layer: block7a_expand_activation, False\n",
      "Layer: block7a_dwconv, False\n",
      "Layer: block7a_bn, False\n",
      "Layer: block7a_activation, False\n",
      "Layer: block7a_se_squeeze, False\n",
      "Layer: block7a_se_reshape, False\n",
      "Layer: block7a_se_reduce, False\n",
      "Layer: block7a_se_expand, False\n",
      "Layer: block7a_se_excite, False\n",
      "Layer: block7a_project_conv, False\n",
      "Layer: block7a_project_bn, False\n",
      "Layer: block7b_expand_conv, False\n",
      "Layer: block7b_expand_bn, False\n",
      "Layer: block7b_expand_activation, False\n",
      "Layer: block7b_dwconv, False\n",
      "Layer: block7b_bn, False\n",
      "Layer: block7b_activation, False\n",
      "Layer: block7b_se_squeeze, False\n",
      "Layer: block7b_se_reshape, False\n",
      "Layer: block7b_se_reduce, False\n",
      "Layer: block7b_se_expand, False\n",
      "Layer: block7b_se_excite, False\n",
      "Layer: block7b_project_conv, False\n",
      "Layer: block7b_project_bn, False\n",
      "Layer: block7b_drop, False\n",
      "Layer: block7b_add, False\n",
      "Layer: block7c_expand_conv, False\n",
      "Layer: block7c_expand_bn, False\n",
      "Layer: block7c_expand_activation, False\n",
      "Layer: block7c_dwconv, False\n",
      "Layer: block7c_bn, False\n",
      "Layer: block7c_activation, False\n",
      "Layer: block7c_se_squeeze, False\n",
      "Layer: block7c_se_reshape, False\n",
      "Layer: block7c_se_reduce, False\n",
      "Layer: block7c_se_expand, False\n",
      "Layer: block7c_se_excite, False\n",
      "Layer: block7c_project_conv, False\n",
      "Layer: block7c_project_bn, False\n",
      "Layer: block7c_drop, False\n",
      "Layer: block7c_add, False\n",
      "Layer: block7d_expand_conv, False\n",
      "Layer: block7d_expand_bn, False\n",
      "Layer: block7d_expand_activation, False\n",
      "Layer: block7d_dwconv, False\n",
      "Layer: block7d_bn, False\n",
      "Layer: block7d_activation, False\n",
      "Layer: block7d_se_squeeze, False\n",
      "Layer: block7d_se_reshape, False\n",
      "Layer: block7d_se_reduce, False\n",
      "Layer: block7d_se_expand, False\n",
      "Layer: block7d_se_excite, False\n",
      "Layer: block7d_project_conv, False\n",
      "Layer: block7d_project_bn, False\n",
      "Layer: block7d_drop, False\n",
      "Layer: block7d_add, False\n",
      "Layer: top_conv, False\n",
      "Layer: top_bn, False\n",
      "Layer: top_activation, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:40:23.315045Z",
     "start_time": "2024-07-25T22:40:23.311217Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:41:28.783876Z",
     "start_time": "2024-07-25T22:41:28.781154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:41:29.257133Z",
     "start_time": "2024-07-25T22:41:29.250926Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "8f631881607b5da6",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:41:31.425531Z",
     "start_time": "2024-07-25T22:41:30.182342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "x = aug_layer(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'EfficientB7_90.49')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7_90.49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " efficientnetb7 (Functional  (None, 7, 7, 2560)        64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 2560)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               655616    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64794715 (247.17 MB)\n",
      "Trainable params: 697028 (2.66 MB)\n",
      "Non-trainable params: 64097687 (244.51 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:43:22.897195Z",
     "start_time": "2024-07-25T22:43:22.894600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models','EfficientB7'), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:43:23.243897Z",
     "start_time": "2024-07-25T22:43:23.241093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=2) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:43:23.597520Z",
     "start_time": "2024-07-25T22:43:23.579808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-25T22:43:24.217717Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 10, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8890 - accuracy: 0.6205\n",
      "Epoch 1: val_loss improved from inf to 1.16254, saving model to Trained_Models/EfficientB7\n",
      "74/74 [==============================] - 120s 2s/step - loss: 0.8890 - accuracy: 0.6205 - val_loss: 1.1625 - val_accuracy: 0.4125 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7583 - accuracy: 0.6895\n",
      "Epoch 2: val_loss did not improve from 1.16254\n",
      "74/74 [==============================] - 41s 548ms/step - loss: 0.7583 - accuracy: 0.6895 - val_loss: 1.3840 - val_accuracy: 0.2997 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.7200\n",
      "Epoch 3: val_loss improved from 1.16254 to 1.14368, saving model to Trained_Models/EfficientB7\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:26:20.767659Z",
     "start_time": "2024-07-25T22:26:20.746231Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:26:20.784056Z",
     "start_time": "2024-07-25T22:26:20.768297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:26:20.791126Z",
     "start_time": "2024-07-25T22:26:20.785251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:26:20.832474Z",
     "start_time": "2024-07-25T22:26:20.791681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 10\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb7 (Functional  (None, 7, 7, 2560)        64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2560)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               655616    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64794715 (247.17 MB)\n",
      "Trainable params: 22413988 (85.50 MB)\n",
      "Non-trainable params: 42380727 (161.67 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:31:08.018877Z",
     "start_time": "2024-07-25T22:26:20.833078Z"
    }
   },
   "cell_type": "code",
   "source": "history_25 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.4415 - accuracy: 0.5426\n",
      "Epoch 11: val_loss did not improve from 0.28987\n",
      "74/74 [==============================] - 27s 224ms/step - loss: 1.4415 - accuracy: 0.5426 - val_loss: 0.5542 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.7874\n",
      "Epoch 12: val_loss did not improve from 0.28987\n",
      "74/74 [==============================] - 14s 191ms/step - loss: 0.5825 - accuracy: 0.7874 - val_loss: 1.0118 - val_accuracy: 0.5865 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8484\n",
      "Epoch 13: val_loss did not improve from 0.28987\n",
      "74/74 [==============================] - 15s 195ms/step - loss: 0.4270 - accuracy: 0.8484 - val_loss: 0.6098 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.8899\n",
      "Epoch 14: val_loss did not improve from 0.28987\n",
      "74/74 [==============================] - 14s 191ms/step - loss: 0.3018 - accuracy: 0.8899 - val_loss: 0.3153 - val_accuracy: 0.8932 - lr: 3.0000e-04\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9081\n",
      "Epoch 15: val_loss did not improve from 0.28987\n",
      "74/74 [==============================] - 14s 191ms/step - loss: 0.2408 - accuracy: 0.9081 - val_loss: 0.3197 - val_accuracy: 0.8952 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.9310\n",
      "Epoch 16: val_loss improved from 0.28987 to 0.19997, saving model to Trained_Models/EfficientB7\n",
      "74/74 [==============================] - 56s 759ms/step - loss: 0.1944 - accuracy: 0.9310 - val_loss: 0.2000 - val_accuracy: 0.9446 - lr: 3.0000e-04\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.9271\n",
      "Epoch 17: val_loss did not improve from 0.19997\n",
      "74/74 [==============================] - 16s 206ms/step - loss: 0.1859 - accuracy: 0.9271 - val_loss: 0.3259 - val_accuracy: 0.8942 - lr: 3.0000e-04\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9449\n",
      "Epoch 18: val_loss improved from 0.19997 to 0.14473, saving model to Trained_Models/EfficientB7\n",
      "74/74 [==============================] - 57s 773ms/step - loss: 0.1580 - accuracy: 0.9449 - val_loss: 0.1447 - val_accuracy: 0.9575 - lr: 3.0000e-04\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9543\n",
      "Epoch 19: val_loss improved from 0.14473 to 0.13556, saving model to Trained_Models/EfficientB7\n",
      "74/74 [==============================] - 58s 791ms/step - loss: 0.1365 - accuracy: 0.9543 - val_loss: 0.1356 - val_accuracy: 0.9594 - lr: 3.0000e-04\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9687\n",
      "Epoch 20: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 15s 205ms/step - loss: 0.0997 - accuracy: 0.9687 - val_loss: 0.3932 - val_accuracy: 0.8961 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:31:08.024564Z",
     "start_time": "2024-07-25T22:31:08.019904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 20\n",
    "for layer in base_model.layers[-175:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:31:08.101758Z",
     "start_time": "2024-07-25T22:31:08.025136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0005), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb7 (Functional  (None, 7, 7, 2560)        64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2560)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               655616    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64794715 (247.17 MB)\n",
      "Trainable params: 41076484 (156.69 MB)\n",
      "Non-trainable params: 23718231 (90.48 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:34:16.257815Z",
     "start_time": "2024-07-25T22:31:08.102491Z"
    }
   },
   "cell_type": "code",
   "source": "history_75 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.6789 - accuracy: 0.6095\n",
      "Epoch 21: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 38s 249ms/step - loss: 1.6789 - accuracy: 0.6095 - val_loss: 0.4152 - val_accuracy: 0.8912 - lr: 7.5000e-04\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.7789\n",
      "Epoch 22: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 17s 226ms/step - loss: 0.5349 - accuracy: 0.7789 - val_loss: 0.5752 - val_accuracy: 0.8111 - lr: 7.5000e-04\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7716 - accuracy: 0.7975\n",
      "Epoch 23: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 17s 227ms/step - loss: 0.7716 - accuracy: 0.7975 - val_loss: 0.4448 - val_accuracy: 0.8556 - lr: 7.5000e-04\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.8916\n",
      "Epoch 24: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 17s 227ms/step - loss: 0.3127 - accuracy: 0.8916 - val_loss: 0.2769 - val_accuracy: 0.9110 - lr: 2.2500e-04\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9030\n",
      "Epoch 25: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 17s 227ms/step - loss: 0.2812 - accuracy: 0.9030 - val_loss: 0.6118 - val_accuracy: 0.7428 - lr: 2.2500e-04\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.9060\n",
      "Epoch 26: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 17s 222ms/step - loss: 0.2803 - accuracy: 0.9060 - val_loss: 0.3386 - val_accuracy: 0.9041 - lr: 2.2500e-04\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9411\n",
      "Epoch 27: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 16s 215ms/step - loss: 0.1647 - accuracy: 0.9411 - val_loss: 0.1866 - val_accuracy: 0.9505 - lr: 6.7500e-05\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9606\n",
      "Epoch 28: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 16s 218ms/step - loss: 0.1236 - accuracy: 0.9606 - val_loss: 0.1701 - val_accuracy: 0.9545 - lr: 6.7500e-05\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9623\n",
      "Epoch 29: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 16s 213ms/step - loss: 0.1121 - accuracy: 0.9623 - val_loss: 0.2022 - val_accuracy: 0.9456 - lr: 6.7500e-05\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9661\n",
      "Epoch 30: val_loss did not improve from 0.13556\n",
      "74/74 [==============================] - 16s 219ms/step - loss: 0.0838 - accuracy: 0.9661 - val_loss: 0.1755 - val_accuracy: 0.9585 - lr: 6.7500e-05\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:34:16.264699Z",
     "start_time": "2024-07-25T22:34:16.258669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 30\n",
    "for layer in base_model.layers[-350:]:\n",
    "    layer.trainable = True"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:34:16.320037Z",
     "start_time": "2024-07-25T22:34:16.265253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000075), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb7 (Functional  (None, 7, 7, 2560)        64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2560)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               655616    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64794715 (247.17 MB)\n",
      "Trainable params: 57226444 (218.30 MB)\n",
      "Non-trainable params: 7568271 (28.87 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-25T22:34:16.320696Z"
    }
   },
   "cell_type": "code",
   "source": "history_75 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 33,
   "source": [
    "start_epoch = 35\n",
    "for layer in base_model.layers[-400:]:\n",
    "    layer.trainable = True"
   ],
   "id": "f24912d6c3aa128"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientB7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb7 (Functional  (None, 7, 7, 2560)        64097687  \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2560)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               327808    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64426914 (245.77 MB)\n",
      "Trainable params: 44827563 (171.00 MB)\n",
      "Non-trainable params: 19599351 (74.77 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 35,
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.00025), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "81ac6230c263bbc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.8822\n",
      "Epoch 26: val_loss did not improve from 0.15705\n",
      "380/380 [==============================] - 102s 230ms/step - loss: 0.2814 - accuracy: 0.8822 - val_loss: 0.1877 - val_accuracy: 0.9431 - lr: 2.5000e-04\n",
      "Epoch 27/35\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9062\n",
      "Epoch 27: val_loss did not improve from 0.15705\n",
      "380/380 [==============================] - 83s 219ms/step - loss: 0.2223 - accuracy: 0.9059 - val_loss: 0.2635 - val_accuracy: 0.9300 - lr: 2.5000e-04\n",
      "Epoch 28/35\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9258\n",
      "Epoch 28: val_loss improved from 0.15705 to 0.14297, saving model to Trained_Models/EfficientB7\n",
      "380/380 [==============================] - 125s 330ms/step - loss: 0.1747 - accuracy: 0.9258 - val_loss: 0.1430 - val_accuracy: 0.9544 - lr: 2.5000e-04\n",
      "Epoch 29/35\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9446\n",
      "Epoch 29: val_loss did not improve from 0.14297\n",
      "380/380 [==============================] - 84s 222ms/step - loss: 0.1390 - accuracy: 0.9446 - val_loss: 0.1954 - val_accuracy: 0.9414 - lr: 2.5000e-04\n",
      "Epoch 30/35\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9538\n",
      "Epoch 30: val_loss did not improve from 0.14297\n",
      "380/380 [==============================] - 84s 220ms/step - loss: 0.1198 - accuracy: 0.9538 - val_loss: 0.1621 - val_accuracy: 0.9542 - lr: 2.5000e-04\n",
      "Epoch 31/35\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9795\n",
      "Epoch 31: val_loss did not improve from 0.14297\n",
      "380/380 [==============================] - 85s 222ms/step - loss: 0.0569 - accuracy: 0.9795 - val_loss: 0.1712 - val_accuracy: 0.9700 - lr: 7.5000e-05\n",
      "Epoch 32/35\n",
      "227/380 [================>.............] - ETA: 25s - loss: 0.0284 - accuracy: 0.9905"
     ]
    }
   ],
   "execution_count": null,
   "source": "history_75 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "fd98979b64e68f4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:48:10.996689Z",
     "start_time": "2024-07-25T22:47:55.684198Z"
    }
   },
   "cell_type": "code",
   "source": "effb7_97 = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/EfficientB7_90.49\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:48:17.862311Z",
     "start_time": "2024-07-25T22:48:10.997720Z"
    }
   },
   "cell_type": "code",
   "source": "effb7_97.evaluate(test_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:48:13.389220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-25 18:48:13.444363: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 7s 138ms/step - loss: 0.3847 - accuracy: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3847275972366333, 0.9041420221328735]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
