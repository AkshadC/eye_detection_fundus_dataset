{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:33.354881Z",
     "start_time": "2024-07-29T18:45:31.407889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:45:31.568421: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 14:45:31.592807: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 14:45:31.592832: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 14:45:31.592856: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 14:45:31.597896: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 14:45:32.261169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:45:33.324576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.347206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.349090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.351077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:33.359121Z",
     "start_time": "2024-07-29T18:45:33.355724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "#Batching using prefetch\n",
    "train_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\""
   ],
   "id": "2bfc02fd3bd68fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Batching using prefetch\\ntrain_data_casted = train_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).shuffle(buffer_size = 1000).batch(batch_size = 32).prefetch(buffer_size = tf.data.AUTOTUNE)\\ntest_data_casted = test_data.map(map_func = preprocess_image, num_parallel_calls = tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:33.366552Z",
     "start_time": "2024-07-29T18:45:33.359631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fundus_train = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/train\"\n",
    "fundus_test = \"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/Dataset/split1/test\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n"
   ],
   "id": "76e3a5421f09f74d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:33.370829Z",
     "start_time": "2024-07-29T18:45:33.367116Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir(fundus_train))",
   "id": "1a2371451891c6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glaucoma', 'normal', 'cataract', 'diabetic_retinopathy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:33.373866Z",
     "start_time": "2024-07-29T18:45:33.371837Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_HEIGHT, IMG_WIDTH = 224, 224",
   "id": "1f94cba87987258",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:34.238555Z",
     "start_time": "2024-07-29T18:45:33.374362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_train,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    fundus_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "id": "348e18c639023b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 2361 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:45:33.430953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.433753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.435733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.559644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.561404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.562912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-29 14:45:33.564302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5955 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-29 14:45:33.702789: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 files belonging to 4 classes.\n",
      "Using 1011 files for validation.\n",
      "Found 845 files belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:34.241107Z",
     "start_time": "2024-07-29T18:45:34.239139Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "d09dab585b1ca859",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:34.248438Z",
     "start_time": "2024-07-29T18:45:34.241688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using tf prefetch dataset\n",
    "preprocess_input = tf.keras.applications.resnet_rs.preprocess_input"
   ],
   "id": "c66d836742f62b76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:34.276653Z",
     "start_time": "2024-07-29T18:45:34.249595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "val_datagen = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_datagen = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "id": "fe651f3421b86187",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:34.279427Z",
     "start_time": "2024-07-29T18:45:34.277305Z"
    }
   },
   "cell_type": "code",
   "source": "train_datagen",
   "id": "2d604d0924419863",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:36.411812Z",
     "start_time": "2024-07-29T18:45:34.353936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow.keras.applications as apps\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "base_model = apps.ResNetRS101(weights = 'imagenet', include_top = False, input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "base_model.trainable = False"
   ],
   "id": "541ea676b52829f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:36.416393Z",
     "start_time": "2024-07-29T18:45:36.412570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in base_model.layers:\n",
    "    print(f'Layer: {i.name}, {i.trainable}')"
   ],
   "id": "79db08db0282846b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_1, False\n",
      "Layer: rescaling, False\n",
      "Layer: normalization, False\n",
      "Layer: zero_padding2d, False\n",
      "Layer: stem_1_stem_conv_1, False\n",
      "Layer: stem_1_stem_batch_norm_1, False\n",
      "Layer: stem_1_stem_act_1, False\n",
      "Layer: stem_1_stem_conv_2, False\n",
      "Layer: stem_1_stem_batch_norm_2, False\n",
      "Layer: stem_1_stem_act_2, False\n",
      "Layer: stem_1_stem_conv_3, False\n",
      "Layer: stem_1_stem_batch_norm_3, False\n",
      "Layer: stem_1_stem_act_3, False\n",
      "Layer: zero_padding2d_1, False\n",
      "Layer: stem_1_stem_conv_4, False\n",
      "Layer: stem_1_stem_batch_norm_4, False\n",
      "Layer: stem_1_stem_act_4, False\n",
      "Layer: BlockGroup2__block_0__conv_1, False\n",
      "Layer: BlockGroup2__block_0_batch_norm_1, False\n",
      "Layer: BlockGroup2__block_0__act_1, False\n",
      "Layer: BlockGroup2__block_0__conv_2, False\n",
      "Layer: BlockGroup2__block_0__batch_norm_2, False\n",
      "Layer: BlockGroup2__block_0__act_2, False\n",
      "Layer: BlockGroup2__block_0__conv_3, False\n",
      "Layer: BlockGroup2__block_0__batch_norm_3, False\n",
      "Layer: BlockGroup2__block_0__se_se_squeeze, False\n",
      "Layer: BlockGroup2__block_0__se_se_reshape, False\n",
      "Layer: BlockGroup2__block_0__se_se_reduce, False\n",
      "Layer: BlockGroup2__block_0__se_se_expand, False\n",
      "Layer: BlockGroup2__block_0__projection_conv, False\n",
      "Layer: BlockGroup2__block_0__se_se_excite, False\n",
      "Layer: BlockGroup2__block_0__projection_batch_norm, False\n",
      "Layer: add, False\n",
      "Layer: BlockGroup2__block_0__output_act, False\n",
      "Layer: BlockGroup2__block_1__conv_1, False\n",
      "Layer: BlockGroup2__block_1_batch_norm_1, False\n",
      "Layer: BlockGroup2__block_1__act_1, False\n",
      "Layer: BlockGroup2__block_1__conv_2, False\n",
      "Layer: BlockGroup2__block_1__batch_norm_2, False\n",
      "Layer: BlockGroup2__block_1__act_2, False\n",
      "Layer: BlockGroup2__block_1__conv_3, False\n",
      "Layer: BlockGroup2__block_1__batch_norm_3, False\n",
      "Layer: BlockGroup2__block_1__se_se_squeeze, False\n",
      "Layer: BlockGroup2__block_1__se_se_reshape, False\n",
      "Layer: BlockGroup2__block_1__se_se_reduce, False\n",
      "Layer: BlockGroup2__block_1__se_se_expand, False\n",
      "Layer: BlockGroup2__block_1__se_se_excite, False\n",
      "Layer: add_1, False\n",
      "Layer: BlockGroup2__block_1__output_act, False\n",
      "Layer: BlockGroup2__block_2__conv_1, False\n",
      "Layer: BlockGroup2__block_2_batch_norm_1, False\n",
      "Layer: BlockGroup2__block_2__act_1, False\n",
      "Layer: BlockGroup2__block_2__conv_2, False\n",
      "Layer: BlockGroup2__block_2__batch_norm_2, False\n",
      "Layer: BlockGroup2__block_2__act_2, False\n",
      "Layer: BlockGroup2__block_2__conv_3, False\n",
      "Layer: BlockGroup2__block_2__batch_norm_3, False\n",
      "Layer: BlockGroup2__block_2__se_se_squeeze, False\n",
      "Layer: BlockGroup2__block_2__se_se_reshape, False\n",
      "Layer: BlockGroup2__block_2__se_se_reduce, False\n",
      "Layer: BlockGroup2__block_2__se_se_expand, False\n",
      "Layer: BlockGroup2__block_2__se_se_excite, False\n",
      "Layer: add_2, False\n",
      "Layer: BlockGroup2__block_2__output_act, False\n",
      "Layer: BlockGroup3__block_0__conv_1, False\n",
      "Layer: BlockGroup3__block_0_batch_norm_1, False\n",
      "Layer: BlockGroup3__block_0__act_1, False\n",
      "Layer: zero_padding2d_2, False\n",
      "Layer: BlockGroup3__block_0__conv_2, False\n",
      "Layer: BlockGroup3__block_0__batch_norm_2, False\n",
      "Layer: BlockGroup3__block_0__act_2, False\n",
      "Layer: BlockGroup3__block_0__conv_3, False\n",
      "Layer: BlockGroup3__block_0__batch_norm_3, False\n",
      "Layer: BlockGroup3__block_0__se_se_squeeze, False\n",
      "Layer: BlockGroup3__block_0__se_se_reshape, False\n",
      "Layer: BlockGroup3__block_0__se_se_reduce, False\n",
      "Layer: BlockGroup3__block_0__projection_pooling, False\n",
      "Layer: BlockGroup3__block_0__se_se_expand, False\n",
      "Layer: BlockGroup3__block_0__projection_conv, False\n",
      "Layer: BlockGroup3__block_0__se_se_excite, False\n",
      "Layer: BlockGroup3__block_0__projection_batch_norm, False\n",
      "Layer: add_3, False\n",
      "Layer: BlockGroup3__block_0__output_act, False\n",
      "Layer: BlockGroup3__block_1__conv_1, False\n",
      "Layer: BlockGroup3__block_1_batch_norm_1, False\n",
      "Layer: BlockGroup3__block_1__act_1, False\n",
      "Layer: BlockGroup3__block_1__conv_2, False\n",
      "Layer: BlockGroup3__block_1__batch_norm_2, False\n",
      "Layer: BlockGroup3__block_1__act_2, False\n",
      "Layer: BlockGroup3__block_1__conv_3, False\n",
      "Layer: BlockGroup3__block_1__batch_norm_3, False\n",
      "Layer: BlockGroup3__block_1__se_se_squeeze, False\n",
      "Layer: BlockGroup3__block_1__se_se_reshape, False\n",
      "Layer: BlockGroup3__block_1__se_se_reduce, False\n",
      "Layer: BlockGroup3__block_1__se_se_expand, False\n",
      "Layer: BlockGroup3__block_1__se_se_excite, False\n",
      "Layer: add_4, False\n",
      "Layer: BlockGroup3__block_1__output_act, False\n",
      "Layer: BlockGroup3__block_2__conv_1, False\n",
      "Layer: BlockGroup3__block_2_batch_norm_1, False\n",
      "Layer: BlockGroup3__block_2__act_1, False\n",
      "Layer: BlockGroup3__block_2__conv_2, False\n",
      "Layer: BlockGroup3__block_2__batch_norm_2, False\n",
      "Layer: BlockGroup3__block_2__act_2, False\n",
      "Layer: BlockGroup3__block_2__conv_3, False\n",
      "Layer: BlockGroup3__block_2__batch_norm_3, False\n",
      "Layer: BlockGroup3__block_2__se_se_squeeze, False\n",
      "Layer: BlockGroup3__block_2__se_se_reshape, False\n",
      "Layer: BlockGroup3__block_2__se_se_reduce, False\n",
      "Layer: BlockGroup3__block_2__se_se_expand, False\n",
      "Layer: BlockGroup3__block_2__se_se_excite, False\n",
      "Layer: add_5, False\n",
      "Layer: BlockGroup3__block_2__output_act, False\n",
      "Layer: BlockGroup3__block_3__conv_1, False\n",
      "Layer: BlockGroup3__block_3_batch_norm_1, False\n",
      "Layer: BlockGroup3__block_3__act_1, False\n",
      "Layer: BlockGroup3__block_3__conv_2, False\n",
      "Layer: BlockGroup3__block_3__batch_norm_2, False\n",
      "Layer: BlockGroup3__block_3__act_2, False\n",
      "Layer: BlockGroup3__block_3__conv_3, False\n",
      "Layer: BlockGroup3__block_3__batch_norm_3, False\n",
      "Layer: BlockGroup3__block_3__se_se_squeeze, False\n",
      "Layer: BlockGroup3__block_3__se_se_reshape, False\n",
      "Layer: BlockGroup3__block_3__se_se_reduce, False\n",
      "Layer: BlockGroup3__block_3__se_se_expand, False\n",
      "Layer: BlockGroup3__block_3__se_se_excite, False\n",
      "Layer: add_6, False\n",
      "Layer: BlockGroup3__block_3__output_act, False\n",
      "Layer: BlockGroup4__block_0__conv_1, False\n",
      "Layer: BlockGroup4__block_0_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_0__act_1, False\n",
      "Layer: zero_padding2d_3, False\n",
      "Layer: BlockGroup4__block_0__conv_2, False\n",
      "Layer: BlockGroup4__block_0__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_0__act_2, False\n",
      "Layer: BlockGroup4__block_0__conv_3, False\n",
      "Layer: BlockGroup4__block_0__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_0__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_0__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_0__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_0__projection_pooling, False\n",
      "Layer: BlockGroup4__block_0__se_se_expand, False\n",
      "Layer: BlockGroup4__block_0__projection_conv, False\n",
      "Layer: BlockGroup4__block_0__se_se_excite, False\n",
      "Layer: BlockGroup4__block_0__projection_batch_norm, False\n",
      "Layer: add_7, False\n",
      "Layer: BlockGroup4__block_0__output_act, False\n",
      "Layer: BlockGroup4__block_1__conv_1, False\n",
      "Layer: BlockGroup4__block_1_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_1__act_1, False\n",
      "Layer: BlockGroup4__block_1__conv_2, False\n",
      "Layer: BlockGroup4__block_1__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_1__act_2, False\n",
      "Layer: BlockGroup4__block_1__conv_3, False\n",
      "Layer: BlockGroup4__block_1__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_1__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_1__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_1__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_1__se_se_expand, False\n",
      "Layer: BlockGroup4__block_1__se_se_excite, False\n",
      "Layer: add_8, False\n",
      "Layer: BlockGroup4__block_1__output_act, False\n",
      "Layer: BlockGroup4__block_2__conv_1, False\n",
      "Layer: BlockGroup4__block_2_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_2__act_1, False\n",
      "Layer: BlockGroup4__block_2__conv_2, False\n",
      "Layer: BlockGroup4__block_2__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_2__act_2, False\n",
      "Layer: BlockGroup4__block_2__conv_3, False\n",
      "Layer: BlockGroup4__block_2__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_2__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_2__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_2__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_2__se_se_expand, False\n",
      "Layer: BlockGroup4__block_2__se_se_excite, False\n",
      "Layer: add_9, False\n",
      "Layer: BlockGroup4__block_2__output_act, False\n",
      "Layer: BlockGroup4__block_3__conv_1, False\n",
      "Layer: BlockGroup4__block_3_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_3__act_1, False\n",
      "Layer: BlockGroup4__block_3__conv_2, False\n",
      "Layer: BlockGroup4__block_3__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_3__act_2, False\n",
      "Layer: BlockGroup4__block_3__conv_3, False\n",
      "Layer: BlockGroup4__block_3__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_3__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_3__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_3__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_3__se_se_expand, False\n",
      "Layer: BlockGroup4__block_3__se_se_excite, False\n",
      "Layer: add_10, False\n",
      "Layer: BlockGroup4__block_3__output_act, False\n",
      "Layer: BlockGroup4__block_4__conv_1, False\n",
      "Layer: BlockGroup4__block_4_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_4__act_1, False\n",
      "Layer: BlockGroup4__block_4__conv_2, False\n",
      "Layer: BlockGroup4__block_4__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_4__act_2, False\n",
      "Layer: BlockGroup4__block_4__conv_3, False\n",
      "Layer: BlockGroup4__block_4__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_4__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_4__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_4__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_4__se_se_expand, False\n",
      "Layer: BlockGroup4__block_4__se_se_excite, False\n",
      "Layer: add_11, False\n",
      "Layer: BlockGroup4__block_4__output_act, False\n",
      "Layer: BlockGroup4__block_5__conv_1, False\n",
      "Layer: BlockGroup4__block_5_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_5__act_1, False\n",
      "Layer: BlockGroup4__block_5__conv_2, False\n",
      "Layer: BlockGroup4__block_5__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_5__act_2, False\n",
      "Layer: BlockGroup4__block_5__conv_3, False\n",
      "Layer: BlockGroup4__block_5__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_5__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_5__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_5__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_5__se_se_expand, False\n",
      "Layer: BlockGroup4__block_5__se_se_excite, False\n",
      "Layer: add_12, False\n",
      "Layer: BlockGroup4__block_5__output_act, False\n",
      "Layer: BlockGroup4__block_6__conv_1, False\n",
      "Layer: BlockGroup4__block_6_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_6__act_1, False\n",
      "Layer: BlockGroup4__block_6__conv_2, False\n",
      "Layer: BlockGroup4__block_6__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_6__act_2, False\n",
      "Layer: BlockGroup4__block_6__conv_3, False\n",
      "Layer: BlockGroup4__block_6__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_6__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_6__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_6__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_6__se_se_expand, False\n",
      "Layer: BlockGroup4__block_6__se_se_excite, False\n",
      "Layer: add_13, False\n",
      "Layer: BlockGroup4__block_6__output_act, False\n",
      "Layer: BlockGroup4__block_7__conv_1, False\n",
      "Layer: BlockGroup4__block_7_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_7__act_1, False\n",
      "Layer: BlockGroup4__block_7__conv_2, False\n",
      "Layer: BlockGroup4__block_7__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_7__act_2, False\n",
      "Layer: BlockGroup4__block_7__conv_3, False\n",
      "Layer: BlockGroup4__block_7__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_7__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_7__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_7__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_7__se_se_expand, False\n",
      "Layer: BlockGroup4__block_7__se_se_excite, False\n",
      "Layer: add_14, False\n",
      "Layer: BlockGroup4__block_7__output_act, False\n",
      "Layer: BlockGroup4__block_8__conv_1, False\n",
      "Layer: BlockGroup4__block_8_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_8__act_1, False\n",
      "Layer: BlockGroup4__block_8__conv_2, False\n",
      "Layer: BlockGroup4__block_8__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_8__act_2, False\n",
      "Layer: BlockGroup4__block_8__conv_3, False\n",
      "Layer: BlockGroup4__block_8__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_8__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_8__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_8__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_8__se_se_expand, False\n",
      "Layer: BlockGroup4__block_8__se_se_excite, False\n",
      "Layer: add_15, False\n",
      "Layer: BlockGroup4__block_8__output_act, False\n",
      "Layer: BlockGroup4__block_9__conv_1, False\n",
      "Layer: BlockGroup4__block_9_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_9__act_1, False\n",
      "Layer: BlockGroup4__block_9__conv_2, False\n",
      "Layer: BlockGroup4__block_9__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_9__act_2, False\n",
      "Layer: BlockGroup4__block_9__conv_3, False\n",
      "Layer: BlockGroup4__block_9__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_9__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_9__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_9__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_9__se_se_expand, False\n",
      "Layer: BlockGroup4__block_9__se_se_excite, False\n",
      "Layer: add_16, False\n",
      "Layer: BlockGroup4__block_9__output_act, False\n",
      "Layer: BlockGroup4__block_10__conv_1, False\n",
      "Layer: BlockGroup4__block_10_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_10__act_1, False\n",
      "Layer: BlockGroup4__block_10__conv_2, False\n",
      "Layer: BlockGroup4__block_10__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_10__act_2, False\n",
      "Layer: BlockGroup4__block_10__conv_3, False\n",
      "Layer: BlockGroup4__block_10__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_10__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_10__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_10__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_10__se_se_expand, False\n",
      "Layer: BlockGroup4__block_10__se_se_excite, False\n",
      "Layer: add_17, False\n",
      "Layer: BlockGroup4__block_10__output_act, False\n",
      "Layer: BlockGroup4__block_11__conv_1, False\n",
      "Layer: BlockGroup4__block_11_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_11__act_1, False\n",
      "Layer: BlockGroup4__block_11__conv_2, False\n",
      "Layer: BlockGroup4__block_11__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_11__act_2, False\n",
      "Layer: BlockGroup4__block_11__conv_3, False\n",
      "Layer: BlockGroup4__block_11__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_11__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_11__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_11__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_11__se_se_expand, False\n",
      "Layer: BlockGroup4__block_11__se_se_excite, False\n",
      "Layer: add_18, False\n",
      "Layer: BlockGroup4__block_11__output_act, False\n",
      "Layer: BlockGroup4__block_12__conv_1, False\n",
      "Layer: BlockGroup4__block_12_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_12__act_1, False\n",
      "Layer: BlockGroup4__block_12__conv_2, False\n",
      "Layer: BlockGroup4__block_12__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_12__act_2, False\n",
      "Layer: BlockGroup4__block_12__conv_3, False\n",
      "Layer: BlockGroup4__block_12__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_12__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_12__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_12__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_12__se_se_expand, False\n",
      "Layer: BlockGroup4__block_12__se_se_excite, False\n",
      "Layer: add_19, False\n",
      "Layer: BlockGroup4__block_12__output_act, False\n",
      "Layer: BlockGroup4__block_13__conv_1, False\n",
      "Layer: BlockGroup4__block_13_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_13__act_1, False\n",
      "Layer: BlockGroup4__block_13__conv_2, False\n",
      "Layer: BlockGroup4__block_13__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_13__act_2, False\n",
      "Layer: BlockGroup4__block_13__conv_3, False\n",
      "Layer: BlockGroup4__block_13__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_13__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_13__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_13__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_13__se_se_expand, False\n",
      "Layer: BlockGroup4__block_13__se_se_excite, False\n",
      "Layer: add_20, False\n",
      "Layer: BlockGroup4__block_13__output_act, False\n",
      "Layer: BlockGroup4__block_14__conv_1, False\n",
      "Layer: BlockGroup4__block_14_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_14__act_1, False\n",
      "Layer: BlockGroup4__block_14__conv_2, False\n",
      "Layer: BlockGroup4__block_14__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_14__act_2, False\n",
      "Layer: BlockGroup4__block_14__conv_3, False\n",
      "Layer: BlockGroup4__block_14__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_14__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_14__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_14__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_14__se_se_expand, False\n",
      "Layer: BlockGroup4__block_14__se_se_excite, False\n",
      "Layer: add_21, False\n",
      "Layer: BlockGroup4__block_14__output_act, False\n",
      "Layer: BlockGroup4__block_15__conv_1, False\n",
      "Layer: BlockGroup4__block_15_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_15__act_1, False\n",
      "Layer: BlockGroup4__block_15__conv_2, False\n",
      "Layer: BlockGroup4__block_15__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_15__act_2, False\n",
      "Layer: BlockGroup4__block_15__conv_3, False\n",
      "Layer: BlockGroup4__block_15__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_15__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_15__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_15__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_15__se_se_expand, False\n",
      "Layer: BlockGroup4__block_15__se_se_excite, False\n",
      "Layer: add_22, False\n",
      "Layer: BlockGroup4__block_15__output_act, False\n",
      "Layer: BlockGroup4__block_16__conv_1, False\n",
      "Layer: BlockGroup4__block_16_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_16__act_1, False\n",
      "Layer: BlockGroup4__block_16__conv_2, False\n",
      "Layer: BlockGroup4__block_16__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_16__act_2, False\n",
      "Layer: BlockGroup4__block_16__conv_3, False\n",
      "Layer: BlockGroup4__block_16__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_16__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_16__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_16__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_16__se_se_expand, False\n",
      "Layer: BlockGroup4__block_16__se_se_excite, False\n",
      "Layer: add_23, False\n",
      "Layer: BlockGroup4__block_16__output_act, False\n",
      "Layer: BlockGroup4__block_17__conv_1, False\n",
      "Layer: BlockGroup4__block_17_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_17__act_1, False\n",
      "Layer: BlockGroup4__block_17__conv_2, False\n",
      "Layer: BlockGroup4__block_17__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_17__act_2, False\n",
      "Layer: BlockGroup4__block_17__conv_3, False\n",
      "Layer: BlockGroup4__block_17__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_17__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_17__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_17__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_17__se_se_expand, False\n",
      "Layer: BlockGroup4__block_17__se_se_excite, False\n",
      "Layer: add_24, False\n",
      "Layer: BlockGroup4__block_17__output_act, False\n",
      "Layer: BlockGroup4__block_18__conv_1, False\n",
      "Layer: BlockGroup4__block_18_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_18__act_1, False\n",
      "Layer: BlockGroup4__block_18__conv_2, False\n",
      "Layer: BlockGroup4__block_18__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_18__act_2, False\n",
      "Layer: BlockGroup4__block_18__conv_3, False\n",
      "Layer: BlockGroup4__block_18__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_18__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_18__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_18__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_18__se_se_expand, False\n",
      "Layer: BlockGroup4__block_18__se_se_excite, False\n",
      "Layer: add_25, False\n",
      "Layer: BlockGroup4__block_18__output_act, False\n",
      "Layer: BlockGroup4__block_19__conv_1, False\n",
      "Layer: BlockGroup4__block_19_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_19__act_1, False\n",
      "Layer: BlockGroup4__block_19__conv_2, False\n",
      "Layer: BlockGroup4__block_19__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_19__act_2, False\n",
      "Layer: BlockGroup4__block_19__conv_3, False\n",
      "Layer: BlockGroup4__block_19__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_19__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_19__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_19__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_19__se_se_expand, False\n",
      "Layer: BlockGroup4__block_19__se_se_excite, False\n",
      "Layer: add_26, False\n",
      "Layer: BlockGroup4__block_19__output_act, False\n",
      "Layer: BlockGroup4__block_20__conv_1, False\n",
      "Layer: BlockGroup4__block_20_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_20__act_1, False\n",
      "Layer: BlockGroup4__block_20__conv_2, False\n",
      "Layer: BlockGroup4__block_20__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_20__act_2, False\n",
      "Layer: BlockGroup4__block_20__conv_3, False\n",
      "Layer: BlockGroup4__block_20__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_20__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_20__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_20__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_20__se_se_expand, False\n",
      "Layer: BlockGroup4__block_20__se_se_excite, False\n",
      "Layer: add_27, False\n",
      "Layer: BlockGroup4__block_20__output_act, False\n",
      "Layer: BlockGroup4__block_21__conv_1, False\n",
      "Layer: BlockGroup4__block_21_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_21__act_1, False\n",
      "Layer: BlockGroup4__block_21__conv_2, False\n",
      "Layer: BlockGroup4__block_21__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_21__act_2, False\n",
      "Layer: BlockGroup4__block_21__conv_3, False\n",
      "Layer: BlockGroup4__block_21__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_21__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_21__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_21__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_21__se_se_expand, False\n",
      "Layer: BlockGroup4__block_21__se_se_excite, False\n",
      "Layer: add_28, False\n",
      "Layer: BlockGroup4__block_21__output_act, False\n",
      "Layer: BlockGroup4__block_22__conv_1, False\n",
      "Layer: BlockGroup4__block_22_batch_norm_1, False\n",
      "Layer: BlockGroup4__block_22__act_1, False\n",
      "Layer: BlockGroup4__block_22__conv_2, False\n",
      "Layer: BlockGroup4__block_22__batch_norm_2, False\n",
      "Layer: BlockGroup4__block_22__act_2, False\n",
      "Layer: BlockGroup4__block_22__conv_3, False\n",
      "Layer: BlockGroup4__block_22__batch_norm_3, False\n",
      "Layer: BlockGroup4__block_22__se_se_squeeze, False\n",
      "Layer: BlockGroup4__block_22__se_se_reshape, False\n",
      "Layer: BlockGroup4__block_22__se_se_reduce, False\n",
      "Layer: BlockGroup4__block_22__se_se_expand, False\n",
      "Layer: BlockGroup4__block_22__se_se_excite, False\n",
      "Layer: add_29, False\n",
      "Layer: BlockGroup4__block_22__output_act, False\n",
      "Layer: BlockGroup5__block_0__conv_1, False\n",
      "Layer: BlockGroup5__block_0_batch_norm_1, False\n",
      "Layer: BlockGroup5__block_0__act_1, False\n",
      "Layer: zero_padding2d_4, False\n",
      "Layer: BlockGroup5__block_0__conv_2, False\n",
      "Layer: BlockGroup5__block_0__batch_norm_2, False\n",
      "Layer: BlockGroup5__block_0__act_2, False\n",
      "Layer: BlockGroup5__block_0__conv_3, False\n",
      "Layer: BlockGroup5__block_0__batch_norm_3, False\n",
      "Layer: BlockGroup5__block_0__se_se_squeeze, False\n",
      "Layer: BlockGroup5__block_0__se_se_reshape, False\n",
      "Layer: BlockGroup5__block_0__se_se_reduce, False\n",
      "Layer: BlockGroup5__block_0__projection_pooling, False\n",
      "Layer: BlockGroup5__block_0__se_se_expand, False\n",
      "Layer: BlockGroup5__block_0__projection_conv, False\n",
      "Layer: BlockGroup5__block_0__se_se_excite, False\n",
      "Layer: BlockGroup5__block_0__projection_batch_norm, False\n",
      "Layer: add_30, False\n",
      "Layer: BlockGroup5__block_0__output_act, False\n",
      "Layer: BlockGroup5__block_1__conv_1, False\n",
      "Layer: BlockGroup5__block_1_batch_norm_1, False\n",
      "Layer: BlockGroup5__block_1__act_1, False\n",
      "Layer: BlockGroup5__block_1__conv_2, False\n",
      "Layer: BlockGroup5__block_1__batch_norm_2, False\n",
      "Layer: BlockGroup5__block_1__act_2, False\n",
      "Layer: BlockGroup5__block_1__conv_3, False\n",
      "Layer: BlockGroup5__block_1__batch_norm_3, False\n",
      "Layer: BlockGroup5__block_1__se_se_squeeze, False\n",
      "Layer: BlockGroup5__block_1__se_se_reshape, False\n",
      "Layer: BlockGroup5__block_1__se_se_reduce, False\n",
      "Layer: BlockGroup5__block_1__se_se_expand, False\n",
      "Layer: BlockGroup5__block_1__se_se_excite, False\n",
      "Layer: add_31, False\n",
      "Layer: BlockGroup5__block_1__output_act, False\n",
      "Layer: BlockGroup5__block_2__conv_1, False\n",
      "Layer: BlockGroup5__block_2_batch_norm_1, False\n",
      "Layer: BlockGroup5__block_2__act_1, False\n",
      "Layer: BlockGroup5__block_2__conv_2, False\n",
      "Layer: BlockGroup5__block_2__batch_norm_2, False\n",
      "Layer: BlockGroup5__block_2__act_2, False\n",
      "Layer: BlockGroup5__block_2__conv_3, False\n",
      "Layer: BlockGroup5__block_2__batch_norm_3, False\n",
      "Layer: BlockGroup5__block_2__se_se_squeeze, False\n",
      "Layer: BlockGroup5__block_2__se_se_reshape, False\n",
      "Layer: BlockGroup5__block_2__se_se_reduce, False\n",
      "Layer: BlockGroup5__block_2__se_se_expand, False\n",
      "Layer: BlockGroup5__block_2__se_se_excite, False\n",
      "Layer: add_32, False\n",
      "Layer: BlockGroup5__block_2__output_act, False\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:36.423673Z",
     "start_time": "2024-07-29T18:45:36.416984Z"
    }
   },
   "cell_type": "code",
   "source": "len(base_model.layers)",
   "id": "4d5901824515235e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:36.512258Z",
     "start_time": "2024-07-29T18:45:36.509186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "No_of_classes = len(os.listdir(fundus_train))\n",
    "No_of_classes"
   ],
   "id": "c24aa2a52df99eca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:37.241414Z",
     "start_time": "2024-07-29T18:45:37.235754Z"
    }
   },
   "cell_type": "code",
   "source": "aug_layer = utils.return_data_aug_layer_for_eff_net()",
   "id": "e1fbc17ac5520d23",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:38.490911Z",
     "start_time": "2024-07-29T18:45:37.712973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, GlobalAvgPool2D, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3), name = 'Input_layer')\n",
    "x = aug_layer(inputs)\n",
    "#x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "x = base_model(x, training = False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "Outputs = Dense(No_of_classes, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model_1 = Model(inputs, Outputs, name = 'Resnet_rs_101')\n",
    "\n",
    "model_1.summary()"
   ],
   "id": "f8314db62f9c88ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_rs_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet-rs-101 (Functional)  (None, 7, 7, 2048)        61675296  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62909156 (239.98 MB)\n",
      "Trainable params: 1227844 (4.68 MB)\n",
      "Non-trainable params: 61681312 (235.30 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:39.390739Z",
     "start_time": "2024-07-29T18:45:39.388694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_1chkpt = ModelCheckpoint(filepath = os.path.join('Trained_Models',model_1.name), save_weights_only = False, save_best_only = True, verbose = 1)"
   ],
   "id": "a30cb8302eb2cd34",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:40.368160Z",
     "start_time": "2024-07-29T18:45:40.365884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.3, patience=3) "
   ],
   "id": "48463ce3a6a20776",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:45:41.129932Z",
     "start_time": "2024-07-29T18:45:41.116185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model compilation\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])"
   ],
   "id": "18264d9b28fa328f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:57:03.091924Z",
     "start_time": "2024-07-29T18:45:44.396554Z"
    }
   },
   "cell_type": "code",
   "source": "history_1 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = 20, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "85e1fa6dc6835069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:45:49.448670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-07-29 14:45:49.496274: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-29 14:45:51.064587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x758ff8003870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-29 14:45:51.064615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-29 14:45:51.070287: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-29 14:45:51.128576: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 13.0940 - accuracy: 0.6099\n",
      "Epoch 1: val_loss improved from inf to 10.46431, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 63s 762ms/step - loss: 13.0940 - accuracy: 0.6099 - val_loss: 10.4643 - val_accuracy: 0.6973 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.9376 - accuracy: 0.7522\n",
      "Epoch 2: val_loss improved from 10.46431 to 5.93901, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 47s 630ms/step - loss: 7.9376 - accuracy: 0.7522 - val_loss: 5.9390 - val_accuracy: 0.9456 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.7237 - accuracy: 0.7738\n",
      "Epoch 3: val_loss improved from 5.93901 to 3.81777, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 47s 636ms/step - loss: 4.7237 - accuracy: 0.7738 - val_loss: 3.8178 - val_accuracy: 0.8259 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 3.0131 - accuracy: 0.7785\n",
      "Epoch 4: val_loss improved from 3.81777 to 2.28677, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 45s 607ms/step - loss: 3.0131 - accuracy: 0.7785 - val_loss: 2.2868 - val_accuracy: 0.9456 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.0868 - accuracy: 0.7997\n",
      "Epoch 5: val_loss improved from 2.28677 to 1.93637, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 45s 601ms/step - loss: 2.0868 - accuracy: 0.7997 - val_loss: 1.9364 - val_accuracy: 0.8516 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 0.8056\n",
      "Epoch 6: val_loss improved from 1.93637 to 1.36897, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 43s 580ms/step - loss: 1.6447 - accuracy: 0.8056 - val_loss: 1.3690 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.3419 - accuracy: 0.8039\n",
      "Epoch 7: val_loss improved from 1.36897 to 1.01529, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 42s 567ms/step - loss: 1.3419 - accuracy: 0.8039 - val_loss: 1.0153 - val_accuracy: 0.9446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2292 - accuracy: 0.7886\n",
      "Epoch 8: val_loss improved from 1.01529 to 0.93636, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 42s 561ms/step - loss: 1.2292 - accuracy: 0.7886 - val_loss: 0.9364 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1557 - accuracy: 0.7984\n",
      "Epoch 9: val_loss did not improve from 0.93636\n",
      "74/74 [==============================] - 21s 273ms/step - loss: 1.1557 - accuracy: 0.7984 - val_loss: 1.6771 - val_accuracy: 0.4085 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0911 - accuracy: 0.7878\n",
      "Epoch 10: val_loss did not improve from 0.93636\n",
      "74/74 [==============================] - 20s 269ms/step - loss: 1.0911 - accuracy: 0.7878 - val_loss: 1.3049 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.7971\n",
      "Epoch 11: val_loss did not improve from 0.93636\n",
      "74/74 [==============================] - 22s 289ms/step - loss: 1.0028 - accuracy: 0.7971 - val_loss: 1.2821 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.8230\n",
      "Epoch 12: val_loss improved from 0.93636 to 0.73376, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 45s 605ms/step - loss: 0.9156 - accuracy: 0.8230 - val_loss: 0.7338 - val_accuracy: 0.9644 - lr: 3.0000e-04\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8006 - accuracy: 0.8433\n",
      "Epoch 13: val_loss did not improve from 0.73376\n",
      "74/74 [==============================] - 26s 347ms/step - loss: 0.8006 - accuracy: 0.8433 - val_loss: 0.7811 - val_accuracy: 0.9050 - lr: 3.0000e-04\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.8446\n",
      "Epoch 14: val_loss did not improve from 0.73376\n",
      "74/74 [==============================] - 22s 294ms/step - loss: 0.7381 - accuracy: 0.8446 - val_loss: 0.7838 - val_accuracy: 0.9050 - lr: 3.0000e-04\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.8213\n",
      "Epoch 15: val_loss improved from 0.73376 to 0.57619, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 39s 521ms/step - loss: 0.7708 - accuracy: 0.8213 - val_loss: 0.5762 - val_accuracy: 0.9486 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.8513\n",
      "Epoch 16: val_loss improved from 0.57619 to 0.55286, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 40s 541ms/step - loss: 0.6965 - accuracy: 0.8513 - val_loss: 0.5529 - val_accuracy: 0.9407 - lr: 3.0000e-04\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.8585\n",
      "Epoch 17: val_loss did not improve from 0.55286\n",
      "74/74 [==============================] - 16s 217ms/step - loss: 0.6561 - accuracy: 0.8585 - val_loss: 0.7053 - val_accuracy: 0.8536 - lr: 3.0000e-04\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.8454\n",
      "Epoch 18: val_loss did not improve from 0.55286\n",
      "74/74 [==============================] - 19s 251ms/step - loss: 0.6778 - accuracy: 0.8454 - val_loss: 0.7070 - val_accuracy: 0.8576 - lr: 3.0000e-04\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.8407\n",
      "Epoch 19: val_loss did not improve from 0.55286\n",
      "74/74 [==============================] - 17s 226ms/step - loss: 0.6997 - accuracy: 0.8407 - val_loss: 0.6988 - val_accuracy: 0.8309 - lr: 3.0000e-04\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.8619\n",
      "Epoch 20: val_loss did not improve from 0.55286\n",
      "74/74 [==============================] - 19s 256ms/step - loss: 0.6472 - accuracy: 0.8619 - val_loss: 0.6214 - val_accuracy: 0.8684 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:57:05.206578Z",
     "start_time": "2024-07-29T18:57:03.092633Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "eb9cc0053cd28662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 78ms/step - loss: 0.8670 - accuracy: 0.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8670157790184021, 0.778698205947876]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:19:01.029710Z",
     "start_time": "2024-07-29T18:19:01.022713Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.trainable = True",
   "id": "9b7e0fe022b2e5ad",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:19:01.041552Z",
     "start_time": "2024-07-29T18:19:01.030184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers[:-25]:\n",
    "    layer.trainable = False"
   ],
   "id": "144c133d132993be",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:19:01.046545Z",
     "start_time": "2024-07-29T18:19:01.042145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ],
   "id": "a853d58f3af9fa71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:19:01.078914Z",
     "start_time": "2024-07-29T18:19:01.047435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 10\n",
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "7233597bf79998e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_rs_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet-rs-101 (Functional)  (None, 7, 7, 2048)        61675296  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62909156 (239.98 MB)\n",
      "Trainable params: 10942532 (41.74 MB)\n",
      "Non-trainable params: 51966624 (198.24 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:22:04.281284Z",
     "start_time": "2024-07-29T18:19:01.079553Z"
    }
   },
   "cell_type": "code",
   "source": "history_50 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "eeb24a49a8759ba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8134 - accuracy: 0.8513\n",
      "Epoch 11: val_loss improved from 0.69015 to 0.59161, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 33s 374ms/step - loss: 0.8134 - accuracy: 0.8513 - val_loss: 0.5916 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.8645\n",
      "Epoch 12: val_loss did not improve from 0.59161\n",
      "74/74 [==============================] - 9s 119ms/step - loss: 0.6325 - accuracy: 0.8645 - val_loss: 1.8722 - val_accuracy: 0.2740 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.8755\n",
      "Epoch 13: val_loss did not improve from 0.59161\n",
      "74/74 [==============================] - 9s 119ms/step - loss: 0.5890 - accuracy: 0.8755 - val_loss: 0.7865 - val_accuracy: 0.8229 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.8941\n",
      "Epoch 14: val_loss did not improve from 0.59161\n",
      "74/74 [==============================] - 9s 119ms/step - loss: 0.5366 - accuracy: 0.8941 - val_loss: 0.7980 - val_accuracy: 0.8378 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.9284\n",
      "Epoch 15: val_loss improved from 0.59161 to 0.44885, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 26s 357ms/step - loss: 0.4109 - accuracy: 0.9284 - val_loss: 0.4488 - val_accuracy: 0.9505 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.9496\n",
      "Epoch 16: val_loss improved from 0.44885 to 0.32038, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 26s 348ms/step - loss: 0.2945 - accuracy: 0.9496 - val_loss: 0.3204 - val_accuracy: 0.9505 - lr: 3.0000e-04\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9445\n",
      "Epoch 17: val_loss improved from 0.32038 to 0.23164, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 26s 355ms/step - loss: 0.2763 - accuracy: 0.9445 - val_loss: 0.2316 - val_accuracy: 0.9594 - lr: 3.0000e-04\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9648\n",
      "Epoch 18: val_loss did not improve from 0.23164\n",
      "74/74 [==============================] - 9s 120ms/step - loss: 0.2296 - accuracy: 0.9648 - val_loss: 0.3107 - val_accuracy: 0.9397 - lr: 3.0000e-04\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9623\n",
      "Epoch 19: val_loss did not improve from 0.23164\n",
      "74/74 [==============================] - 9s 120ms/step - loss: 0.2323 - accuracy: 0.9623 - val_loss: 0.3425 - val_accuracy: 0.9110 - lr: 3.0000e-04\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.9661\n",
      "Epoch 20: val_loss improved from 0.23164 to 0.19967, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 26s 352ms/step - loss: 0.2104 - accuracy: 0.9661 - val_loss: 0.1997 - val_accuracy: 0.9614 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:57:26.376997Z",
     "start_time": "2024-07-29T18:57:24.615658Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "76e9cd11a6024452",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 63ms/step - loss: 0.8670 - accuracy: 0.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8670157790184021, 0.778698205947876]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:58:17.811650Z",
     "start_time": "2024-07-29T18:58:17.808992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 20\n",
    "for layer in base_model.layers[-25:]:\n",
    "    layer.trainable = True"
   ],
   "id": "6a7cd8da92ae1b49",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:58:19.328146Z",
     "start_time": "2024-07-29T18:58:19.280930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0003), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "1e494e7e29768448",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_rs_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet-rs-101 (Functional)  (None, 7, 7, 2048)        61675296  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62909156 (239.98 MB)\n",
      "Trainable params: 1227844 (4.68 MB)\n",
      "Non-trainable params: 61681312 (235.30 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:02:10.697769Z",
     "start_time": "2024-07-29T18:58:37.204457Z"
    }
   },
   "cell_type": "code",
   "source": "history_100 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "81d7f639996a2cff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.8488\n",
      "Epoch 21: val_loss did not improve from 0.55286\n",
      "74/74 [==============================] - 21s 217ms/step - loss: 0.6629 - accuracy: 0.8488 - val_loss: 0.5706 - val_accuracy: 0.9041 - lr: 3.0000e-04\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.8590\n",
      "Epoch 22: val_loss improved from 0.55286 to 0.46664, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 36s 480ms/step - loss: 0.6436 - accuracy: 0.8590 - val_loss: 0.4666 - val_accuracy: 0.9476 - lr: 3.0000e-04\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.8602\n",
      "Epoch 23: val_loss did not improve from 0.46664\n",
      "74/74 [==============================] - 14s 192ms/step - loss: 0.6401 - accuracy: 0.8602 - val_loss: 0.7798 - val_accuracy: 0.7933 - lr: 3.0000e-04\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.8488\n",
      "Epoch 24: val_loss did not improve from 0.46664\n",
      "74/74 [==============================] - 15s 197ms/step - loss: 0.6499 - accuracy: 0.8488 - val_loss: 1.0315 - val_accuracy: 0.6222 - lr: 3.0000e-04\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.8628\n",
      "Epoch 25: val_loss did not improve from 0.46664\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 0.6328 - accuracy: 0.8628 - val_loss: 0.5127 - val_accuracy: 0.9258 - lr: 3.0000e-04\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.8721\n",
      "Epoch 26: val_loss improved from 0.46664 to 0.38222, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 35s 477ms/step - loss: 0.5731 - accuracy: 0.8721 - val_loss: 0.3822 - val_accuracy: 0.9644 - lr: 9.0000e-05\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8873\n",
      "Epoch 27: val_loss did not improve from 0.38222\n",
      "74/74 [==============================] - 14s 182ms/step - loss: 0.5317 - accuracy: 0.8873 - val_loss: 0.4252 - val_accuracy: 0.9446 - lr: 9.0000e-05\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.8911\n",
      "Epoch 28: val_loss improved from 0.38222 to 0.36182, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 36s 482ms/step - loss: 0.4971 - accuracy: 0.8911 - val_loss: 0.3618 - val_accuracy: 0.9585 - lr: 9.0000e-05\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.8797\n",
      "Epoch 29: val_loss did not improve from 0.36182\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 0.5150 - accuracy: 0.8797 - val_loss: 0.3722 - val_accuracy: 0.9594 - lr: 9.0000e-05\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.8933\n",
      "Epoch 30: val_loss did not improve from 0.36182\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 0.4951 - accuracy: 0.8933 - val_loss: 0.4256 - val_accuracy: 0.9347 - lr: 9.0000e-05\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:02:12.537039Z",
     "start_time": "2024-07-29T19:02:10.698569Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "cb9409c4dba63f27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 67ms/step - loss: 0.6451 - accuracy: 0.8331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.645103394985199, 0.8331360816955566]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:07:52.332247Z",
     "start_time": "2024-07-29T19:07:52.318255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 30\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-25]:\n",
    "    layer.trainable = False"
   ],
   "id": "9c3fa202d236af9e",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:07:52.930815Z",
     "start_time": "2024-07-29T19:07:52.892757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000075), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "10b77e72c3b9b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_rs_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet-rs-101 (Functional)  (None, 7, 7, 2048)        61675296  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62909156 (239.98 MB)\n",
      "Trainable params: 10942532 (41.74 MB)\n",
      "Non-trainable params: 51966624 (198.24 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:11:30.061778Z",
     "start_time": "2024-07-29T19:07:54.347198Z"
    }
   },
   "cell_type": "code",
   "source": "history_200 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "38d94ee2c181b1df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4646 - accuracy: 0.8878\n",
      "Epoch 31: val_loss did not improve from 0.28269\n",
      "74/74 [==============================] - 23s 199ms/step - loss: 0.4646 - accuracy: 0.8878 - val_loss: 0.4277 - val_accuracy: 0.9050 - lr: 7.5000e-05\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.9089\n",
      "Epoch 32: val_loss did not improve from 0.28269\n",
      "74/74 [==============================] - 12s 162ms/step - loss: 0.4084 - accuracy: 0.9089 - val_loss: 0.3359 - val_accuracy: 0.9466 - lr: 7.5000e-05\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.9136\n",
      "Epoch 33: val_loss improved from 0.28269 to 0.27764, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 33s 450ms/step - loss: 0.4009 - accuracy: 0.9136 - val_loss: 0.2776 - val_accuracy: 0.9634 - lr: 7.5000e-05\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.9064\n",
      "Epoch 34: val_loss did not improve from 0.27764\n",
      "74/74 [==============================] - 13s 177ms/step - loss: 0.4248 - accuracy: 0.9064 - val_loss: 0.3236 - val_accuracy: 0.9565 - lr: 7.5000e-05\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.9204\n",
      "Epoch 35: val_loss did not improve from 0.27764\n",
      "74/74 [==============================] - 12s 160ms/step - loss: 0.3816 - accuracy: 0.9204 - val_loss: 0.2855 - val_accuracy: 0.9594 - lr: 7.5000e-05\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.9132\n",
      "Epoch 36: val_loss did not improve from 0.27764\n",
      "74/74 [==============================] - 12s 159ms/step - loss: 0.3829 - accuracy: 0.9132 - val_loss: 0.3009 - val_accuracy: 0.9575 - lr: 7.5000e-05\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.9183\n",
      "Epoch 37: val_loss improved from 0.27764 to 0.24531, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 32s 428ms/step - loss: 0.3544 - accuracy: 0.9183 - val_loss: 0.2453 - val_accuracy: 0.9753 - lr: 2.2500e-05\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.9356\n",
      "Epoch 38: val_loss improved from 0.24531 to 0.24404, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 33s 447ms/step - loss: 0.3311 - accuracy: 0.9356 - val_loss: 0.2440 - val_accuracy: 0.9743 - lr: 2.2500e-05\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.9416\n",
      "Epoch 39: val_loss improved from 0.24404 to 0.23144, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 32s 433ms/step - loss: 0.3106 - accuracy: 0.9416 - val_loss: 0.2314 - val_accuracy: 0.9773 - lr: 2.2500e-05\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.9348\n",
      "Epoch 40: val_loss did not improve from 0.23144\n",
      "74/74 [==============================] - 13s 168ms/step - loss: 0.3122 - accuracy: 0.9348 - val_loss: 0.2534 - val_accuracy: 0.9733 - lr: 2.2500e-05\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:11:31.844968Z",
     "start_time": "2024-07-29T19:11:30.062657Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "572beefd899e12a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 64ms/step - loss: 0.5906 - accuracy: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5906388759613037, 0.8627219200134277]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:12:05.729528Z",
     "start_time": "2024-07-29T19:12:05.726618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 40\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True"
   ],
   "id": "93ad3cc030c9c69",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:12:06.625519Z",
     "start_time": "2024-07-29T19:12:06.582526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.000025), metrics = ['accuracy'])\n",
    "model_1.summary()"
   ],
   "id": "9ed4bf4a63f90d77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet_rs_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_Augmentation (Sequent  (None, None, None, 3)     0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " resnet-rs-101 (Functional)  (None, 7, 7, 2048)        61675296  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2048)              8192      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62909156 (239.98 MB)\n",
      "Trainable params: 22491716 (85.80 MB)\n",
      "Non-trainable params: 40417440 (154.18 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:15:32.658978Z",
     "start_time": "2024-07-29T19:12:12.135221Z"
    }
   },
   "cell_type": "code",
   "source": "history_500 = model_1.fit(train_datagen, validation_data = (val_datagen), epochs = start_epoch+10, initial_epoch = start_epoch, verbose = 1, callbacks = [model_1chkpt, lr_scheduler], steps_per_epoch = len(train_datagen), validation_steps = len(val_datagen))",
   "id": "b0794490c20e0209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.9276\n",
      "Epoch 41: val_loss improved from 0.23144 to 0.20779, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 47s 536ms/step - loss: 0.3422 - accuracy: 0.9276 - val_loss: 0.2078 - val_accuracy: 0.9773 - lr: 2.5000e-05\n",
      "Epoch 42/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.9348\n",
      "Epoch 42: val_loss did not improve from 0.20779\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 0.3325 - accuracy: 0.9348 - val_loss: 0.2978 - val_accuracy: 0.9456 - lr: 2.5000e-05\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.9238\n",
      "Epoch 43: val_loss did not improve from 0.20779\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 0.3403 - accuracy: 0.9238 - val_loss: 0.2304 - val_accuracy: 0.9753 - lr: 2.5000e-05\n",
      "Epoch 44/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.9343\n",
      "Epoch 44: val_loss did not improve from 0.20779\n",
      "74/74 [==============================] - 12s 153ms/step - loss: 0.3292 - accuracy: 0.9343 - val_loss: 0.3965 - val_accuracy: 0.9041 - lr: 2.5000e-05\n",
      "Epoch 45/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.9441\n",
      "Epoch 45: val_loss did not improve from 0.20779\n",
      "74/74 [==============================] - 12s 154ms/step - loss: 0.3094 - accuracy: 0.9441 - val_loss: 0.3231 - val_accuracy: 0.9456 - lr: 7.5000e-06\n",
      "Epoch 46/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.9437\n",
      "Epoch 46: val_loss did not improve from 0.20779\n",
      "74/74 [==============================] - 14s 177ms/step - loss: 0.3100 - accuracy: 0.9437 - val_loss: 0.2692 - val_accuracy: 0.9634 - lr: 7.5000e-06\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.9407\n",
      "Epoch 47: val_loss improved from 0.20779 to 0.20723, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 33s 445ms/step - loss: 0.2967 - accuracy: 0.9407 - val_loss: 0.2072 - val_accuracy: 0.9852 - lr: 7.5000e-06\n",
      "Epoch 48/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.9500\n",
      "Epoch 48: val_loss did not improve from 0.20723\n",
      "74/74 [==============================] - 12s 161ms/step - loss: 0.2861 - accuracy: 0.9500 - val_loss: 0.2104 - val_accuracy: 0.9842 - lr: 7.5000e-06\n",
      "Epoch 49/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.9581\n",
      "Epoch 49: val_loss did not improve from 0.20723\n",
      "74/74 [==============================] - 11s 142ms/step - loss: 0.2653 - accuracy: 0.9581 - val_loss: 0.2160 - val_accuracy: 0.9802 - lr: 7.5000e-06\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.9543\n",
      "Epoch 50: val_loss improved from 0.20723 to 0.19622, saving model to Trained_Models/Resnet_rs_101\n",
      "74/74 [==============================] - 34s 458ms/step - loss: 0.2857 - accuracy: 0.9543 - val_loss: 0.1962 - val_accuracy: 0.9832 - lr: 7.5000e-06\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:15:36.306764Z",
     "start_time": "2024-07-29T19:15:34.626282Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.evaluate(test_datagen)",
   "id": "7accf2968e67a759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 61ms/step - loss: 0.6092 - accuracy: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6092352271080017, 0.8568047285079956]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:29:20.860931Z",
     "start_time": "2024-07-29T18:29:20.592463Z"
    }
   },
   "cell_type": "code",
   "source": "resnet = tf.keras.models.load_model(\"/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\")\n",
   "id": "cc8e6b2a803e9d63",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m resnet \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/saving/saving_api.py:262\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    255\u001B[0m         filepath,\n\u001B[1;32m    256\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[1;32m    258\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[1;32m    259\u001B[0m     )\n\u001B[1;32m    261\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/eye_detection_fundus_dataset/.venv/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[0;32m--> 234\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[1;32m    235\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    236\u001B[0m         )\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[1;32m    239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[1;32m    240\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[1;32m    241\u001B[0m         )\n",
      "\u001B[0;31mOSError\u001B[0m: No file or directory found at /home/thefilthysalad/PycharmProjects/eye_detection_fundus_dataset/ML_Models/Trained_Models/Resnet"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resnet.evaluate(val_datagen)",
   "id": "ebb33e0640d23929",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
